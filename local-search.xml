<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>常识Transformer用于自动知识图构建</title>
    <link href="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/"/>
    <url>/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="《COMET：Commonsense-Transformers-for-Automatic-Knowledge-Graph-Construction》"><a href="#《COMET：Commonsense-Transformers-for-Automatic-Knowledge-Graph-Construction》" class="headerlink" title="《COMET：Commonsense Transformers for Automatic Knowledge Graph Construction》"></a>《COMET：Commonsense Transformers for Automatic Knowledge Graph Construction》</h3><p><a href="https://arxiv.org/pdf/1906.05317v2.pdf">论文地址</a></p><p><a href="https://github.com/atcbosselut/comet-commonsense">论文源码</a></p><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><ul><li><strong>目的层面</strong> —— 根据两个当前最常用的常识知识图<strong>ATOMIC</strong>和<strong>ConceptNet</strong>构建一个用于<strong>开发常识知识</strong>的自适应生成模型<strong>COMET</strong>，以协助完成常识知识的<strong>自我补充</strong>。</li></ul><p>​    <strong>COMET</strong>是一个自适应框架，用于通过在知识元组的种子集上训练语言模型来从语言模型构建常识知识库。这些知识元组为<strong>COMET</strong>提供了必须学习的知识库结构和关系，<strong>COMET</strong>学习调整从预处理中学习的语言模型表示，以向种子知识图添加新的节点和边。</p><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/1.png" class=""><ul><li><strong>实验层面</strong> <ul><li>训练知识库 —— 格式为 <script type="math/tex">\{s ,r, o\}</script>的自然语言元组, 其中 <script type="math/tex">s</script> 为元组的短语主语,  <script type="math/tex">r</script> 为元组的关系， <script type="math/tex">o</script> 为元组的短语宾语。例如 <script type="math/tex">\left(s="take \space a \space nap", r=Causes, o="have \space energy" \right)</script>。</li><li>任务 —— 给定 <script type="math/tex">s</script> 和 <script type="math/tex">r</script> 作为输入， 要求生成 <script type="math/tex">o</script>。 </li></ul></li></ul><h4 id="Transformer语言模型"><a href="#Transformer语言模型" class="headerlink" title="Transformer语言模型"></a>Transformer语言模型</h4><p>​    采用<strong>GPT</strong>的语言模型架构构建<strong>COMET</strong>。</p><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/2.png" class=""><h5 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h5><p>​    多头注意力机制 —— 顾名思义， 注意力由多个头部组成，每个头部使用查询 <script type="math/tex">Q</script> 和键 <script type="math/tex">K</script> 来计算一个唯一的点积注意力分布。</p><script type="math/tex; mode=display">\text { ATTENTION }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V</script><p>​    其中，<script type="math/tex">d_{k}</script> 为 <script type="math/tex">Q, \space K, \space V</script> 的输入向量的维度。对于每个注意力头来说，在计算注意力之前， <script type="math/tex">Q, \space K, \space V</script> 被一组矩阵唯一映射。(<strong>对应a图蓝色部分</strong>)</p><script type="math/tex; mode=display">H_{i} = \text { ATTENTION }(QW_{i}^{Q}, KW_{i}^{K}, V_{i}^{V})</script><p>​    <script type="math/tex">H_{i}</script> 为单个注意力头的输出， <script type="math/tex">W_{i}^{Q}, \space W_{i}^{K}, \space W_{i}^{V}</script> 为特定头的关于 <script type="math/tex">Q, \space K, \space V</script> 的映射矩阵。</p><p>​    同时，多个注意力头的输出将被连接在一起。(<strong>对应a图紫色部分</strong>)</p><script type="math/tex; mode=display">\operatorname{MULTIH}(\mathrm{Q}, \mathrm{K}, \mathrm{V})=\left[H_{1} ; \ldots ; H_{b}\right] W^{O}</script><p>​    其中 <script type="math/tex">W^{O}</script> 为输出的映射矩阵。</p><p><strong>多头注意力的输入</strong></p><p>​    如b图所示，当前层多头注意力的输入来源于上一层Transformer Block的输出。其中，输入的 <script type="math/tex">Q</script> 对应于上一层Block的输出 <script type="math/tex">h_{t}^{l-1}</script>，而 <script type="math/tex">K</script> 和 <script type="math/tex">V</script> 对应于所有先前时间步长的前一层块的输出 <script type="math/tex">\mathbf{h}_{t}^{l-1} = \left\{h^{l-1}\right\}_{<t}</script> 。</p><script type="math/tex; mode=display">\operatorname{MULTIATTN}\left(h_{t}^{l-1}\right)=\operatorname{MULTIH}\left(h_{t}^{l-1}, \mathbf{h}_{t}^{l-1}, \mathbf{h}_{t}^{l-1}\right)</script><h5 id="Transformer块"><a href="#Transformer块" class="headerlink" title="Transformer块"></a>Transformer块</h5><p>​    如b图所示，每个Transformer层包含一个架构上相同的Transformer Block块(尽管具有唯一的可训练参数)，该Transformer Block对该块的输入应用以下变换:</p><script type="math/tex; mode=display">\begin{aligned}\tilde{g}^{l} &=\mathrm{MULTIATTN}\left(h^{l-1}\right) \\g^{l} &=\mathrm{LAYERNORM}\left(\tilde{g}^{l}+h^{l-1}\right) \\\tilde{h}^{l} &=\mathrm{FFN}\left(g^{l}\right) \\h^{l} &=\text { LAYERNORM }\left(\tilde{h}^{l}+g^{l}\right)\end{aligned}</script><p>​    其中，<script type="math/tex">\tilde{g}^{l}</script> 为多头注意力的输出，<script type="math/tex">FFN</script> 是一个两层的前馈神经网络(Feedforward Network), 而 <script type="math/tex">LAYERNORM</script>层是对多头注意力层输出以及前馈层输出的正则化操作，操作的输入包含一个残差连接，该连接将前一个操作的输出和输入相加。</p><h5 id="输入编码器"><a href="#输入编码器" class="headerlink" title="输入编码器"></a>输入编码器</h5><p>​    <strong>文本嵌入</strong> —— <script type="math/tex">\mathbf{X}= \{ X^{s}, \space X^{r}, \space X^{o} \}</script>,  其中 <script type="math/tex">X^{s}, \space X^{r}, \space X^{o}</script> 分别代表知识元组 <script type="math/tex">\{s ,r, o\}</script> 中每一项的单词序列，<script type="math/tex">\mathbf{X}</script> 为三者的串联。对于任意 <script type="math/tex">x_{t} \in \mathbf{X}</script> ，单词 <script type="math/tex">x_{t}</script> 的单词嵌入为 <script type="math/tex">e_{t} = \sum x_{t}^{i}</script> ，这里的 <script type="math/tex">\sum</script> 为向量和。</p><p><strong>为何单词嵌入是一种向量和的形式？</strong></p><p>这是因为GPT采用<strong>字节对编码</strong>(BPE)的方式构建字词，准确来说，GPT以子词表中子词作为词嵌入的基本单位的，这里输入的文本中的完整单词在字词表中可能是好几个字词之和，所以在表示完整单词的文本嵌入时，用的是子词嵌入向量的和。关于<strong>字节对编码</strong>的具体步骤，我之前的一篇<a href="https://caoyusang.github.io/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/">文章</a>中有提到，这里不再赘述。    </p><p>​    <strong>位置嵌入</strong> —— 因为transformer是一种自注意力模型，没有token顺序的概念，所以引入位置编码 <script type="math/tex">p_{t}</script> 来指示模型各个token在文本序列中所处的绝对位置。</p><p>​    <strong>最终输入</strong> —— <script type="math/tex">h_{t}^{l} = e_{t} + p_{t}</script>， 其中 <script type="math/tex">l</script> 表示transformer层数， <script type="math/tex">t</script> 代表第 <script type="math/tex">t</script> 个时间步。如c图所示，第一层的输入为： <script type="math/tex">h^{0} = e_{0} + p_{0}</script>，</p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul><li><strong>训练任务</strong> —— 给定知识元组 <script type="math/tex">\{ s, \space r, \space o \}</script>，要求以 <script type="math/tex">s</script> 和 <script type="math/tex">r</script> 对应token的串接 <script type="math/tex">\left[ X^{s}, X^{r} \right]</script> 作为输入，模型需要学会生成 <script type="math/tex">o</script> 对应的那些tokens，即 <script type="math/tex">X^{o}</script> 。</li><li><strong>损失函数</strong> —— 标准的语言模型的损失函数，即对数似然函数。</li></ul><script type="math/tex; mode=display">\mathcal{L}=-\sum_{t=|s|+|r|}^{|s|+|r|+|o|} \log P\left(x_{t} \mid x_{<t}\right)</script><p>​    已知前 <script type="math/tex">t-1</script> 个生成的token <script type="math/tex">x_{<t}</script> ，当前第 <script type="math/tex">t</script> 个位置生成token <script type="math/tex">x_{t}</script>的概率为：</p><script type="math/tex; mode=display">P\left(x_{t} \mid x_{<t}\right)=\operatorname{softmax}\left(\mathbf{W}_{\text {vocab}} \cdot \mathbf{h}_{\mathrm{t}}\right)</script><p>​    其中，<script type="math/tex">|s|, \space |r|, \space |o|</script> 分别为短句主语、关系、宾语对应的token数目。 这里 <script type="math/tex">h_{t}</script> 表示在解码时GPT对<script type="math/tex">x_{t}</script> 的最终表示，<script type="math/tex">\mathbf{W}_{\text {vocab}}</script>是GPT使用的词汇表的嵌入矩阵。</p><ul><li><p><strong>实验数据集</strong> —— ATOMIC 和 ConceptNet</p></li><li><p><strong>输入构造</strong></p><ul><li>ATOMIC —— 关系token只有一个</li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/3.png" class=""><ul><li>ConceptNet —— 关系token可能有多个，引入第二组mask来分隔关系token和宾语token。</li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/4.png" class=""></li><li><p><strong>模型参数初始化</strong> —— 使用GPT的预训练模型权重初始化模型，为了微调，往词汇表中加入了一些特殊的token。例如，关系嵌入(如oReact for ATOMIC和IsA for ConceptNet)是通过从标准正态分布中采样来初始化的。</p></li><li><p><strong>超参设置 </strong></p><ul><li><strong>12</strong> layers</li><li><strong>768</strong>-dimensional hidden states </li><li><strong>12</strong> attention heads</li><li>dropout    <strong>0.1</strong></li><li>activation fuction    <strong>GeLU</strong></li><li>batch size    <strong>64</strong></li><li>lr    <strong>6.25e-5</strong> (with a warmup period of 100 minibatches)</li><li>decay method    <strong>linear</strong></li></ul></li></ul><h4 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h4><h5 id="ATOMIC"><a href="#ATOMIC" class="headerlink" title="ATOMIC"></a>ATOMIC</h5><h6 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h6><ul><li>877K 知识元组，涵盖围绕特定事件的社会常识知识</li><li>九个关系维度提炼事件中的常识知识</li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/5.png" class=""><p>​    对应到实验中，ATOMIC事件(例如，“<strong>X goes to the store</strong>”)是短语主体 <script type="math/tex">s</script> ，<strong>xIntent</strong>是短语关系 <script type="math/tex">r</script> ，<strong>causes/effects</strong>(例如，“<strong>to get food</strong>”)是短语客体 <script type="math/tex">o</script>。训练集/开发集/测试集的数目分别为：<strong>710k/80k/87k</strong></p><h6 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h6><ul><li><strong>自动评估</strong></li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/6.png" class=""><p>​    上图为采用自动评估标准的评估结果(评估的是生成 <script type="math/tex">o</script> 的质量和新颖性，第一列对比的模型为<strong>ATOMIC</strong>提出文章中的<strong>baseline</strong>，后面两个是论文提出的COMET模型。从第二列开始都是评估的指标，第二列是困惑度<strong>PPL</strong>，第三列是<strong>BLEU-2</strong>，第三列是模型生成元组所占的比例，第四列是模型生成的未出现在训练集元组中 <script type="math/tex">o</script> 所占的比例(<strong>元组新颖性</strong>)，为了证明模型生成的元组新客体不是唯一的，把产生的新客体的数目作为测试集事件产生的唯一客体集合的函数，就是第五列。</p><ul><li><strong>人工评估</strong></li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/7.png" class=""><p>​    <strong>BLEU-2</strong>的评估结果表明，<strong>COMET</strong>模型超越了所有baseline的表现，比表现最好的baseline实现了51%的相对表现提升。对于人工评估的结果，<strong>COMET</strong>报告了统计上显著的<strong>相对Avg性能</strong>，比最高基线提高了18%。</p><p>​    为了评估在大型语料库上的预训练如何帮助模型学习产生知识，训练了一个没有用预训练权重初始化的COMET版本(COMET(- pretrain))。通过在不同比例的训练数据上训练模型来评估方法的数据效率。</p><p>​    最后，因为最终目标是能够执行高质量、多样化的知识库构建，所以探索了各种解码方案如何影响候选知识元组的质量，采用了不同生成策略进行了实验，这些策略包括：argmax贪婪解码、波束大小的波束搜索、b=2、5、10和k = 5、10的top-k采样。对于每种解码方法，对每种方法产生的最终候选数进行人工评估，结果如下：</p><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/8.png" class=""><p>​    上述结果表明，使用贪婪解码来产生知识元组，与人工评估ATOMIC测试集相比，仅存在10%的相对性能差距，表明由模型产生的知识接近人工性能。</p><h5 id="ConceptNet"><a href="#ConceptNet" class="headerlink" title="ConceptNet"></a>ConceptNet</h5><h6 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h6><ul><li>标准的SRO三元组格式，涵盖大量关系三元组，例如(take a nap,  Causes,  have energy)</li></ul><p>​    对应到实验中，各选取了1200个三元组作为测试集和开发集，包含34个关系类型的100k版本的训练集用于训练模型。</p><h6 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h6><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/9.png" class=""><p><strong>生成质量评估</strong></p><p>​    为了评估生成知识的质量，给出在测试集中生成的正面示例的数量，这些正面示例被评为正确。对于给定的 <script type="math/tex">s \space r \space o \space</script>元组，考虑该模型产生元组是否正确的概率，以50%的概率对分数进行阈值化，以识别正确的预测。</p><p>​    结果表明，该模型可以生成高质量的知识：上表中的<strong>低困惑度</strong>(<strong>PPL</strong>)分数表明其预测的高模型置信度，而高分类器得分Score<strong>(95.25%)</strong>表明知识库补全模型在大多数情况下将生成的元组评分为正确。在人工评估(遵循与ATOMIC相同的设计)中，贪婪解码得到的元组的91.7%被评为正确。</p><p><strong>生成新颖度评估</strong></p><p>​    其中<script type="math/tex">N/T \space sro</script> 达到了<strong>59.25%</strong>，说明有接近<strong>6成</strong>的生成元组未出现在训练集中，显示该模型能够在节点之间生成新的边，甚至创建新的节点(<script type="math/tex">N/T \space o = 3.75</script> ，即<strong>3.75%的节点是新的</strong>)来扩展知识图的大小。但是需要注意的是，有一些新产生的元组仅仅是训练集中元组的简化形式。为此论文进行了研究，这些简化形式的新元组到底有多少。结论是<strong>大多数产生的新元组与训练集中它们最接近的元组具有明显不同的单词序列。</strong></p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>​    本文引入常识转换器<strong>(COMET)</strong>来自动构建常识知识库。<strong>COMET</strong>是一个框架，用于调整语言模型的权重，以学习生成新颖和多样的常识知识元组。在两个常识知识库<strong>ATOMIC</strong>和<strong>ConceptNet上</strong>的实验结果表明，<strong>COMET</strong>经常产生人类评估者认为是正确的新常识知识。这些积极的结果表明未来可以寻求将该方法扩展到各种其他类型的知识库上，以及研究<strong>COMET</strong>是否可以学习为任意知识种子产生OpenIE风格的知识元组。</p>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自然语言处理任务梳理</title>
    <link href="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/"/>
    <url>/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="NLP任务"><a href="#NLP任务" class="headerlink" title="NLP任务"></a>NLP任务</h1><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/1.png" class="" title="1.png"><h2 id="前处理任务"><a href="#前处理任务" class="headerlink" title="前处理任务"></a>前处理任务</h2><p>前处理任务的结果可作为下游任务输入的额外特征。</p><h3 id="POSTa-词性标注"><a href="#POSTa-词性标注" class="headerlink" title="POSTa(词性标注)"></a>POSTa(词性标注)</h3><p>往模型中输入句子，对每一个token进行词性的识别。</p><p>识别出的词性可以用于下游任务。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/2.png" class="" title="2.png"><h3 id="Word-Segmentation-分词"><a href="#Word-Segmentation-分词" class="headerlink" title="Word Segmentation(分词)"></a>Word Segmentation(分词)</h3><p>对于英文，显然句子有天然的分词。所以分词通常是针对中文句子。</p><p>分词之后，模型的输入就可以以词汇作单位，而不再以字作单位。</p><p>以下面例子做说明：</p><p>将一个句子按字输入模型，训练模型来对每个字来进行二分类决定每个字的对应位置输出N或者Y(N/Y是词的边界标识)</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/3.png" class="" title="3.png"><h3 id="Parsing-语义分析"><a href="#Parsing-语义分析" class="headerlink" title="Parsing(语义分析)"></a>Parsing(语义分析)</h3><p>给定句子产生树状结构——句子的语法结构。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/4.png" class="" title="4.png"><h3 id="Coreference-Rosolution-共指消解"><a href="#Coreference-Rosolution-共指消解" class="headerlink" title="Coreference Rosolution(共指消解)"></a>Coreference Rosolution(共指消解)</h3><p>从一段文章或者一段对话中找出指代同一个人或事物的所有词汇。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/5.png" class="" title="5.png"><h2 id="具体NLP任务"><a href="#具体NLP任务" class="headerlink" title="具体NLP任务"></a>具体NLP任务</h2><h3 id="Summarization-文本摘要"><a href="#Summarization-文本摘要" class="headerlink" title="Summarization(文本摘要)"></a>Summarization(文本摘要)</h3><p><strong>抽取式摘要：</strong>基于二分类任务，每个句子分开考虑。</p><p>衡量文章中句子应不应该放到摘要里面，但是这么做远远不够。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/6.png" class="" title="6.png"><p><strong>生成式摘要：</strong>属于seq2seq模型，输入长文本，模型用自己的语言进行短摘要的生成。</p><p><strong>模型的copy能力</strong>：输入文本序列和输出摘要很有可能有很多共用词汇，这些共用词汇经过模型的修改整合形成摘要的文本。因此模型需要增加输入copy能力，怎么实现？Pointer network(指针网络)。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/7.png" class="" title="7.png"><h3 id="Machine-Translation-机器翻译"><a href="#Machine-Translation-机器翻译" class="headerlink" title="Machine Translation(机器翻译)"></a>Machine Translation(机器翻译)</h3><p><strong>seq2seq</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/8.png" class="" title="8.png"><p><strong>audio2seq</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/9.png" class="" title="9.png"><p><strong>audio2audio</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/10.png" class="" title="10.png"><h3 id="Grammer-Error-Correction-语法纠正"><a href="#Grammer-Error-Correction-语法纠正" class="headerlink" title="Grammer Error Correction(语法纠正)"></a>Grammer Error Correction(语法纠正)</h3><p><strong>seq2seq?</strong> </p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/11.png" class="" title="11.png"><p>不，杀鸡焉用牛刀。</p><p><strong>seq2class</strong></p><p>输入句子，做分类，输出要对token要做的动作的标识（C/R/A/D)。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/12.png" class="" title="12.png"><p>C——复制，保持不变</p><p>A——在后面增加词汇</p><p>R——置换，把词换个时态或者换成别的词</p><p>D——删除</p><h3 id="Sentiment-Classfication-情感分类"><a href="#Sentiment-Classfication-情感分类" class="headerlink" title="Sentiment Classfication(情感分类)"></a>Sentiment Classfication(情感分类)</h3><p>输入一段文本或者评论，训练模型，输出文本的情感分类(正面/负面)。</p><p><strong>seq2class</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/13.png" class="" title="13.png"><h3 id="Stance-Detection-立场侦测"><a href="#Stance-Detection-立场侦测" class="headerlink" title="Stance Detection(立场侦测)"></a>Stance Detection(立场侦测)</h3><p><strong>seq2class</strong></p><p>通过一则博文或者文章以及其下的评论回复来进行评论者所处立场的判断。</p><p>立场通常有四类：SDQC(Support、Denying、Querying and Commenting)。</p><p>立场侦测经常被用于事实预测:</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/14.png" class="" title="14.png"><p><strong>事实预测：</strong></p><p><strong>seq2class</strong></p><p>根据新闻消息或者博文的评论立场以及外部的知识判断消息或文章内容的真实性。</p><h3 id="Natural-Language-Inference-自然语言推理"><a href="#Natural-Language-Inference-自然语言推理" class="headerlink" title="Natural Language Inference(自然语言推理)"></a>Natural Language Inference(自然语言推理)</h3><p><strong>seq2class</strong></p><p><strong>推理模型的文本输入</strong>：premise(前提) + hypothesis(假设)</p><p><strong>模型输出：</strong>对假设是否成立的判断结果，矛盾/包含(可推得)/中立(contradiction/entailment/neutral)</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/15.png" class="" title="15.png"><h3 id="Question-Answering-问答"><a href="#Question-Answering-问答" class="headerlink" title="Question Answering(问答)"></a>Question Answering(问答)</h3><h4 id="传统的基于检索的问答系统"><a href="#传统的基于检索的问答系统" class="headerlink" title="传统的基于检索的问答系统"></a>传统的基于检索的问答系统</h4><p><strong>简单的(模组少)：</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/16.png" class="" title="16.png"><ul><li><p>问题处理——对问题进行格式化，检测其答案的类别</p></li><li><p>检索资料库——进行文档、文章的检索选择</p></li><li><p>答案的生成和评估——从候选文章中抽取答案，抽取的答案根据第一步检测到的答案类别评估其正确性</p></li></ul><p><strong>复杂的(模组多)：</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/17.png" class="" title="17.png"><p><strong>和简单架构的区别：</strong></p><ul><li><p>问题处理——模组更多</p></li><li><p>候选答案生成——综合检索文章得到的候选答案和从自带的有结构资料库中调取的答案</p></li><li>答案评分</li><li>融合对等答案，返回答案及其可信度</li></ul><h4 id="基于深度学习的QA"><a href="#基于深度学习的QA" class="headerlink" title="基于深度学习的QA"></a>基于深度学习的QA</h4><p><strong>seq2seq</strong></p><p>输入问题文本和外部结构化/无结构化的知识(大多来自搜索引擎)，训练模型得到问题的答案。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/18.png" class="" title="18.png"><p>但是要实现直接向模型输入问题和外部知识就生成问题答案还有非常长的一段路要走。目前我们常做的只是从文本中抽取答案。</p><p><strong>抽取式QA：</strong></p><p><strong>seq2seq</strong></p><p>答案就在背景文章里面，向模型输入背景文章和问题，其实就是做通常意义上的阅读理解，模型产生抽取的答案文本在文章中的 start position 和 end position。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/19.png" class="" title="19.png"><h3 id="Dialogue-对话"><a href="#Dialogue-对话" class="headerlink" title="Dialogue(对话)"></a>Dialogue(对话)</h3><p>对话涉及到自然语言生成(NLG)和自然语言理解(NLU)</p><h4 id="Chatting-闲聊"><a href="#Chatting-闲聊" class="headerlink" title="Chatting(闲聊)"></a>Chatting(闲聊)</h4><p><strong>seq2seq</strong></p><p>聊天都是有背景的，所以模型的输入应该是增量式的，模型的输出是根据之前的对话内容产生的。</p><p>根据对话的需求可以进行定制：</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/20.png" class="" title="20.png"><h4 id="Task-oriented-任务导向的对话"><a href="#Task-oriented-任务导向的对话" class="headerlink" title="Task-oriented(任务导向的对话)"></a>Task-oriented(任务导向的对话)</h4><p><strong>seq2seq</strong></p><p>需要实现一定的功能，比如提供订票、订餐厅、订酒店等服务</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/21.png" class="" title="21.png"><p><strong>系统架构</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/22.png" class="" title="22.png"><p>State Tracker记录当前对话的状态</p><h2 id="知识图"><a href="#知识图" class="headerlink" title="知识图"></a>知识图</h2><h3 id="NER-命名实体识别"><a href="#NER-命名实体识别" class="headerlink" title="NER(命名实体识别)"></a>NER(命名实体识别)</h3><p><strong>seq2class</strong></p><p>识别出句子中的人名、地名、组织等实体</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/23.png" class="" title="23.png"><h3 id="RE-关系抽取"><a href="#RE-关系抽取" class="headerlink" title="RE(关系抽取)"></a>RE(关系抽取)</h3><p><strong>seq2class</strong></p><p>输入文本和文本中两个实体，训练模型得到两个实体之间的关系</p><p>关系的种类基本是固定的，因此关系抽取的模型往往是去做一个复杂的分类任务</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/24.png" class="" title="24.png"><h2 id="综合任务"><a href="#综合任务" class="headerlink" title="综合任务"></a>综合任务</h2><p>综合任务的意义：看模型是否是真的“理解”了人类语言，能“举一反三”</p><h3 id="GLUE"><a href="#GLUE" class="headerlink" title="GLUE"></a>GLUE</h3><p>分为三大类</p><ul><li>文本分类(语法错误检查、文本情感分析)</li><li>文本相似度计算</li><li>自然语言推理</li></ul><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/25.png" class="" title="25.png"><h3 id="Super-GLUE"><a href="#Super-GLUE" class="headerlink" title="Super GLUE"></a>Super GLUE</h3><p>包含8个NLP任务，大多和QA有关</p><h3 id="DecaNLP"><a href="#DecaNLP" class="headerlink" title="DecaNLP"></a>DecaNLP</h3><p>同一个模型解决10个NLP任务</p><p>怎么实现？往QA的方向改造这些任务</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/26.png" class="" title="26.png"><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>根据这些NLP任务的输入输出，把这些任务和任务相关的一些技术手段进行梳理</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/27.png" class="" title="27.png"><h3 id="one-on-one"><a href="#one-on-one" class="headerlink" title="one on one"></a>one on one</h3><p><strong>seq2class</strong></p><ul><li>情感分析</li><li>立场检测</li><li>文本内容辨真伪</li><li>文本意图识别</li><li>对话决策</li></ul><p><strong>seq2tokenclass</strong></p><ul><li>词性标注</li><li>分词</li><li>抽取式摘要</li><li>命名实体识别</li></ul><p><strong>seq2seq</strong></p><ul><li>抽象式摘要</li><li>机器翻译</li><li>文本语法矫正</li><li>自然语言生成</li></ul><h3 id="n-on-one"><a href="#n-on-one" class="headerlink" title="n on one"></a>n on one</h3><p><strong>seq2class</strong></p><ul><li>自然语言推理</li><li>搜索引擎</li><li>关系抽取</li></ul><p><strong>copy from input</strong></p><ul><li>抽取式QA</li></ul><p><strong>seq2seq</strong></p><ul><li>常规QA</li><li>任务导向对话</li><li>聊天机器人</li><li>State Tracker</li></ul><h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><ul><li>语义分析</li><li>共指消解</li></ul>]]></content>
    
    
    <categories>
      
      <category>综述</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>溯因推理</title>
    <link href="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/"/>
    <url>/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="Abductive-Commonsense-Reasoning-溯因推理"><a href="#Abductive-Commonsense-Reasoning-溯因推理" class="headerlink" title="Abductive Commonsense Reasoning(溯因推理)"></a>Abductive Commonsense Reasoning(溯因推理)</h2><p><a href="https://arxiv.org/pdf/1908.05739v2.pdf">论文地址</a><br><a href="https://github.com/allenai/abductive-commonsense-reasoning">论文代码</a></p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><strong>溯因推理</strong>是对不完全观察情境的<strong>最合理解释</strong>或假设的推论。</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/1.png" class=""><p><strong>上图给出的是一个简明扼要的例子：</strong></p><p>给定不同时间节点上的情境观测值 <script type="math/tex">O_{1}</script> 和 <script type="math/tex">O_{2}</script> ，溯因推理的任务是从给出的一众解释性假设 <script type="math/tex">H_{1}, \space H_{2}, \space \cdots ,H_{n}</script> 中选出<strong>最合理</strong>的。例如，上图在 <script type="math/tex">t_{0}</script> 时刻观测到的情境 <script type="math/tex">O_{1}</script> 是：<strong>Jenny打扫好了房间并给窗户留了条缝隙之后去工作了</strong>。而在 <script type="math/tex">t_{n}</script> 时刻，情境变成了：<strong>当Jenny回到家，发现房间里一片狼藉。</strong>针对这两个观测到的不同时间节点上情境，有若干个解释性假设 <script type="math/tex">H_{1}, \space H_{2}, \space H_{3}</script>。</p><ul><li>对于假设 <script type="math/tex">H_{1}</script> ，小偷的入室盗窃(<strong>broke into</strong>)很好的承接了 <script type="math/tex">O_{1}</script> 中”<strong>未关紧窗户(a crack open)</strong>“带来的安全隐患，并很好地解释了情境 <script type="math/tex">O_{2}</script> 中房间为什么一团乱(<strong>小偷翻东西</strong>)，因此看上去假设 <script type="math/tex">H_{1}</script> 非常合理的解释了情境 <script type="math/tex">O_{1}</script> 到情境 <script type="math/tex">O_{2}</script> 的转换。</li><li>对于假设 <script type="math/tex">H_{2}</script> ，假设中提到的大只的鸟(<strong>large bird</strong>)似乎不太可能从窗户缝隙飞进房间，但是如果不考虑情境 <script type="math/tex">O_{1}</script>，该假设可以很好地解释房间乱的现象(<strong>鸟儿被困房间，为了逃离，弄得房间很乱</strong>)</li><li>对于假设 <script type="math/tex">H_{3}</script>，前半部分<strong>(At work)</strong>可以很好地承接情境 <script type="math/tex">O_{1}</script>(<strong>Jenny去工作了，因此Jenny在工作中</strong>)，但是该假设后半部分(<strong>blew her papers everywhere</strong>)完全没法解释情境 <script type="math/tex">O_{2}</script>， 因为该假设完全指的是发生在<strong>办公处</strong>的事情，而情境 <script type="math/tex">O_{2}</script> 则是Jenny<strong>家中</strong>的场景。</li></ul><p>综合以上对三个假设的考量，我们很容易得出，第一个假设是最符合情境 <script type="math/tex">O_{1}</script> 和 <script type="math/tex">O_{2}</script> 的。然而这看似简单的推理过程，对于现有的模型来说，却不是那么容易的。</p><p>虽然长期以来<strong>”溯因“</strong>这种行为被认为是人们解读、理解自然语言的核心，但受限于数据集的缺乏和模型的性能，支撑溯因自然语言推理和生成的研究却相对较少。</p><h3 id="ART数据集"><a href="#ART数据集" class="headerlink" title="ART数据集"></a>ART数据集</h3><p>ART(<strong>叙事文本中的溯因推理</strong>——ABDUCTIVE REASONING IN NARRATIVE TEXT)是第一个用于研究叙事文本中溯因推理的大规模基准数据集。其组成如下：</p><ul><li><strong>20K左右的叙述背景</strong> ——成对的观察结果&lt;<script type="math/tex">O_{1}\space，O_{2}</script>&gt;<ul><li>这些观察情境是根据<strong>ROCStories</strong>数据集进行编写的。<strong>ROCStories</strong>是一个由五句话组成的手动精选短篇故事的大集合。它被设计为每个故事都有一个清晰的开始和结束，这自然对应到ART数据集中的 <script type="math/tex">O_{1},O_{2}</script> 。</li></ul></li><li><strong>超过200K的解释性假设</strong><ul><li>按可能的解释性假设 <script type="math/tex">h^{+}</script> 和不太可能的解释性假设 <script type="math/tex">h^{-}</script> 进行众包。对于 <script type="math/tex">h^{-}</script> 的众包 ,要求众包工人在 <script type="math/tex">h^{+}</script> 的基础上，进行最小限度的编辑(最多改动5个单词)，为每个 <script type="math/tex">h^{+}</script> 创造不可信的假设变量 <script type="math/tex">h^{-}</script>。</li></ul></li><li><strong>数据集分析</strong><ul><li>下面分别分析了训练集、开发集、测试集上对应每个观测的平均对应的正反解释性假设的个数和假设及观测文本句的平均词长。</li></ul></li></ul><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/2.png" class=""><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>论文中提出的两个溯因推理任务分别是αNLI(溯因自然语言推理——Abductive Natural Language Inference)和αNLG(溯因自然语言生成 —— Abductive Natural Language Generation)。</p><p>ART数据集中每个例子按如下格式定义：</p><ul><li><script type="math/tex">O_{1}</script> —— <script type="math/tex">t_{1}</script>时刻的观察</li><li><script type="math/tex">O_{2}</script> —— <script type="math/tex">t_{2}</script>时刻的观察</li><li><script type="math/tex">h^{+}</script> —— 对观察 <script type="math/tex">O_{1}</script> 和观察 <script type="math/tex">O_{2}</script> 的更合理的解释</li><li><script type="math/tex">h^{-}</script> —— 对观察 <script type="math/tex">O_{1}</script> 和观察 <script type="math/tex">O_{2}</script> 来说不太合理的解释</li></ul><h4 id="αNLI"><a href="#αNLI" class="headerlink" title="αNLI"></a>αNLI</h4><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/4.png" class=""><p>给定一对观测和一对解释性假设，αNLI的任务是选出两个假设中更有可能的那个。</p><p>在概率框架下模型的目标函数为：</p><script type="math/tex; mode=display">h^{*}=\arg \max _{h^{i}} P\left(H=h^{i} \mid O_{1}, O_{2}\right)</script><p>根据贝叶斯法则，以观测 <script type="math/tex">O_{1}</script> 为先验条件，可以重写上述公式：</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}P\left(h^{i} \mid O_{1}, O_{2}\right) = \frac{P\left(O_{2}, O_{1}, h^{i}\right)}{P\left(O_{1} , O_{2}\right)} \\=\frac{P\left(O_{2}\mid h^{i}, O_{1}\right)P\left(h^{i},O_{1}\right)}{P\left(O_{2}, O_{1}\right)} \\=\frac{P\left(O_{2}\mid h^{i}, O_{1}\right)P\left(h^{i} \mid O_{1}\right)}{P\left(O_{2}\mid O_{1}\right)}\end{aligned}\end{equation}</script><p>因为 <script type="math/tex">P\left(O_{2}\mid O_{1}\right)</script> 是定值，所求又是优化问题，所以可以仅考虑左侧的目标函数与右侧乘式的相关关系即可：</p><script type="math/tex; mode=display">P\left(h^{i} \mid O_{1}, O_{2}\right) \propto P\left(O_{2} \mid h^{i}, O_{1}\right) P\left(h^{i} \mid O_{1}\right)</script><p>根据上式，建立如下若干独立性假设，为αNLI任务构建一套概率模型：</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/3.png" class=""><ul><li><script type="math/tex">H_{i}</script> 与 <script type="math/tex">O_{1},O_{2}</script>都无关时(模型没用到观测值)</li></ul><script type="math/tex; mode=display">P\left(h^{i} \mid O_{1}, O_{2}\right)=P\left(h_{i}\right)</script><ul><li><p><script type="math/tex">H_{i}</script> 仅与 <script type="math/tex">O_{1},O_{2}</script>其中一个有关（模型用到了一个观测值）</p></li><li><p><strong>线性链</strong>模型 —— <script type="math/tex">H_{i}</script> 与 <script type="math/tex">O_{1},O_{2}</script>都直接相关，但 <script type="math/tex">O_{1} \perp O_{2}</script> (模型使用两个观测值，但独立地考虑了每个观测值对假设的影响)，</p></li></ul><script type="math/tex; mode=display">h^{*}=\arg \max _{h^{i}} P\left(O_{2} \mid h^{i}\right) P\left(h^{i} \mid O_{1}\right) \text { where }\left(O_{1} \perp O_{2} \mid H\right)</script><ul><li><strong>全连接</strong>(模型使用两个观测值，结合两个观测值的信息选择合理的假设)，目标函数为：</li></ul><script type="math/tex; mode=display">h^{*}=\arg \max _{h^{i}} P\left(O_{2} \mid h^{i},O_{1}\right) P\left(h^{i} \mid O_{1}\right)</script><p>在论文的实验中，将不同的独立性假设文本输入BERT进行编码。对于前两个概率模型，可以通过简单地将模型的输入限制为相关变量来加强独立性。另一方面，相关线性链模型将所有三个变量 <script type="math/tex">O_{1},O_{2},H</script> 都作为输入，通过限制模型的形式以加强条件独立性。具体来说，学习一个具有二分类功能的分类器:</p><script type="math/tex; mode=display">P_{\text {Linear }} \text { Chain }\left(h \mid O_{1}, O_{2}\right) \propto e^{\phi\left(O_{1}, h\right)+\phi^{\prime}\left(h, O_{2}\right)}</script><p>其中，<script type="math/tex">\phi</script> 和 <script type="math/tex">\phi^{\prime}</script> 为产生标量值的神经网络模型。</p><h4 id="αNLG"><a href="#αNLG" class="headerlink" title="αNLG"></a>αNLG</h4><p>给定 <script type="math/tex">O_{1},O_{2},h^{+}</script> 为一组的的训练数据，<strong>αNLG</strong>的任务就是最大化 <script type="math/tex">O_{1},O_{2},h^{+}</script> 对应的文本句在生成模型中的生成概率。同时，还可以在给定两个观测的基础上再添加背景知识 <script type="math/tex">\text{K}</script> 作为条件，模型的损失函数构造如下：</p><script type="math/tex; mode=display">\mathcal{L}=-\sum_{i=1}^{N} \log P\left(w_{i}^{h} \mid w_{<i}^{h}, w_{1}^{o 1} \ldots w_{m}^{o 1}, w_{1}^{o 2} \ldots w_{n}^{o 2}, \mathcal{K}\right)</script><p>其中，<script type="math/tex">O_{1}=\left\{w_{1}^{o 1} \ldots w_{m}^{o 1}\right\}</script> ，<script type="math/tex">O_{2}=\left\{w_{1}^{o 2} \ldots w_{n}^{o 2}\right\}</script>，<script type="math/tex">h^{+}=\left\{w_{1}^{h} \ldots w_{l}^{h}\right\}</script>，它们都由其自然语言文本对应的token组成。 <script type="math/tex">w_{<i}^{h}</script> 代表当前位置的前 <script type="math/tex">i</script> 个token，<script type="math/tex">w_{i}^{h}</script> 为当前位置 <script type="math/tex">i</script> 处的token。模型的训练目标就是最大化句子的生成概率 <script type="math/tex">P</script>，也即最小化上述公式的损失 <script type="math/tex">L</script>。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="αNLI-1"><a href="#αNLI-1" class="headerlink" title="αNLI"></a>αNLI</h4><p>αNLI任务被构造成了一个二分类问题。</p><h5 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h5><ul><li><strong>SVM</strong> —— 利用Glove词嵌入，考虑词长度、词的重叠和情感特征等对两个假设选项进行选择。(<strong>50.6%</strong>)</li><li><strong>BOW</strong> —— 将两个观察和一个解释性假设文本串接在一起，利用<strong>Glove</strong>为串接起来的文本构建句子嵌入，再通过一个全连接网络为包含每个不同的解释性假设选项的句子的嵌入打分。(<strong>50.5%</strong>)</li><li><strong>Bi-LSTM + max-pooling</strong> —— 用Bi-LSTM编码句子，使用经过最大池化后的句子嵌入进行打分。(<strong>50.8%</strong>)</li></ul><p>可以看到，传统分类器 + 上下文无关的单词嵌入的方式对解决这个二分类问题看上去几乎毫无作用(因为随机二选一都有一半的概率选对)。</p><h5 id="实验模型"><a href="#实验模型" class="headerlink" title="实验模型"></a>实验模型</h5><p>采用预训练模型GPT和BERT编码观测和解释性假设。</p><ul><li>对于GPT，将观测 <script type="math/tex">O_{1}</script> 和解释性假设 <script type="math/tex">H</script> 串接在一起，然后使用 [SEP] 将其与观测 <script type="math/tex">O_{2}</script> 分隔开，以[START] 和 [SEP] 结尾。</li><li>对于BERT，根据不同独立性假设。有如下五种输入的构造方式：</li></ul><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/6.png" class=""><h5 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h5><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/5.png" class=""><p>最后一列代表模型在论文提出的 <script type="math/tex">\text{ART}</script> 数据集上的表现，和前四个baseline相比，基于GPT和BERT构造的分类模型在数据集上的表现明显提高了很多，最好的<strong>BERT-ft[Linear Chain]</strong>比最佳baseline提升了10.1个百分点，达到了68.9。但是和人类的表现相比，这样的结果还是非常差的。因此，在溯因推理方面的研究还有很多工作要做。</p><h4 id="αNLG-1"><a href="#αNLG-1" class="headerlink" title="αNLG"></a>αNLG</h4><h5 id="实验模型-1"><a href="#实验模型-1" class="headerlink" title="实验模型"></a>实验模型</h5><ul><li><p><script type="math/tex">O_{1}-O_{2}-\text{Only}</script> —— 以组成两个观测值 <script type="math/tex">O_{1}</script> 和 <script type="math/tex">O_{2}</script> 的token为起始训练GPT2。</p></li><li><p>使用<strong>COMET</strong>生成<strong>ATOMIC</strong>格式(<strong>如果-那么</strong>)的知识 —— 包含常识知识的图，是一个以推理“如果-那么”的知识为主的知识库，它以事件作为节点，下列九大关系作为边：</p></li></ul><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/10.png" class=""><p><strong>ATOMIC</strong>是对<script type="math/tex">\text{ART}</script> 数据集中的叙事上下文进行推理所需的背景常识的来源。<strong>COMET</strong>是基于<strong>ATOMIC</strong>训练的专门实现常识知识图自动构建的Transformer，这里借助<strong>COMET</strong>生成基于事件的常识推理知识，然后再GPT2中集成了COMET生成的信息用于αNLG任务。集成方式分两种：</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/9.png" class=""><ul><li><strong>COMeT-Txt+GPT-2</strong>（作为文本短语的方式集成）</li></ul><p>在单词嵌入层嵌入输入标记之后，我们在通过Transformer架构的层之前，向串接的观察序列添加18个(对应于每个观察的九个关系)<strong>自然语言文本</strong>，由GPT2进行编码。</p><ul><li><strong>COMeT-Emb+GPT2</strong>（作为嵌入的方式集成）</li></ul><p>和上面那种方式一样，不过在观察序列前添加的是18个<strong>COMeT Embedding</strong>，这允许模型在处理COMeT嵌入时学习每个token的表示——有效地将背景常识知识集成到语言模型中。</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/7.png" class=""><h5 id="评估-1"><a href="#评估-1" class="headerlink" title="评估"></a>评估</h5><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/8.png" class=""><ul><li><strong>自动评估</strong> —— BLEU、METEOR、ROUGE、CIDEr、BERT-Score</li><li><strong>人工评估</strong> —— 向众包人员展示成对的观察结果和一个生成的假设，要求他们标注该假设是否解释了给定的观察结果。最后一栏为对应的评估分数。人工编写的假设在96%的情况下是正确的，而我们最好的生成模型，即使有背景常识知识的增强，也只能达到45%——这表明αNLG生成任务对当前最优越的文本生成器来说尤其具有挑战性。</li></ul><h5 id="生成实例"><a href="#生成实例" class="headerlink" title="生成实例"></a>生成实例</h5><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/11.png" class=""><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>文章提出了第一项研究，调查基于语言的溯因推理的可行性。概念化并引入溯因自然语言推理(αNLI)——一个关注叙事语境中溯因推理的新任务。该任务被表述为一个选择题回答问题。文章还介绍了溯因自然语言生成(αNLG)——一种新的任务，需要机器为给定的观察结果生成可信的假设。为了支持这些任务，创建并引入了一个新的挑战数据集ART，它由20k个常识性叙述和200k多个解释性假设组成。在实验中，基于最先进的NLI和语言模型建立了这一新任务的Baseline，其准确率为68.9%，与人类性能(91.4%)有相当大的差距。αNLG任务要困难得多——虽然人类可以写出96%的有效解释，但是当前表现最好模型只能达到45%。文章的分析让我们对深度预训练语言模型无法执行的推理类型有了新的见解——尽管预训练模型在NLI蕴涵的密切相关但不同的任务中表现出色，但是在应对基于 <script type="math/tex">\text{ART}</script> 数据集提出的溯因推理和溯因生成任务时，表现却差强人意，这为未来的研究指出了有趣的途径。作者希望ART将成为未来基于语言的溯因推理研究的一个具有挑战性的基准，并且αNLI和αNLG任务将鼓励在人工智能系统中实现复杂推理能力的表征学习。</p>]]></content>
    
    
    <categories>
      
      <category>溯因推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>构建动态知识路径生成器用于常识推理</title>
    <link href="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/"/>
    <url>/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="构建常识问答知识路径生成器"><a href="#构建常识问答知识路径生成器" class="headerlink" title="构建常识问答知识路径生成器"></a>构建常识问答知识路径生成器</h2><h3 id="论文贡献"><a href="#论文贡献" class="headerlink" title="论文贡献"></a>论文贡献</h3><p>  提出学习一个多跳知识路径产生器来根据问题动态产生结构化证据。生成器以预先训练的语言模型为主干，利用语言模型中存储的大量非结构化知识来补充知识库的不完整性。路径生成器生成的这些相关路径被进一步聚合为知识嵌入，并与文本编码器给出的上下文嵌入进行融合。</p><h3 id="论文架构"><a href="#论文架构" class="headerlink" title="论文架构"></a>论文架构</h3><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/1.png" class=""><ul><li><p>从问题和答案选择中提取实体</p></li><li><p>使用构造的路径生成器生成一个多跳知识路径来连接每对问答实体</p><p>生成器学习将问题实体（红色）和选择实体（绿色）与生成的路径连接起来，这些路径充当QA的动态KG。</p></li></ul><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/2.png" class=""><ul><li>将生成的路径聚合为一个知识嵌入，并将其与文本编码器中的上下文嵌入相融合以进行分类。</li></ul><h4 id="识别实体"><a href="#识别实体" class="headerlink" title="识别实体"></a>识别实体</h4><p>从问题选项对中识别出问题中出现的实体和选项中出现的实体</p><ul><li>字符串匹配(论文中实际使用的方法)</li><li>NER(命名实体识别)</li></ul><h4 id="知识路径采样"><a href="#知识路径采样" class="headerlink" title="知识路径采样"></a>知识路径采样</h4><p>使用随机游走从一个常识KG中抽取符号路径，为GPT-2知识路径生成器采样具有代表性的关系路径作为训练的原始数据。</p><p><strong>提高路径质量</strong></p><p>假设使用Random Walk采样的这些样本路径包含和常识问答任务相关的知识，为了保证这些采样路径的质量，制定了两种启发式策略：</p><ul><li><p>保证相关性——定义了一个可能对回答常识问题有帮助的关系类型的子集。例如 {atlocation，isa}。在进行采样之前，丢弃一些被认为是帮助不大甚至无用处的关系类型，这些关系对于回答问题没什么帮助，这些关系包括：relatedto（相关)、synonym（同义）、antonym（反义）、derived-from（派生自）、formof（一种..形式）、etymologicallyderivedfrom（词源派生自） 和 etymologicallyrelatedto（词源相关）。</p></li><li><p>保证信息性——要求采样的路径不包含具有重复关系类型的边，即路径上每条边的关系都是唯一的。</p></li></ul><h5 id="局部采样（帮助生成器生成适用于任务的路径）"><a href="#局部采样（帮助生成器生成适用于任务的路径）" class="headerlink" title="局部采样（帮助生成器生成适用于任务的路径）"></a>局部采样（帮助生成器生成适用于任务的路径）</h5><ul><li>其中<script type="math/tex">E</script> 为实体集，<script type="math/tex">R</script>为关系集，<script type="math/tex">E</script> 由问题实体和选项实体组成，<script type="math/tex">R</script> 为定义的关系集合关系。以此给出静态的知识图(KG)，<script type="math/tex">G=(E,R)</script>。</li><li>随机游走是从任务训练集中的问题和答案选择中出现的实体开始的。随机游走算法进行图 <script type="math/tex">G</script> 上的路径采样，采样的路径形式为<script type="math/tex">({e_{0},r_{0},e_{1},r_{1},\cdots ,r_{T-1},e_{T}})</script>，其中<script type="math/tex">e_{T} \epsilon E</script>，<script type="math/tex">r_{T} \epsilon R</script>，<script type="math/tex">T</script> 为路径跳数</li></ul><h5 id="全局采样（防止生成器偏向生成KG的局部结构的路径）"><a href="#全局采样（防止生成器偏向生成KG的局部结构的路径）" class="headerlink" title="全局采样（防止生成器偏向生成KG的局部结构的路径）"></a>全局采样（防止生成器偏向生成KG的局部结构的路径）</h5><p>从静态KG中随机采样一些实体，并从它们开始进行随机游走，得到一些局部KG以外的路径用于生成器的泛化。</p><p>此外，还为每个关系添加了一个反向关系，这样采样的路径中不光有正向的路径和有反向的路径，这将使得路径生成器更加灵活地连接两个实体。</p><p>除此之外，还对具有混合跳数的路径进行采样，以训练生成器在需要事用可变长的路径来连接实体。对跳数从1到3的路径进行采样，以构造具有混合跳数的路径集。从特定任务数据集的全局采样和局部采样中获得的路径数如下表所示。将这两种抽样策略的路径合并，并进一步将其分成训练/开发/测试集，其比率为 9:0.5:0.5。</p><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/3.png" class=""><h4 id="基于GPT-2的路径生成器构建"><a href="#基于GPT-2的路径生成器构建" class="headerlink" title="基于GPT-2的路径生成器构建"></a>基于GPT-2的路径生成器构建</h4><p>  在随机游走采样的那些路径上对GPT-2进行微调。</p><p>  GPT-2是一种预训练的大容量语言模型，它从庞大的语料库中编码出丰富的非结构化知识。用它来作为路径生成器带来的好处是双重的：</p><ul><li>微调时使用到的结构化知识路径帮助丰富GPT-2，使得它学到按照设计生成具有“常识”风格路径的能力。</li><li>GPT-2从庞大的语料库中编码出的非结构化知识可以缓解KG的稀疏性问题。</li></ul><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/4.png" class=""><h5 id="采样的路径转化为文本化输入"><a href="#采样的路径转化为文本化输入" class="headerlink" title="采样的路径转化为文本化输入"></a><strong>采样的路径转化为文本化输入</strong></h5><p>  GPT-2 使用字节对编码（Byte Pair Encoding）方式来创建词汇表中的词（token），也就是说词（token）其实通常只是单词的一部分。使用GPT2的字节对编码(Byte-Pair Encoding)方法将上一步直接对知识图进行随机游走采样得到的符号路径转换成GPT-2输入的文本形式：</p><script type="math/tex; mode=display">{x}=\left\{X_{0}, Y_{0}, X_{1}, Y_{1}, \ldots, Y_{T-1}, X_{T}\right\}</script><p>  其中，<script type="math/tex">X_{t}=\left\{x_{t}^{0}, x_{t}^{1}, \ldots, x_{t}^{\left|e_{t}\right|}\right\}</script> 是实体 <script type="math/tex">e_{t}</script> 的短语token，而<script type="math/tex">Y_{t}=\left\{y_{t}^{0}, y_{t}^{1}, \ldots, y_{t}^{\left|r_{t}\right|}\right\}</script>是关系 <script type="math/tex">r_{t}</script> 的短语token。<br>  这样生成的文本形式的路径，方可在GPT-2中作为输入。</p><h6 id="字节对编码方法"><a href="#字节对编码方法" class="headerlink" title="字节对编码方法"></a><strong>字节对编码方法</strong></h6><p>  BPE最早是一种数据压缩算法，于2015年被引入到机器翻译领域并很快得到推广。该算法简单有效，因而目前它是最流行的子词表构建方法。GPT-2和RoBERTa使用的Subword算法都是BPE。</p><p>  BPE获得Subword的步骤如下：</p><ul><li>准备足够大的训练语料，并确定期望的Subword词表大小；</li><li>将单词拆分为成最小单元。比如英文中26个字母加上各种符号，这些作为初始词表；</li><li>在语料上统计单词内相邻单元对的频数，选取频数最高的单元对合并成新的Subword单元；</li><li>重复第3步直到达到第1步设定的Subword词表大小或下一个最高频数为1。</li></ul><p>假设有语料集经过统计后表示为{‘l o w &lt;/w&gt;’: 5, ‘l o w e r &lt;/w&gt;’: 2, ‘n e w e s t &lt;/w&gt;’: 6, ‘w i d e s t &lt;/w&gt;’: 3}，其中数字代表的是对应单词在语料中的频数。其中&lt;/w&gt;为终止符，用于区分单词的边界。</p><p>step 1, 最高频连续字节对”e”和”s”出现了6+3=9次，合并成”es”。输出：</p><pre><code class="hljs json">&#123;&#x27;l o w &lt;/w&gt;&#x27;: 5, &#x27;l o w e r &lt;/w&gt;&#x27;: 2, &#x27;n e w es t &lt;/w&gt;&#x27;: 6, &#x27;w i d es t &lt;/w&gt;&#x27;: 3&#125;</code></pre><p>step 2, 最高频连续字节对”es”和”t”出现了6+3=9次, 合并成”est”。输出：</p><pre><code class="hljs json">&#123;&#x27;l o w &lt;/w&gt;&#x27;: 5, &#x27;l o w e r &lt;/w&gt;&#x27;: 2, &#x27;n e w est &lt;/w&gt;&#x27;: 6, &#x27;w i d est &lt;/w&gt;&#x27;: 3&#125;</code></pre><p>step 3, 以此类推，最高频连续字节对为”est”和”&lt;/w&gt;” 输出：</p><pre><code class="hljs json">&#123;&#x27;l o w &lt;/w&gt;&#x27;: 5, &#x27;l o w e r &lt;/w&gt;&#x27;: 2, &#x27;n e w est&lt;/w&gt;&#x27;: 6, &#x27;w i d est&lt;/w&gt;&#x27;: 3&#125;</code></pre><p>……</p><p>step n, 继续迭代直到达到预设的subword词表大小或下一个最高频的字节对出现频率为1。</p><h6 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h6><ul><li><p>编码</p><p>在之前的算法中，已经得到了subword的词表，对该词表按照子词长度由大到小排序。编码时，对于每个单词，遍历排好序的子词词表寻找是否有token是当前单词的子字符串，如果有，则该token是表示单词的tokens之一。</p><p>从最长的token迭代到最短的token，尝试将每个单词中的子字符串替换为token。 最终，我们将迭代所有tokens，并将所有子字符串替换为tokens。 如果仍然有子字符串没被替换但所有token都已迭代完毕，则将剩余的子词替换为特殊token，如<unk>。</p></li></ul><p>例子</p><pre><code class="hljs text">// 给定单词序列[“the&lt;/w&gt;”, “highest&lt;/w&gt;”, “mountain&lt;/w&gt;”]// 假设已有排好序的subword词表[“errrr&lt;/w&gt;”, “tain&lt;/w&gt;”, “moun”, “est&lt;/w&gt;”, “high”, “the&lt;/w&gt;”, “a&lt;/w&gt;”]// 迭代结果&quot;the&lt;/w&gt;&quot; -&gt; [&quot;the&lt;/w&gt;&quot;]&quot;highest&lt;/w&gt;&quot; -&gt; [&quot;high&quot;, &quot;est&lt;/w&gt;&quot;]&quot;mountain&lt;/w&gt;&quot; -&gt; [&quot;moun&quot;, &quot;tain&lt;/w&gt;&quot;]</code></pre><ul><li>解码</li></ul><p>将所有的tokens拼在一起，以<script type="math/tex"></w></script>为界定符。</p><p>例子：</p><pre><code class="hljs python">// 编码序列[“the&lt;/w&gt;”, “high”, “est&lt;/w&gt;”, “moun”, “tain&lt;/w&gt;”]// 解码序列“the&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;”</code></pre><p>通过BPE编码和解码，为采样的路径构造出适合GPT-2的输入的文本格式。</p><h5 id="GPT-2生成器输入构造"><a href="#GPT-2生成器输入构造" class="headerlink" title="GPT-2生成器输入构造"></a>GPT-2生成器输入构造</h5><p>  为了进一步模拟生成器提供一个问题实体和一个选择实体的场景，在每个路径的开始处添加最后一个实体短语标记 <script type="math/tex">x_{T}</script> 和一个单独的标记[SEP]。这样，生成器将知道在生成路径时它应该输出的最后一个实体。</p><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/5.png" class=""><p> 将目标实体 + [SEP]标记 + 起始实体，即灰色部分交给GPT-2生成器来生成连接这两个实体的路径。</p><p>  已知前 <script type="math/tex">t-1</script> 个生成的token <script type="math/tex">s_{<t}</script>，当前第t个位置生成token <script type="math/tex">s_{t}</script> 的概率为：</p><script type="math/tex; mode=display">P\left(s_{t} \mid s_{<t}\right)=\operatorname{softmax}\left(\mathbf{W}_{\text {vocab}} \cdot \mathbf{h}_{\mathrm{t}}\right)</script><p>  这里 <script type="math/tex">h_{t}</script> 表示在解码时GPT-2对 <script type="math/tex">s_{t}</script> 的最终表示， <script type="math/tex">W_{vocab}</script> 是GPT-2使用的词汇表的嵌入矩阵。</p><p>  为了在给定实体对的情况下最大化生成句子 <script type="math/tex">s</script> 的概率，将损失函数定义为：</p><script type="math/tex; mode=display">\mathcal{L}=-\sum_{\mathbf{s}} \log P\left(\mathbf{s} \mid X_{T},[S E P], X_{0}\right)</script><p>  其中，<script type="math/tex">P\left(\mathbf{s} \mid X_{T},[S E P], X_{0}\right)</script> 为条件概率的乘积，另外，由于输入的 <script type="math/tex">X_{0}</script> 和 <script type="math/tex">X_{1}</script> 以及 <script type="math/tex">[SEP]</script>是固定的输入，所以 <script type="math/tex">t</script> 的下标从 <script type="math/tex">|X_{0}|+|X_{1}| + 1</script> 开始。</p><script type="math/tex; mode=display">P\left(\mathbf{s} \mid X_{T},[S E P], X_{0}\right)=\prod_{t=\left|X_{0}\right|+\left|X_{T}\right|+1}^{|\mathbf{s}|} P\left(s_{t} \mid s_{<t}\right)</script><h4 id="文本编码器的选择和构建"><a href="#文本编码器的选择和构建" class="headerlink" title="文本编码器的选择和构建"></a>文本编码器的选择和构建</h4><p>  本文常识问答的框架由两个主要部分组成。第一部分是前面提到的路径生成器。第二部分是一个上下文编码器，它对问题和选择进行编码，以输出一个上下文嵌入 <script type="math/tex">c</script> 作为非结构化证据。</p><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/6.png" class=""><p>  该论文实验采用的文本编码器为BERT和Robert，两种常用的文本输入上下文编码器。问题和选择通过添加一些特殊的标记串接起来，然后输入上下文编码器得到 <script type="math/tex">c</script> 。上下文嵌入 <script type="math/tex">c</script> 和路径生成器生成的路径进行Attention之后，输出一个知识嵌入 <script type="math/tex">p</script> 作为结构化证据。最后，这两类证据被输入分类器，为每个选择输出一个似然性得分。</p><h5 id="KE-知识嵌入-模块"><a href="#KE-知识嵌入-模块" class="headerlink" title="KE(知识嵌入)模块"></a>KE(知识嵌入)模块</h5><p>路径生成器GPT-2为每对问题选项生成一条最终的推理路径，对于生成的这些长度不一的离散路径，将GPT-2中最后一层隐藏状态的平均值 <script type="math/tex">p_{k}</script> 作为路径嵌入，从而最大限度地利用路径生成器。</p><script type="math/tex; mode=display">\mathbf{p}_{\mathbf{k}}=\operatorname{MEAN}\left(\left\{\mathbf{h}_{\mathbf{0}}, \mathbf{h}_{\mathbf{1}}, \ldots, \mathbf{h}_{\mathbf{T}}\right\}\right)</script><p>  由于GPT-2已经在一个大型语料库上进行了预训练，这样的表示应该足以保存路径的信息。</p><p>  由于并非所有的路径都会对决定哪个选择是正确答案做出同等贡献，所以我们利用非结构化证据，即上面提到的上下文嵌入c作为编码这种结构化证据的指导。</p><script type="math/tex; mode=display">\mathbf{p}=W_{p r o j} \cdot \sum_{k} \alpha_{k} \mathbf{p}_{k}</script><p>  其中 <script type="math/tex">W_{proj}</script> 是个可学习的映射矩阵，<script type="math/tex">\alpha_{k}</script> 为每条路径嵌入的注意力权重，其计算公式如下：</p><script type="math/tex; mode=display">\alpha_{k}=\frac{\exp \left(s_{k}\right)}{\sum_{k^{\prime}} \exp \left(s_{k^{\prime}}\right)}</script><p>  其中，<script type="math/tex">s_{k}</script> 的计算公式如下，注意力网络由 <script type="math/tex">W_{att}</script> 和 <script type="math/tex">b_{att}</script> 参数化</p><script type="math/tex; mode=display">s_{k}=\mathbf{c}^{\top} \tanh \left(\mathbf{W}_{a t t} \cdot \mathbf{p}_{k}+\mathbf{b}_{a t t}\right)</script><h5 id="融合异质信息进行分类"><a href="#融合异质信息进行分类" class="headerlink" title="融合异质信息进行分类"></a>融合异质信息进行分类</h5><p>  分类器利用路径生成器产生的路径嵌入 <script type="math/tex">p</script> 和文本编码器产生的非结构化的问题选项的上下文嵌入 <script type="math/tex">c</script> 来计算问题选择对的似然性。</p><p>  <strong>如何计算似然性</strong>？</p><p>  将 <script type="math/tex">c</script> 和 <script type="math/tex">p</script> 连接起来，并将它们提供给最终的线性分类层为每个问题选项对获取一个最终得分，这里涉及一个线性变换：</p><script type="math/tex; mode=display">f(q, a)=\mathbf{W}_{c l s} \cdot[\mathbf{c} ; \mathbf{p}]+\mathbf{b}_{c l s}</script><p>  最后通过一个softmax层对得分进行标准化，得到所有选择的最终概率。</p><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><h4 id="Pre-trained-LM"><a href="#Pre-trained-LM" class="headerlink" title="Pre-trained LM"></a><strong>Pre-trained LM</strong></h4><ul><li><p>BERT</p></li><li><p>RoBERTa</p><p>在该论文的框架中，使用了RoBERTa最后一层隐藏状态的平均池作为上下文嵌入，并将其输入到线性分类器以获得分数。</p></li></ul><h4 id="KG"><a href="#KG" class="headerlink" title="KG"></a><strong>KG</strong></h4><ul><li>静态KG，例如KagNet和RGCN</li><li>动态KG，该论文使用到的GPT-2路径动态生成</li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/7.png" class=""><p>当使用RoBERTa作为上下文编码器以及上面提及的路径生成器之后，模型在CSQA的表现同baseline相比是最好的，但是当使用BERT作为上下文编码器时，表现并没有优于所有使用静态KG的模型。这是方法的局限性，在某种程度上仍然依赖上下文编码器来聚合具有注意机制的路径。如何设计一个与文本模块耦合较少的路径生成器是今后的工作。</p><p>​    </p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>  该论文提出了一种生成多跳知识路径的生成器，作为回答常识问题的结构化证据。为了学习这样一个路径生成器，微调了GPT-2，从一个常识KG中随机抽取样本。然后生成器将每对问答实体用一条知识路径连接起来。这些路径被进一步聚合为知识嵌入，并与文本编码器给出的上下文嵌入进行融合。在两个基准数据集上的实验结果表明，该论文的框架在性能上优于强预训练语言模型和静态KG增强方法。除此之外，还证明了所生成的路径在信息性和帮助性方面是可以解释的。未来的工作包括如何将生成器与文本编码器解耦，以及如何更好地融合知识。</p><h3 id="感谢"><a href="#感谢" class="headerlink" title="感谢"></a>感谢</h3><ul><li>BPE字节对编码方法的内容摘自文章：<a href="https://zhuanlan.zhihu.com/p/86965595">https://zhuanlan.zhihu.com/p/86965595</a></li><li>论文地址：<a href="https://arxiv.org/pdf/2005.00691.pdf">《Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering》</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>融合异构知识在图上进行常识推理</title>
    <link href="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/"/>
    <url>/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="融合异构知识进行常识问答"><a href="#融合异构知识进行常识问答" class="headerlink" title="融合异构知识进行常识问答"></a>融合异构知识进行常识问答</h2><p>论文标题 —— 《Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering》<br><a href="https://arxiv.org/pdf/1909.05311v2.pdf">论文来源</a><br><a href="https://github.com/DecstionBack/AAAI_2020_CommonsenseQA">论文代码</a></p><h3 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h3><h4 id="任务概述"><a href="#任务概述" class="headerlink" title="任务概述"></a>任务概述</h4><p>以CSQA（常识问答）为例，针对未提及背景知识的问题，要求考虑背景知识并作出回答</p><h4 id="任务形式"><a href="#任务形式" class="headerlink" title="任务形式"></a>任务形式</h4><p><strong>输入：</strong>问题Q=q_1 q_2⋯q_m和包含n个答案的候选答案集合A={a_1,a_2,⋯,a_n}<br><strong>目标：</strong>从候选集合中选出正确答案<br><strong>评价指标：</strong>准确率</p><h3 id="面临的问题"><a href="#面临的问题" class="headerlink" title="面临的问题"></a>面临的问题</h3><ul><li><p>在与问题相关的背景知识中如何获取evidence信息（抽取三元组，为知识源构建图）</p></li><li><p>如何基于获取到的evidence信息做出预测（图表示学习+图推理来解决）</p></li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/1.png" class=""><h4 id="从外部知识库抽取evidence"><a href="#从外部知识库抽取evidence" class="headerlink" title="从外部知识库抽取evidence"></a>从外部知识库抽取evidence</h4><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>人工标注——耗时耗力耗财</p></li><li><p>仅从同构（结构化/非结构化）知识源中抽取evidence——没有同时利用不同来源的知识，得到的evidence可能不够全面</p></li><li><p>融合结构化与非结构化知识库中的知识，例如融合结构化的ConceptNet库和纯文本的Wikipedia库，并从中抽取evidence</p></li></ol><h5 id="具体实施"><a href="#具体实施" class="headerlink" title="具体实施"></a>具体实施</h5><p>从ConceptNet中抽取</p><ol><li><p>在ConceptNet中确定不同的问题和选项中出现的实体；</p></li><li><p>从ConceptNet中抽取从问题中的实体到候选中的实体的路径（小于 3 hops）</p></li></ol><p>从Wikipedia中抽取</p><ol><li><p>使用 Spacy 从中抽取出 107M 个句子，并用 Elastic Search 工具构建句子索引；</p></li><li><p>对于每个训练样例，去除问句和候选中的停用词，然后将所有词串联，作为检索查询 ；</p></li><li><p>使用 Elastic 搜索引擎 在检索查询和所有句子之间进行排序，选择出 top-K 个句子作为 Wikipedia 提供的证据信息（在实验中 K=10）；</p></li></ol><h4 id="为每个知识源构建图"><a href="#为每个知识源构建图" class="headerlink" title="为每个知识源构建图"></a>为每个知识源构建图</h4><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><ol><li><p>对于ConceptNet库，用其自身的三元组即可</p></li><li><p>对于Wikipedia库，通过语义角色标注SRL(semantic role labeling)来抽取句子中的三元组</p></li></ol><h5 id="具体实施-1"><a href="#具体实施-1" class="headerlink" title="具体实施"></a>具体实施</h5><p><strong>构建ConceptNet图</strong></p><ol><li><p>把从ConceptNet中抽取出的路径拆分成三元组的形式，将每个三元组看做一个节点，融合到图中；对于含有相同实体的三元组，给图中对应到的节点加上一条边；</p></li><li><p>为了获取ConceptNet中节点的上下文词表示，将三元组根据关系模板转化为自然语言语句；</p></li></ol><p><strong>构建Wikipedia图</strong></p><ol><li><p>使用SRL抽出句子中的每个谓词的论元，谓词和论元作为节点，它们之间的关系作为边</p></li><li><p>同样地，为了增强构建图的连通性，基于两条给定的规则进行节点a,b之间的加边：</p><ul><li>b 中包含 a 且 a 的词数大于3</li><li>a 与 b 仅有一个不同的词，并且 a 和 b 包含的词数都大于3</li></ul></li></ol><h4 id="编码图信息、聚集evidence信息"><a href="#编码图信息、聚集evidence信息" class="headerlink" title="编码图信息、聚集evidence信息"></a>编码图信息、聚集evidence信息</h4><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/2.png" class=""><h5 id="具体实施-2"><a href="#具体实施-2" class="headerlink" title="具体实施"></a>具体实施</h5><ol><li><p>利用Topology Sort算法，根据知识抽取部分得到的图结构,对evidence句的顺序进行重排；<br>利用得到的图的结构，通过重定义evidence词之间的相对位置，来让语义相关的词的相对位置更加接近；<br>利用evidence内部的关系结构获取更好的上下文表示；</p></li><li><p>排好顺序的从ConceptNet库、Wikipedia库中抽出的evidence句、问题、所有选项<br>以上4个部分的串接，在使用了[sep]进行分隔后，作为XLNet的输入进行编码</p></li></ol><h4 id="进行最终的预测"><a href="#进行最终的预测" class="headerlink" title="进行最终的预测"></a>进行最终的预测</h4><h5 id="具体实施-3"><a href="#具体实施-3" class="headerlink" title="具体实施"></a>具体实施</h5><ul><li><p>把两个evidence图看作一个无向图，利用GCN对知识图和XLNet编码提供的问答+evidence的词级向量表示，来进行编码来获得节点层次的表示</p></li><li><p>evidence传播：</p><ul><li>从邻居节点聚集信息；</li><li>组合、更新节点表示</li></ul></li><li><p>利用图注意力网络对经过GCN得到的节点表示以及XLNet的input表示进行处理，聚集图级别的表示，进而进行最终的预测打分</p></li></ul><h3 id="重点模块及方法阐述"><a href="#重点模块及方法阐述" class="headerlink" title="重点模块及方法阐述"></a>重点模块及方法阐述</h3><h4 id="SRL"><a href="#SRL" class="headerlink" title="SRL"></a>SRL</h4><p>语义角色标注（Semantic Role Labeling，SRL）以句子的谓词为中心，不对句子所包含的语义信息进行深入分析，只分析句子中各成分与谓词之间的关系，即句子的谓词（Predicate）- 论元（Argument）结构。并用语义角色来描述这些结构关系，是许多自然语言理解任务（如信息抽取，篇章分析，深度问答等）的一个重要中间步骤。在研究中一般都假定谓词是给定的，所要做的就是找出给定谓词的各个论元和它们的语义角色。</p><h4 id="ConceptNet"><a href="#ConceptNet" class="headerlink" title="ConceptNet"></a>ConceptNet</h4><p>ConceptNet：常识知识库，它以三元组形式的关系型知识构成。</p><h4 id="ElaticSearch"><a href="#ElaticSearch" class="headerlink" title="ElaticSearch"></a>ElaticSearch</h4><p>ElasticSearch：一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，是当前流行的企业级搜索引擎。</p><h4 id="Topology-Sort"><a href="#Topology-Sort" class="headerlink" title="Topology Sort"></a>Topology Sort</h4><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/3.png" class=""><ul><li><p><strong>处理ConceptNet</strong></p><p>将三元组转化为自然语句，例如，(mammals, HasA, hair) -&gt; mammals has hair</p></li><li><p><strong>处理Wikipedia</strong></p><p>以evidence句作为句子图中的节点来构建句子图，如果在构建wikipedia图的过程中，节点p和q分别在句子s和t中，则为句子图中的代表两个相应句子的节点添加一条边。<br>利用拓扑排序算法对这些构建的句子图中的节点进行排序。</p></li></ul><h4 id="XLNET"><a href="#XLNET" class="headerlink" title="XLNET"></a>XLNET</h4><p><strong>使用XLNet而不采用BERT的原因，总结起来有以下几点：</strong></p><ul><li><p>BERT训练数据和测试数据之间的不一致性，这也叫作Discrephancy。当我们训练BERT的时候，<br> 会随机的Mask掉一些单词的，但实际上在使用的过程当中，我们却没有MASK这类的标签，<br> 所以这个问题就导致训练的过程和使用（测试）的过程其实不太一样，这是一个主要的问题。</p></li><li><p>BERT并不能用来生成数据。由于BERT本身是依赖于DAE的结构来训练的，所以不像那些基于语言模型训练出来的模型具备很好地生成能力。<br> 之前的方法比如NNLM，ELMo是基于语言模型生成的，所以用训练好的模型可以生成出一些句子、文本等。<br> 但基于这类生成模型的方法论本身也存在一些问题，因为理解一个单词在上下文里的意思的时候，语言模型只考虑了它的上文，而没有考虑下文！</p></li></ul><p>基于这些BERT的缺点，学者们提出了XLNet, 而且也借鉴了语言模型，还有BERT的优缺点。具体做法如下：</p><ul><li><p>首先，生成模型是单向的，即便我们使用Bidirectional LSTM类模型，其实本质是使用了两套单向的模型。<br> 通过使用permutation language model, 也就是把所有可能的permutation全部考虑进来。</p></li><li><p>另外，为了迎合这种改变，他们在原来的Transformer Encoder架构上做了改进，引入双流注意力机制,<br> 而且为了更好地处理较长的文本，进而使用的是Transformer-XL。 </p></li></ul><h4 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h4><p>图卷积神经网络，实际上跟CNN的作用一样，就是一个特征提取器，只不过它的对象是图数据（结构十分不规则，数据不具有平移不变性，<br>这让适用于处理图片、语言这类欧氏空间数据的传统的CNN、RNN瞬间失效）。</p><p>GCN精妙地设计了一种从图数据中提取特征的方法，从而让我们可以使用这些特征去对图数据进行节点分类<br>（node classification）、图分类（graph classification）、边预测（link prediction），还可以顺便得到图的嵌入表示（graph embedding）。</p><p>在Step 4对evidence图进行编码的过程，实际上就相当于对图数据进行了特征的提取。</p><p>GCN也是一个神经网络层，层与层之间的传播方式如下（利用了拉普拉斯矩阵）：</p><script type="math/tex; mode=display">H^{l+1}=\sigma\left(\widetilde{D}^{-\frac{1}{2}} \tilde{A} \widetilde{D}^{-\frac{1}{2}} H^{l} W^{l}\right)</script><p>需要说明的是，<script type="math/tex">\tilde{A}=A+I</script>为图的邻接矩阵，I为单位阵。<script type="math/tex">\tilde{D}</script> 为 <script type="math/tex">\tilde{A}</script> 的度矩阵。<script type="math/tex">H</script> 为每一层的特征。对于输入层 <script type="math/tex">H=X</script>。</p><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/4.png" class=""><p>若构造一个两层的GCN来进行分类任务，激活函数分别采用ReLU和softmax，则整体的正向传播公式为：</p><script type="math/tex; mode=display">\mathrm{Z}=\mathrm{f}(\mathrm{X}, \mathrm{A})=\operatorname{softmax}\left(\tilde{A} \operatorname{Re} L U\left(\tilde{A} X W^{(0)}\right) W^{(1)}\right)</script><p>上图中的GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，node之间的连接关系，即A，都是共享的。</p><p>GCN的特别之处：即使不训练，完全使用随机初始化的参数W，GCN提取出来的特征就已经非常优秀了！</p><h4 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h4><p>和所有的attention mechanism一样，GAT的计算也分为两步走：</p><ul><li>计算注意力系数；对于顶点i，注意计算它与它的邻接节点的相似系数</li></ul><script type="math/tex; mode=display">  e_{i j}=a\left(W \overrightarrow{h_{i}}, W \overrightarrow{h_{j}}\right)</script><p>其中共享参数W的线性映射给顶点的特征进行了增强，a(·)把拼接后的高维特征映射到一个实数上，这个过程一般通过一个单层的前馈神经网络来实现.对相关系数用softmax进行归一化便得到了注意力系数。 要理解计算过程可见下图。</p><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/5.png" class=""><ul><li>加权求和。把计算好的注意力系数进行加权求和，加上多头机制进行增强</li></ul><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/6.png" class=""><h4 id="GCN与GAT的异同"><a href="#GCN与GAT的异同" class="headerlink" title="GCN与GAT的异同"></a>GCN与GAT的异同</h4><ul><li><strong>同</strong>：GCN与GAT都是将邻居顶点的特征聚合到中心顶点上（一种aggregate运算），利用graph上的局部平稳性学习新的顶点特征表达。</li><li><strong>异</strong>：GCN利用了拉普拉斯矩阵，GAT利用attention系数。</li></ul><h5 id="为什么要融合异构知识源？"><a href="#为什么要融合异构知识源？" class="headerlink" title="为什么要融合异构知识源？"></a>为什么要融合异构知识源？</h5><ul><li><strong>结构化知识</strong> (Structured Knowledge Source)：包含大量的三元组信息（概念及其之间的关系），利于推理，但是存在覆盖度低的问题；</li><li><strong>非结构化知识</strong> (Unstructured Knowledge Source)：即 Plain-Text，包含大量冗余的、覆盖范围广的信息，可以辅助/补充结构化知识；</li></ul><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/7.png" class=""><p>在结构化知识和非结构化知识的协同作用下，模型选出了最佳答案。</p>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>B站弹幕爬取</title>
    <link href="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/"/>
    <url>/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h3 id="B站弹幕爬取"><a href="#B站弹幕爬取" class="headerlink" title="B站弹幕爬取"></a>B站弹幕爬取</h3><h4 id="单个视频弹幕的爬取"><a href="#单个视频弹幕的爬取" class="headerlink" title="单个视频弹幕的爬取"></a>单个视频弹幕的爬取</h4><pre><code>B站弹幕都是以xml文件的形式存在的，而xml文件的请求地址是如下形式：</code></pre><pre><code class="hljs html">http://comment.bilibili.com/233182992.xml</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/1.png" class=""><pre><code>其中，**233182992**是**cid**，这个需要从原视频的网页中获取。获取了**cid**之后，就可以按照上述的形式拼接请求地址，发送**get**请求，获取对应的xml文件。</code></pre><h5 id="cid获取"><a href="#cid获取" class="headerlink" title="cid获取"></a>cid获取</h5><pre><code>以华农兄弟的某个视频为例，进入视频主页。</code></pre><ul><li>右键启用<strong>检查模式</strong></li><li>选择<strong>网络</strong>(Network)，刷新网页</li><li>点开第一个文件，选择<strong>响应</strong>(response)</li><li>使用<strong>CTRL + F</strong>进行字段查找，输入<strong>“cid:”</strong>，发现匹配到的第一个cid就是视频的cid</li></ul><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/2.png" class=""><pre><code>接下来，就是如何从视频主页返回的网页信息中**提取cid**。</code></pre><ul><li>确定视频的<strong>bv号</strong> </li><li>根据bv号确定请求地址 </li><li>使用<strong>正则表达式</strong>从网页返回的文本中匹配cid</li><li>根据拿到的cid请求<strong>获取xml</strong>文件</li></ul><h5 id="xml文件解析"><a href="#xml文件解析" class="headerlink" title="xml文件解析"></a>xml文件解析</h5><pre><code>获取到xml文件之后，需要从xml文件中提取出弹幕文本。调用lxml库中的etree类，etree.HTML()可以用来解析字符串格式的HTML文档对象，将传进去的字符串转变成Element对象。作为Element对象，可以方便的使用getparent()、remove()、xpath()等方法。这里使用xpath来提取需要的那部分弹幕文本。</code></pre><h5 id="爬虫封装"><a href="#爬虫封装" class="headerlink" title="爬虫封装"></a>爬虫封装</h5><p>完整代码如下：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> re<span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BiliBiliDanMu</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, bv, filename</span>):</span>        <span class="hljs-comment"># 根据bv号构造要爬取的视频url地址</span>        self.video_url = <span class="hljs-string">&quot;https://bilibili.com/video/BV&quot;</span> + bv        self.filename = filename        self.headers = &#123;            <span class="hljs-string">&quot;User-Agent&quot;</span>: <span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)\</span><span class="hljs-string">             AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44&quot;</span>        &#125;    <span class="hljs-comment"># 获取视频的cid</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_video_cid</span>(<span class="hljs-params">self</span>):</span>        response = requests.get(self.video_url, headers=self.headers)        html = response.content.decode()        cid = re.findall(<span class="hljs-string">r&#x27;(&quot;cid&quot;:)([0-9]+)&#x27;</span>, html)        <span class="hljs-comment"># 有的视频没有这个字段，我们跳过它</span>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(cid) == <span class="hljs-number">0</span>:            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>        <span class="hljs-keyword">else</span>:            <span class="hljs-keyword">return</span> cid[<span class="hljs-number">0</span>][<span class="hljs-number">-1</span>]    <span class="hljs-comment"># 获取请求弹幕xml文件返回的内容</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_content</span>(<span class="hljs-params">self, xml_url</span>):</span>        response = requests.get(xml_url, headers=self.headers)        <span class="hljs-keyword">return</span> response.content    <span class="hljs-comment"># 解析获取到的内容，得到包含视频所有弹幕的列表</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_danmu</span>(<span class="hljs-params">self, content_str</span>):</span>        html = etree.HTML(content_str)        danmu_list = html.xpath(<span class="hljs-string">&quot;//d/text()&quot;</span>)        <span class="hljs-keyword">return</span> danmu_list    <span class="hljs-comment"># 将弹幕逐行写入并保存为txt文件</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span>(<span class="hljs-params">self, save_items</span>):</span>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(self.filename, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:            lines = []            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> save_items:                lines.append(item + <span class="hljs-string">&#x27;\n&#x27;</span>)            f.writelines(lines)    <span class="hljs-comment"># 爬虫的过程封装</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl</span>(<span class="hljs-params">self</span>):</span>        cid = self.get_video_cid()        <span class="hljs-comment"># 跳过没有cid字段的视频</span>        <span class="hljs-keyword">if</span> cid <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:            xml_url = <span class="hljs-string">&quot;http://comment.bilibili.com/&quot;</span> + <span class="hljs-built_in">str</span>(cid) + <span class="hljs-string">&quot;.xml&quot;</span>            content_str = self.get_content(xml_url)            danmu_lst = self.extract_danmu(content_str)            self.save(danmu_lst)        <span class="hljs-keyword">else</span>:            <span class="hljs-keyword">pass</span><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    bv = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;请输入视频的bv号: &quot;</span>)    dm = BiliBiliDanMu(bv, <span class="hljs-string">&#x27;./output/&#123;&#125;.txt&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">str</span>(bv)))    dm.crawl()</code></pre><h4 id="up主所有视频的弹幕爬取"><a href="#up主所有视频的弹幕爬取" class="headerlink" title="up主所有视频的弹幕爬取"></a>up主所有视频的弹幕爬取</h4><pre><code>仍然以华农兄弟的视频为例，进入华农兄弟的个人空间的视频页，地址如下：</code></pre><pre><code class="hljs html">https://space.bilibili.com/250858633/video</code></pre><h5 id="视频页数和up名字获取"><a href="#视频页数和up名字获取" class="headerlink" title="视频页数和up名字获取"></a>视频页数和up名字获取</h5><pre><code>仍然启用网页检查，来看我们需要的信息究竟该如何请求。首先，选中网络中的**XHR选项**，刷新页面，点击出现的**search**文件，点击响应，**左键连击3次**，选中响应返回的全部数据，其实，这里返回的就是一个**json文件**。</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/3.png" class=""><pre><code>我们使用一个在线工具来看看这个json文件的结构：[json工具](http://json.cn/)</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/4.png" class=""><pre><code>从这个结构里可以看到，**tlist字段**下包含了三类视频的类型id及数目(**count字段**)。而视频页的**最大固定展示数目为30**，因此，我们通过一个简单的计算就可以得到up主视频的总页数。由页数，也就能确定**循环请求的次数**。请求的**url地址**如下：</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/5.png" class=""><pre><code class="hljs html">https://api.bilibili.com/x/space/arc/search？mid=250858633&amp;ps=30&amp;tid=0&amp;pn=1&amp;keyword=&amp;order=pubdate&amp;jsonp=jsonp</code></pre><pre><code>其中，**mid**为up主的id号，**pn**为视频页号。</code></pre><h5 id="视频bv号批量获取"><a href="#视频bv号批量获取" class="headerlink" title="视频bv号批量获取"></a>视频bv号批量获取</h5><pre><code>从上述方式获取到的json文件中，我们可以不仅可以推断视频页的**总页数**，还能获取到当前页**所有视频的BV号以及作者信息**，根据BV号就能使用前面获取单个视频弹幕的代码来逐一获取当前页号下所有视频的弹幕了。</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/6.png" class=""><h5 id="爬虫封装-1"><a href="#爬虫封装-1" class="headerlink" title="爬虫封装"></a>爬虫封装</h5><p>完整代码如下：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> json<span class="hljs-keyword">import</span> re<span class="hljs-keyword">import</span> os<span class="hljs-keyword">from</span> bilibili_danmu <span class="hljs-keyword">import</span> BiliBiliDanMuuper_name = <span class="hljs-literal">None</span><span class="hljs-comment"># 获取某个up主的全部视频的弹幕</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AllBv</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, up_id</span>):</span>        self.up_id = up_id        self.headers = &#123;            <span class="hljs-string">&quot;User-Agent&quot;</span>: <span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)\</span><span class="hljs-string">                     AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44&quot;</span>        &#125;    <span class="hljs-comment"># 获取视频总页数</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_num</span>(<span class="hljs-params">self</span>):</span>        url = <span class="hljs-string">&#x27;https://api.bilibili.com/x/space/arc/search?mid=&#123;&#125;\</span><span class="hljs-string">        &amp;ps=30&amp;tid=0&amp;pn=1&amp;keyword=&amp;order=pubdate&amp;jsonp=jsonp&#x27;</span>.<span class="hljs-built_in">format</span>(self.up_id)        response = requests.get(url=url, headers=self.headers)        json_dict = json.loads(response.content.decode())        video_dict = json_dict[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-string">&#x27;tlist&#x27;</span>]        total_videos = <span class="hljs-number">0</span>        <span class="hljs-keyword">global</span> uper_name        <span class="hljs-keyword">for</span> _, v <span class="hljs-keyword">in</span> video_dict.items():            total_videos += v[<span class="hljs-string">&#x27;count&#x27;</span>]        <span class="hljs-keyword">for</span> comment <span class="hljs-keyword">in</span> json_dict[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-string">&#x27;vlist&#x27;</span>]:            <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(comment[<span class="hljs-string">&#x27;mid&#x27;</span>]) == self.up_id:                uper_name = comment[<span class="hljs-string">&#x27;author&#x27;</span>]            <span class="hljs-keyword">else</span>:                <span class="hljs-keyword">continue</span>        <span class="hljs-comment"># 每页最多30个视频</span>        <span class="hljs-keyword">return</span> uper_name, <span class="hljs-built_in">int</span>(total_videos / <span class="hljs-number">30</span> + <span class="hljs-number">1</span>)    <span class="hljs-comment"># 获取返回的json</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_json</span>(<span class="hljs-params">self, total_pages</span>):</span>        json_dict_lst = []        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, total_pages + <span class="hljs-number">1</span>):            url = <span class="hljs-string">&#x27;https://api.bilibili.com/x/space/arc/search?mid=&#123;&#125;&amp;ps=30&amp;tid=0&amp;pn=&#123;&#125; \</span><span class="hljs-string">            &amp;keyword=&amp;order=pubdate&amp;jsonp=jsonp&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">str</span>(self.up_id), <span class="hljs-built_in">str</span>(i))            response = requests.get(url=url, headers=self.headers)            json_dict_lst.append(json.loads(response.content.decode()))        <span class="hljs-keyword">return</span> json_dict_lst    <span class="hljs-comment"># 从json文件中获取bv号列表</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_bv_from_json</span>(<span class="hljs-params">self, json_dict</span>):</span>        v_lst = json_dict[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-string">&#x27;vlist&#x27;</span>]        bv_lst = []        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> v_lst:            bv_lst.append(item[<span class="hljs-string">&#x27;bvid&#x27;</span>][<span class="hljs-number">2</span>:])        <span class="hljs-keyword">return</span> bv_lst    <span class="hljs-comment"># 将得到的bv号列表存到一个txt文件中，文件夹名字以up主名字命名</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_bv_lst</span>(<span class="hljs-params">self, bv_lst, au_name</span>):</span>        folder = au_name        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(folder):            os.mkdir(folder)        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(au_name + <span class="hljs-string">&#x27;/bv_lst.txt&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:            lines = []            <span class="hljs-keyword">for</span> bv_id <span class="hljs-keyword">in</span> bv_lst:                lines.append(bv_id + <span class="hljs-string">&#x27;\n&#x27;</span>)            f.writelines(lines)    <span class="hljs-comment"># 封装爬取过程，返回up主的名字和所有视频的bv号列表</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl</span>(<span class="hljs-params">self</span>):</span>        up_name, pages_total = self.get_pages_num()        bv_video_lst = []        json_dict_lst = self.get_pages_json(pages_total)        <span class="hljs-keyword">for</span> json_file <span class="hljs-keyword">in</span> json_dict_lst:            bv_lst = self.get_bv_from_json(json_file)            bv_video_lst = bv_video_lst + bv_lst            self.save_bv_lst(bv_lst, <span class="hljs-string">&#x27;./&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(up_name))        <span class="hljs-keyword">return</span> up_name, bv_video_lst<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    up_id = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;please input up_id: &quot;</span>)    <span class="hljs-comment"># 实例化</span>    abm = AllBv(up_id)    author_name, bv_video_list = abm.crawl()    <span class="hljs-comment"># 借助单独一个bv视频弹幕爬取的类BiliBiliDanMu进行弹幕的爬取</span>    <span class="hljs-keyword">for</span> bv <span class="hljs-keyword">in</span> bv_video_list:        bm = BiliBiliDanMu(bv, <span class="hljs-string">&#x27;./&#123;&#125;/&#123;&#125;.txt&#x27;</span>.<span class="hljs-built_in">format</span>(author_name, <span class="hljs-built_in">str</span>(bv)))        bm.crawl()</code></pre><h4 id="制作词云"><a href="#制作词云" class="headerlink" title="制作词云"></a>制作词云</h4><pre><code class="hljs python"><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud<span class="hljs-keyword">import</span> jieba<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-comment"># 1:打开词云文本</span>txt = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./a.txt&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).read()<span class="hljs-comment"># 2:用jieba进行分词</span>txt_cut = <span class="hljs-string">&quot;&quot;</span>.join(jieba.cut(txt, cut_all=<span class="hljs-literal">False</span>) )<span class="hljs-comment"># 3:设置词云的属性</span>font = <span class="hljs-string">&quot;C:\\Windows\\Fonts\\simkai.TTF&quot;</span>     <span class="hljs-comment"># 词云的中文字体所在路径，不设置字体的话，很可能出现乱码</span>wc = WordCloud(font_path=font,               background_color=<span class="hljs-string">&quot;white&quot;</span>,               height=<span class="hljs-number">800</span>,               width=<span class="hljs-number">1000</span>               )<span class="hljs-comment"># 4:生成词云</span>wc.generate(txt_cut)<span class="hljs-comment"># 5:存储词云</span>wc.to_file(<span class="hljs-string">&quot;./demo.png&quot;</span>)</code></pre><p>效果图如下：</p><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/7.png" class="">]]></content>
    
    
    <categories>
      
      <category>爬虫</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker安装部署neo4j</title>
    <link href="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/"/>
    <url>/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/</url>
    
    <content type="html"><![CDATA[<h3 id="docker部署neo4j"><a href="#docker部署neo4j" class="headerlink" title="docker部署neo4j"></a>docker部署neo4j</h3><p>环境：ubuntu16.04LTS</p><h4 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h4><p>详见：<a href="https://www.runoob.com/docker/ubuntu-docker-install.html">菜鸟教程(docker安装)</a></p><h4 id="docker国内镜像源配置"><a href="#docker国内镜像源配置" class="headerlink" title="docker国内镜像源配置"></a>docker国内镜像源配置</h4><p>第一步，进入<a href="https://cr.console.aliyun.com/">阿里云</a>，登陆后点击左侧的镜像加速，生成自己的镜像加速地址。</p><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/%E9%98%BF%E9%87%8C%E4%BA%91%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E5%9C%B0%E5%9D%80%E7%94%9F%E6%88%90.png" class="" title="阿里云镜像加速"><p>第二步，选择ubuntu，执行阿里云推荐的终端命令，即可更新docker的镜像源为阿里云镜像。</p><h4 id="docker部署neo4j-1"><a href="#docker部署neo4j-1" class="headerlink" title="docker部署neo4j"></a>docker部署neo4j</h4><h5 id="拉取neo4j镜像"><a href="#拉取neo4j镜像" class="headerlink" title="拉取neo4j镜像"></a>拉取neo4j镜像</h5><p>第一步，从镜像源中找合适的镜像</p><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> search neo<span class="hljs-number">4</span>j</code></pre><p>第二步，拉取镜像源</p><pre><code class="hljs gcode">docker pull <span class="hljs-symbol">neo4</span>j<span class="hljs-comment">(:版本号)</span> <span class="hljs-comment">//缺省 “:版本号” 时默认安装latest版本的</span></code></pre><p>第三步，查看本地镜像，检验是否拉取成功</p><pre><code class="hljs ebnf"><span class="hljs-attribute">docker images</span></code></pre><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/%E6%9C%AC%E5%9C%B0%E9%95%9C%E5%83%8F.png" class="" title="本地镜像"><h5 id="构建neo4j容器"><a href="#构建neo4j容器" class="headerlink" title="构建neo4j容器"></a>构建neo4j容器</h5><p>第一步，在你根目录的任意一个子目录（我这里是/home)下建立四个基本的文件夹</p><ul><li>data——数据存放的文件夹</li><li>logs——运行的日志文件夹</li><li>conf——数据库配置文件夹（在配置文件<strong>neo4j.conf</strong>中配置包括开放远程连接、设置默认激活的数据库）</li><li>import——为了大批量导入csv来构建数据库，需要导入的节点文件<strong>nodes.csv</strong>和关系文件<strong>rel.csv</strong>需要放到这个文件夹下）</li></ul><pre><code class="hljs haml">docker run -d --name container_name \  //-d表示容器后台运行 --name指定容器名字-<span class="ruby">p <span class="hljs-number">7474</span><span class="hljs-symbol">:</span><span class="hljs-number">7474</span> -p <span class="hljs-number">7687</span><span class="hljs-symbol">:</span><span class="hljs-number">7687</span> \  /<span class="hljs-regexp">/映射容器的端口号到宿主机的端口号</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">data:</span>/data \  /<span class="hljs-regexp">/把容器内的数据目录挂载到宿主机的对应目录下</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">logs:</span>/logs \  /<span class="hljs-regexp">/挂载日志目录</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">conf:</span>/var/lib/neo4j/conf   /<span class="hljs-regexp">/挂载配置目录</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">import:</span>/var/lib/neo4j/import \  /<span class="hljs-regexp">/挂载数据导入目录</span></span><span class="ruby">--env NEO4J_AUTH=neo4j/password \  /<span class="hljs-regexp">/设定数据库的名字的访问密码</span></span><span class="ruby">neo4j /<span class="hljs-regexp">/指定使用的镜像</span></span></code></pre><p>一个可以直接复制粘贴到终端执行的代码模板</p><pre><code class="hljs awk">docker run -d --name container_name -p <span class="hljs-number">7474</span>:<span class="hljs-number">7474</span> -p <span class="hljs-number">7687</span>:<span class="hljs-number">7687</span> -v <span class="hljs-regexp">/home/</span>neo4j<span class="hljs-regexp">/data:/</span>data -v <span class="hljs-regexp">/home/</span>neo4j<span class="hljs-regexp">/logs:/</span>logs -v <span class="hljs-regexp">/home/</span>neo4j<span class="hljs-regexp">/conf:/</span>var<span class="hljs-regexp">/lib/</span>neo4j<span class="hljs-regexp">/conf -v /</span>home<span class="hljs-regexp">/neo4j/im</span>port:<span class="hljs-regexp">/var/</span>lib<span class="hljs-regexp">/neo4j/im</span>port --env NEO4J_AUTH=neo4j/password neo4j</code></pre><p>其中<strong>container_name</strong>可以自己指定，挂载在根目录下的子目录可以根据你自己的实际情况进行替换，我这里是<strong>/home</strong>。另外<strong>NEO4J_AUTH</strong>也是你自己来进行设置。</p><p>执行完上述命令后就在后台把neo4j容器启动起来了，这个时候你就能在宿主机的浏览器中输入</p><pre><code class="hljs angelscript">localhost:<span class="hljs-number">7474</span></code></pre><p>输入用户名和密码就能登录到数据库了。</p><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/neo4j%E7%95%8C%E9%9D%A2.png" class="" title="neo4j界面"><h5 id="neo4j配置"><a href="#neo4j配置" class="headerlink" title="neo4j配置"></a>neo4j配置</h5><p>上述方式启动的neo4j是按照默认的配置进行启动的，而默认的数据库配置是不允许远程登陆的，这样对于在服务器上使用docker搭载neo4j的同学来说，就很不方便了。所以我们对默认配置进行一些改变，改变如下：</p><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 进入容器配置目录挂载在宿主机的对应目录，我这里是<span class="hljs-regexp">/home/</span>neo4j/confcd <span class="hljs-regexp">/home/</span>neo4j/conf<span class="hljs-regexp">//</span> vim编辑器打开neo4j.confvim neo4j.conf<span class="hljs-regexp">//</span> 进行以下更改<span class="hljs-regexp">//</span>在文件配置末尾添加这一行dbms.connectors.default_listen_address=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>  <span class="hljs-regexp">//</span>指定连接器的默认监听ip为<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>，即允许任何ip连接到数据库<span class="hljs-regexp">//</span>修改dbms.connector.bolt.listen_address=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7687</span>  <span class="hljs-regexp">//</span>取消注释并把对bolt请求的监听“地址:端口”改为“<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7687</span>”dbms.connector.http.listen_address=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7474</span>  <span class="hljs-regexp">//</span>取消注释并把对http请求的监听“地址:端口”改为“<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7474</span>”</code></pre><p>保存后退出，重启neo4j容器，可以使用容器的省略id或者生成容器时指定的容器名进行重启。</p><pre><code class="hljs applescript">docker restart 容器<span class="hljs-built_in">id</span>（或者容器名）</code></pre><p><strong>防火墙设置</strong></p><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 查看当前防火墙状态，若为“inactive”，则防火墙已关闭，不必进行接续操作。sudo ufw status<span class="hljs-regexp">//</span> 若防火墙状态为“active”，则使用下列命令开放端口sudo ufw allow <span class="hljs-number">7474</span>sudo ufw allow <span class="hljs-number">7687</span><span class="hljs-regexp">//</span> 重启防火墙sudo ufw reload</code></pre><h4 id="neo4j数据导入"><a href="#neo4j数据导入" class="headerlink" title="neo4j数据导入"></a>neo4j数据导入</h4><p>neo4j数据的批量导入方法</p><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/%E5%AF%BC%E5%85%A5%E6%96%B9%E6%B3%95.png" class="" title="导入方法"><p>为了加快速度，使用官方的<strong>Neo4j-import</strong>进行导入</p><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 数据准备清空data<span class="hljs-regexp">/databases/g</span>raph.db文件夹(如果有),将清洗好的结点文件nodes.csv和关系文件rel.csv拷贝到宿主机<span class="hljs-regexp">/home/</span>neo4j/import中<span class="hljs-regexp">//</span> docker以exec方式进入容器的交互式终端docker exec -it container_name(or container_id) <span class="hljs-regexp">/bin/</span>bash<span class="hljs-regexp">//</span> 停掉neo4jbin/neo4j stop<span class="hljs-regexp">//</span>使用如下命令导入bin/neo4j-admin import \--database=graph.db \        <span class="hljs-regexp">//</span>指定导入的数据库，没有系统则会在data/databases下自动创建一个--nodes .<span class="hljs-regexp">/import/</span>nodes.csv <span class="hljs-regexp">//</span>指定导入的节点文件位置--relationships .<span class="hljs-regexp">/import/</span>rel.csv <span class="hljs-regexp">//</span>指定导入的关系文件位置--skip-duplicate-nodes=true <span class="hljs-regexp">//</span>设置重复节点自动过滤--skip-bad-relationships=true <span class="hljs-regexp">//</span>设置bad关系自动过滤<span class="hljs-regexp">//</span>可执行一行式终端命令bin<span class="hljs-regexp">/neo4j-admin import --database=graph.db --nodes ./im</span>port<span class="hljs-regexp">/nodes.csv --relationships ./im</span>port/rel.csv --skip-duplicate-nodes=true --skip-bad-relationships=true<span class="hljs-regexp">//</span> 容器内启动neo4jbin/neo4j start<span class="hljs-regexp">//</span> 退出交互式终端但是保证neo4j后台继续运行ctrl + P + Q<span class="hljs-regexp">//</span>保险起见，重启neo4j容器docker restart container_name(or container_id)</code></pre><p>重启后使用另一台主机向服务器发送http请求进行远程登陆，在浏览器中输入</p><pre><code class="hljs angelscript">服务器ip:<span class="hljs-number">7474</span></code></pre><p><strong>切换连接模式</strong>为 <strong>bolt:/</strong> ，输入用户名和密码进行登陆，登陆成功发现在数据库一栏没找到新导入的数据库<strong>graph.db</strong></p><p>这是因为配置不够全，继续进到容器挂载到宿主机的<strong>/home/neo4j/conf</strong>中对<strong>neo4j.conf</strong>进行配置</p><pre><code class="hljs reasonml"><span class="hljs-comment">//在文件末尾添加默认的数据库</span>dbms.active_database=graph.db<span class="hljs-comment">// 保存后重启容器</span>docker restart container<span class="hljs-constructor">_name(<span class="hljs-params">or</span> <span class="hljs-params">container_id</span>)</span></code></pre><p>重新进行远程连接，此时数据库的默认选择应该就切换到了新导入的graph.db。</p><h4 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h4><p>数据如何清洗成两个符合neo4j-import导入格式的csv文件？</p><ul><li><a href="https://blog.csdn.net/muruibin88/article/details/106475757">ownthink_kg 1.4亿数据快速导入Neo4j</a></li><li><a href="https://github.com/jievince/rdf-converter">GO语言编写的开源数据清洗工具</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
