<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MyBatis基础知识</title>
    <link href="/2020/12/14/MyBatis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2020/12/14/MyBatis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h3 id="MyBatis框架使用"><a href="#MyBatis框架使用" class="headerlink" title="MyBatis框架使用"></a>MyBatis框架使用</h3><h2 id="1-导入mybatis的jar包"><a href="#1-导入mybatis的jar包" class="headerlink" title="1. 导入mybatis的jar包"></a>1. 导入mybatis的jar包</h2><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.mybatis<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>mybatis<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.5.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><h2 id="2-根据数据表建立实体类"><a href="#2-根据数据表建立实体类" class="headerlink" title="2. 根据数据表建立实体类"></a>2. 根据数据表建立实体类</h2><img src="/2020/12/14/MyBatis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/database.png" class="" title="database.png"><h3 id="方式1-——-借助IDEA"><a href="#方式1-——-借助IDEA" class="headerlink" title="方式1 —— 借助IDEA"></a>方式1 —— 借助IDEA</h3><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.youzikeji.pojo;<span class="hljs-comment">// 实体类</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">User</span> </span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> id;    <span class="hljs-keyword">private</span> String name;    <span class="hljs-keyword">private</span> String password;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">User</span><span class="hljs-params">()</span> </span>&#123;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">User</span><span class="hljs-params">(<span class="hljs-keyword">int</span> id, String name, String pwd)</span> </span>&#123;        <span class="hljs-keyword">this</span>.id = id;        <span class="hljs-keyword">this</span>.name = name;        <span class="hljs-keyword">this</span>.password = pwd;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getId</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> id;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setId</span><span class="hljs-params">(<span class="hljs-keyword">int</span> id)</span> </span>&#123;        <span class="hljs-keyword">this</span>.id = id;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getName</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> name;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setName</span><span class="hljs-params">(String name)</span> </span>&#123;        <span class="hljs-keyword">this</span>.name = name;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getPwd</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> password;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setPwd</span><span class="hljs-params">(String pwd)</span> </span>&#123;        <span class="hljs-keyword">this</span>.password = pwd;    &#125;    <span class="hljs-meta">@Override</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">toString</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;User&#123;&quot;</span> +                <span class="hljs-string">&quot;id=&quot;</span> + id +                <span class="hljs-string">&quot;, name=&#x27;&quot;</span> + name + <span class="hljs-string">&#x27;\&#x27;&#x27;</span> +                <span class="hljs-string">&quot;, pwd=&#x27;&quot;</span> + password + <span class="hljs-string">&#x27;\&#x27;&#x27;</span> +                <span class="hljs-string">&#x27;&#125;&#x27;</span>;    &#125;&#125;</code></pre><h3 id="方式2-——-利用lombok插件"><a href="#方式2-——-利用lombok插件" class="headerlink" title="方式2 —— 利用lombok插件"></a>方式2 —— 利用lombok插件</h3><ol><li><p>先给IDEA安装lombok插件</p></li><li><p>lombok插件提供了众多pojo类注解，可以自动生成get/set/toString/hashCode/无参构造/有参构造等方法，常用的注解有</p><p>@Getter/@Setter</p><p>@ToString</p><p>@Data</p><p>@RequiredArgsConstructor</p><p>@AllArgsConstructor </p><p>@NoArgsConstructor </p><p>使用样例如下：</p></li></ol><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.youzikeji.pojo;<span class="hljs-keyword">import</span> lombok.AllArgsConstructor;<span class="hljs-keyword">import</span> lombok.Data;<span class="hljs-keyword">import</span> lombok.NoArgsConstructor;<span class="hljs-comment">// 实体类</span><span class="hljs-meta">@Data</span>       <span class="hljs-comment">// 包含get、set方法、无参构造、toString和hashCode等</span><span class="hljs-meta">@AllArgsConstructor</span>     <span class="hljs-comment">// 全参构造，会覆盖无参方法</span><span class="hljs-meta">@NoArgsConstructor</span>      <span class="hljs-comment">// 无参构造</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">User</span> </span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> id;    <span class="hljs-keyword">private</span> String name;    <span class="hljs-keyword">private</span> String password;&#125;</code></pre><ol><li>导入lombok的jar包</li></ol><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.projectlombok<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>lombok<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.18.16<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><h2 id="3-业务接口定义与实现"><a href="#3-业务接口定义与实现" class="headerlink" title="3. 业务接口定义与实现"></a>3. 业务接口定义与实现</h2><h3 id="方式1-——-直接给dao层添加接口"><a href="#方式1-——-直接给dao层添加接口" class="headerlink" title="方式1 —— 直接给dao层添加接口"></a>方式1 —— 直接给dao层添加接口</h3><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.youzikeji.dao;<span class="hljs-keyword">import</span> com.youzikeji.pojo.User;<span class="hljs-keyword">import</span> java.util.List;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">UserMapper</span> </span>&#123;    <span class="hljs-comment">// 查询全部用户</span>    <span class="hljs-function">List&lt;User&gt; <span class="hljs-title">getUserList</span><span class="hljs-params">()</span></span>;    <span class="hljs-comment">// 根据ID查询用户</span>    <span class="hljs-function">User <span class="hljs-title">getUserById</span><span class="hljs-params">(<span class="hljs-keyword">int</span> id)</span></span>;    <span class="hljs-comment">// 增加用户</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">addUser</span><span class="hljs-params">(User user)</span></span>;    <span class="hljs-comment">// 修改用户</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">updateUser</span><span class="hljs-params">(User user)</span></span>;    <span class="hljs-comment">// 删除用户</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">deleteUser</span><span class="hljs-params">(<span class="hljs-keyword">int</span> id)</span></span>;    <span class="hljs-comment">// 模糊查询</span>    <span class="hljs-function">List&lt;User&gt; <span class="hljs-title">getSimilarUser</span><span class="hljs-params">(String name)</span></span>;&#125;</code></pre><p>定义好接口后，新建一个同名的xml文件用于绑定接口并定义实现的sql语句</p><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</span><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">mapper</span></span><span class="hljs-meta">        <span class="hljs-meta-keyword">PUBLIC</span> <span class="hljs-meta-string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span></span><span class="hljs-meta">        <span class="hljs-meta-string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span><span class="hljs-comment">&lt;!--bind Mapper interface--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">mapper</span> <span class="hljs-attr">namespace</span>=<span class="hljs-string">&quot;com.youzikeji.dao.UserMapper&quot;</span>&gt;</span>    <span class="hljs-comment">&lt;!--resultSet Mapping--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">resultMap</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;UserMap&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;user&quot;</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">result</span> <span class="hljs-attr">column</span>=<span class="hljs-string">&quot;pwd&quot;</span> <span class="hljs-attr">property</span>=<span class="hljs-string">&quot;password&quot;</span>/&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">resultMap</span>&gt;</span>    <span class="hljs-comment">&lt;!--sql command--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;getUserList&quot;</span> <span class="hljs-attr">resultMap</span>=<span class="hljs-string">&quot;UserMap&quot;</span>&gt;</span>        select * from mybatis.user    <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;getUserById&quot;</span> <span class="hljs-attr">resultMap</span>=<span class="hljs-string">&quot;UserMap&quot;</span>&gt;</span>        select  * from mybatis.user where id = #&#123;id&#125;    <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">insert</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;addUser&quot;</span> <span class="hljs-attr">parameterType</span>=<span class="hljs-string">&quot;user&quot;</span>&gt;</span>        insert into mybatis.user (id, name, pwd) VALUES (#&#123;id&#125;,#&#123;name&#125;,#&#123;pwd&#125;)    <span class="hljs-tag">&lt;/<span class="hljs-name">insert</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">update</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;updateUser&quot;</span> <span class="hljs-attr">parameterType</span>=<span class="hljs-string">&quot;user&quot;</span>&gt;</span>        update mybatis.user set name=#&#123;name&#125;, pwd=#&#123;pwd&#125;  where id=#&#123;id&#125;    <span class="hljs-tag">&lt;/<span class="hljs-name">update</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">delete</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;deleteUser&quot;</span> <span class="hljs-attr">parameterType</span>=<span class="hljs-string">&quot;int&quot;</span>&gt;</span>        delete from mybatis.user where id=#&#123;id&#125;    <span class="hljs-tag">&lt;/<span class="hljs-name">delete</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;getSimilarUser&quot;</span> <span class="hljs-attr">resultMap</span>=<span class="hljs-string">&quot;UserMap&quot;</span>&gt;</span>        select * from mybatis.user where name like concat(&#x27;%&#x27;, #&#123;name&#125; ,&#x27;%&#x27;)    <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">mapper</span>&gt;</span></code></pre><p>ps：</p><p>pojo类定义时的属性名和数据表对应位置的字段名不同时，需要进行结果集映射，即resultMap</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--resultSet Mapping--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">resultMap</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;UserMap&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;user&quot;</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">result</span> <span class="hljs-attr">column</span>=<span class="hljs-string">&quot;pwd&quot;</span> <span class="hljs-attr">property</span>=<span class="hljs-string">&quot;password&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">resultMap</span>&gt;</span></code></pre><p>绑定好mapper接口之后，需要到<code>resources/mybatis-config.xml</code>文件中注册mapper</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--mapper.xml registering--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">mappers</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">mapper</span> <span class="hljs-attr">resource</span>=<span class="hljs-string">&quot;com/youzikeji/dao/UserMapper.xml&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">mappers</span>&gt;</span></code></pre><p>ps：</p><p>使用<code>&lt;mapper resource=&quot;&quot;/&gt;</code>方式时，需要填入xml文件的相对路径</p><h3 id="方式2-——-使用注解"><a href="#方式2-——-使用注解" class="headerlink" title="方式2 —— 使用注解"></a>方式2 —— 使用注解</h3><p>在定义业务接口时使用注解将方法和对应sql命令进行绑定</p><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.youzikeji.dao;<span class="hljs-keyword">import</span> com.youzikeji.pojo.User;<span class="hljs-keyword">import</span> org.apache.ibatis.annotations.*;<span class="hljs-keyword">import</span> java.util.List;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">UserMapper</span> </span>&#123;    <span class="hljs-comment">// 查询全部用户,注解实现</span>    <span class="hljs-meta">@Select(&quot;select * from user&quot;)</span>    <span class="hljs-function">List&lt;User&gt; <span class="hljs-title">getUserList</span><span class="hljs-params">()</span></span>;    <span class="hljs-comment">// 根据ID查询用户</span>    <span class="hljs-meta">@Select(&quot;select * from user where id = #&#123;id&#125;&quot;)</span>    <span class="hljs-function">User <span class="hljs-title">getUserById</span><span class="hljs-params">(<span class="hljs-meta">@Param(&quot;id&quot;)</span> <span class="hljs-keyword">int</span> id)</span></span>;    <span class="hljs-comment">// 增加用户</span>    <span class="hljs-meta">@Insert(&quot;insert into user(id, name, pwd) values (#&#123;id&#125;, #&#123;name&#125;, #&#123;password&#125;)&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">addUser</span><span class="hljs-params">(User user)</span></span>;    <span class="hljs-comment">// 修改用户</span>    <span class="hljs-meta">@Update(&quot;update user set name=#&#123;name&#125;, pwd=#&#123;password&#125; where id=#&#123;id&#125;&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">updateUser</span><span class="hljs-params">(User user)</span></span>;    <span class="hljs-comment">// 删除用户</span>    <span class="hljs-meta">@Delete(&quot;delete from user where id=#&#123;uid&#125;&quot;)</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">deleteUser</span><span class="hljs-params">(<span class="hljs-meta">@Param(&quot;uid&quot;)</span> <span class="hljs-keyword">int</span> id)</span></span>;    <span class="hljs-comment">// 模糊查询</span>    <span class="hljs-function">List&lt;User&gt; <span class="hljs-title">getSimilarUser</span><span class="hljs-params">(String name)</span></span>;&#125;</code></pre><p>之后直接到<code>resources/mybatis-config.xml</code>文件中注册mapper</p><pre><code class="hljs xml"><span class="hljs-comment">&lt;!--mapper class registering--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">mappers</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">mapper</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;com.youzikeji.dao.UserMapper&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">mappers</span>&gt;</span></code></pre><h2 id="4-构建mybatis核心配置文件"><a href="#4-构建mybatis核心配置文件" class="headerlink" title="4. 构建mybatis核心配置文件"></a>4. 构建mybatis核心配置文件</h2><p>XML 配置文件中包含了对 MyBatis 系统的核心设置，包括获取数据库连接实例的数据源（DataSource）以及决定事务作用域和控制方式的事务管理器（TransactionManager）。</p><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</span><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">configuration</span></span><span class="hljs-meta">        <span class="hljs-meta-keyword">PUBLIC</span> <span class="hljs-meta-string">&quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span></span><span class="hljs-meta">        <span class="hljs-meta-string">&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;</span>&gt;</span><span class="hljs-comment">&lt;!--core setting--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>    <span class="hljs-comment">&lt;!--load db.properties--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">properties</span> <span class="hljs-attr">resource</span>=<span class="hljs-string">&quot;db.properties&quot;</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;username&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;root&quot;</span>/&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;password&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;root&quot;</span>/&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span>    <span class="hljs-comment">&lt;!--settings--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">settings</span>&gt;</span>        <span class="hljs-comment">&lt;!--standard log settings--&gt;</span><span class="hljs-comment">&lt;!--        &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot;/&gt;--&gt;</span>        <span class="hljs-comment">&lt;!--LOG4J setting, need dependency--&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;logImpl&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;LOG4J&quot;</span>/&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">settings</span>&gt;</span>    <span class="hljs-comment">&lt;!--set typeAlias--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">typeAliases</span>&gt;</span>        <span class="hljs-comment">&lt;!--method 1--&gt;</span><span class="hljs-comment">&lt;!--        &lt;typeAlias type=&quot;com.youzikeji.pojo.User&quot; alias=&quot;user&quot;/&gt;--&gt;</span>        <span class="hljs-comment">&lt;!--method 2--&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">package</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;com.youzikeji.pojo&quot;</span>/&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">typeAliases</span>&gt;</span>    <span class="hljs-comment">&lt;!--multi-environments--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">environments</span> <span class="hljs-attr">default</span>=<span class="hljs-string">&quot;development&quot;</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">environment</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;development&quot;</span>&gt;</span>            <span class="hljs-comment">&lt;!--JDBC--&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">transactionManager</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;JDBC&quot;</span>/&gt;</span>            <span class="hljs-comment">&lt;!--database connect setting--&gt;</span>            <span class="hljs-tag">&lt;<span class="hljs-name">dataSource</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;POOLED&quot;</span>&gt;</span>                <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;driver&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;$&#123;driver&#125;&quot;</span>/&gt;</span>                <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;url&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;$&#123;url&#125;&quot;</span>/&gt;</span>                <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;username&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;$&#123;username&#125;&quot;</span>/&gt;</span>                <span class="hljs-tag">&lt;<span class="hljs-name">property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;password&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;$&#123;password&#125;&quot;</span>/&gt;</span>            <span class="hljs-tag">&lt;/<span class="hljs-name">dataSource</span>&gt;</span>        <span class="hljs-tag">&lt;/<span class="hljs-name">environment</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">environments</span>&gt;</span>    <span class="hljs-comment">&lt;!--mapper class registering--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">mappers</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">mapper</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;com.youzikeji.dao.UserMapper&quot;</span>/&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">mappers</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre><p>关于配置文件的说明：</p><ol><li><p>所有核心的配置都在<code>&lt;configuration&gt;...&lt;/configuration&gt;</code>中，其中，各部分配置需要遵从既定的顺序。</p><p>前三个按顺序必须依次是<code>&lt;properties&gt; ——&gt; &lt;settings&gt; ——&gt; &lt;typeAliases&gt;</code>.</p><p>另外<code>&lt;mappers&gt;</code>必须在最后进行注册配置；</p></li><li><p><code>&lt;properties&gt;</code>，顾名思义，可以在这里配置属性.</p><p>这些属性可以在外部进行配置，并可以进行动态替换。</p><p>这说明既可以在java属性文件<code>resources/*.properties</code>中配置这些属性，也可以在<code>&lt;property&gt;</code>中设置。</p><p>在<code>db.properties</code>中的配置为：</p><pre><code class="hljs properties"><span class="hljs-attr">driver</span>=<span class="hljs-string">com.mysql.jdbc.Driver</span><span class="hljs-attr">url</span>=<span class="hljs-string">jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghai</span></code></pre><p>在<code>&lt;properties&gt;</code>的子属性<code>&lt;property&gt;</code>中的配置如下：</p><pre><code class="hljs properties"><span class="hljs-meta">&lt;!--load</span> <span class="hljs-string">db.properties--&gt;</span><span class="hljs-meta">&lt;properties</span> <span class="hljs-string">resource=&quot;db.properties&quot;&gt;</span>    <span class="hljs-meta">&lt;property</span> <span class="hljs-string">name=&quot;username&quot; value=&quot;root&quot;/&gt;</span>    <span class="hljs-meta">&lt;property</span> <span class="hljs-string">name=&quot;password&quot; value=&quot;root&quot;/&gt;</span><span class="hljs-attr">&lt;/properties&gt;</span></code></pre></li><li><p><code>&lt;settings&gt;</code>作为MyBatis 中极为重要的调整设置，它们会改变 MyBatis 的运行时行为。 一个配置完整的 settings 元素的示例如下：</p></li></ol><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">settings</span>&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;cacheEnabled&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;true&quot;</span>/&gt;</span><span class="hljs-comment">&lt;!--全局性地开启或关闭所有映射器配置文件中已配置的任何缓存--&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;lazyLoadingEnabled&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;true&quot;</span>/&gt;</span>  <span class="hljs-comment">&lt;!--延迟加载的全局开关。当开启时，所有关联对象都会延迟加载--&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;multipleResultSetsEnabled&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;true&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;useColumnLabel&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;true&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;useGeneratedKeys&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;false&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;autoMappingBehavior&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;PARTIAL&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;autoMappingUnknownColumnBehavior&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;WARNING&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;defaultExecutorType&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;SIMPLE&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;defaultStatementTimeout&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;25&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;defaultFetchSize&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;100&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;safeRowBoundsEnabled&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;false&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;mapUnderscoreToCamelCase&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;false&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;localCacheScope&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;SESSION&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;jdbcTypeForNull&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;OTHER&quot;</span>/&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;lazyLoadTriggerMethods&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;equals,clone,hashCode,toString&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">settings</span>&gt;</span></code></pre><p>特别的，只是简单在<code>&lt;settings&gt;</code>中进行日志配置，可以使用自带的标准日志，也可使用log4j，使用log4j的步骤如下：</p><ul><li>前提——导入log4j的jar包</li></ul><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.17<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><ul><li>编写日志的属性文件<code>resources/log4j.properties</code></li></ul><pre><code class="hljs properties"><span class="hljs-comment">#将等级为DEBUG的日志信息输出到控制台和file两个目的地</span><span class="hljs-meta">log4j.rootLogger</span> = <span class="hljs-string">DEBUG,console,file</span><span class="hljs-comment">#控制台输出相关配置</span><span class="hljs-meta">log4j.appender.console</span> = <span class="hljs-string">org.apache.log4j.ConsoleAppender</span><span class="hljs-meta">log4j.appender.console.Target</span> = <span class="hljs-string">System.out</span><span class="hljs-meta">log4j.appender.console.Threshold</span> = <span class="hljs-string">DEBUG</span><span class="hljs-meta">log4j.appender.console.layout</span> = <span class="hljs-string">org.apache.log4j.PatternLayout</span><span class="hljs-meta">log4j.appender.console.layout.ConversionPatten</span> = <span class="hljs-string">[%c]-%m%n</span><span class="hljs-comment">#文件输出相关设置</span><span class="hljs-meta">log4j.appender.file</span> = <span class="hljs-string">org.apache.log4j.RollingFileAppender</span><span class="hljs-meta">log4j.appender.file.File</span> = <span class="hljs-string">./log/youzikeji.log</span><span class="hljs-meta">log4j.appender.file.MaxFileSize</span> = <span class="hljs-string">10mb</span><span class="hljs-meta">log4j.appender.file.Threshold</span> = <span class="hljs-string">DEBUG</span><span class="hljs-meta">log4j.appender.file.layout</span> = <span class="hljs-string">org.apache.log4j.PatternLayout</span><span class="hljs-meta">log4j.appender.file.layout.ConversionPatten</span> = <span class="hljs-string">[%p][%d&#123;yy-MM-dd&#125;][%c]%m%n</span><span class="hljs-comment">#日志输出级别</span><span class="hljs-meta">log4j.logger.org.mybatis</span> = <span class="hljs-string">DEBUG</span><span class="hljs-meta">log4j.logger.java.sql</span> = <span class="hljs-string">DEBUG</span><span class="hljs-meta">log4j.logger.java.sql.Statement</span> = <span class="hljs-string">DEBUG</span><span class="hljs-meta">log4j.logger.java.sql.ResultSet</span> = <span class="hljs-string">DEBUG</span><span class="hljs-meta">log4j.logger.java.sql.PreparedStatement</span> = <span class="hljs-string">DEBUG</span></code></pre><ul><li>在<code>&lt;setting&gt;</code>中配置</li></ul><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">settings</span>&gt;</span>    <span class="hljs-comment">&lt;!--LOG4J setting, need dependency--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">setting</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;logImpl&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;LOG4J&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">settings</span>&gt;</span></code></pre><ol><li><p><code>&lt;typeAliases&gt;</code>为取别名的配置，有两种方式取别名</p></li><li><p>传统方式</p></li></ol><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">typeAliases</span>&gt;</span>    <span class="hljs-comment">&lt;!--method 1--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">typeAlias</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;com.youzikeji.pojo.User&quot;</span> <span class="hljs-attr">alias</span>=<span class="hljs-string">&quot;user&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">typeAliases</span>&gt;</span></code></pre><ol><li>声明包名方式——(该包下的类的别名默认为其小写形式)</li></ol><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">typeAliases</span>&gt;</span>    <span class="hljs-comment">&lt;!--method 2--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">package</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;com.youzikeji.pojo&quot;</span>/&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">typeAliases</span>&gt;</span></code></pre><h2 id="5-从XML中构建SqlSessionFactory"><a href="#5-从XML中构建SqlSessionFactory" class="headerlink" title="5. 从XML中构建SqlSessionFactory"></a>5. 从XML中构建SqlSessionFactory</h2><p>MyBatis 包含一个名叫 Resources 的工具类，它包含一些实用方法，使得从类路径或其它位置加载资源文件更加容易。</p><pre><code class="hljs java">String resource = <span class="hljs-string">&quot;org/mybatis/example/mybatis-config.xml&quot;</span>;InputStream inputStream = Resources.getResourceAsStream(resource);SqlSessionFactory sqlSessionFactory = <span class="hljs-keyword">new</span> SqlSessionFactoryBuilder().build(inputStream);</code></pre><p>由XML文件生成SqlSessionFactory对象这一步骤是既定的，可以包装成工具类MybatisUtils</p><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.youzikeji.utils;<span class="hljs-keyword">import</span> org.apache.ibatis.io.Resources;<span class="hljs-keyword">import</span> org.apache.ibatis.session.SqlSession;<span class="hljs-keyword">import</span> org.apache.ibatis.session.SqlSessionFactory;<span class="hljs-keyword">import</span> org.apache.ibatis.session.SqlSessionFactoryBuilder;<span class="hljs-keyword">import</span> java.io.IOException;<span class="hljs-keyword">import</span> java.io.InputStream;<span class="hljs-comment">// Mybatis工具类</span><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MybatisUtils</span> </span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> SqlSessionFactory sqlSessionFactory;    <span class="hljs-keyword">static</span> &#123;        <span class="hljs-comment">// 使用Mybatis第一步：获取sqlSessionFactory对象</span>        <span class="hljs-keyword">try</span> &#123;            String resource = <span class="hljs-string">&quot;mybatis-config.xml&quot;</span>;            <span class="hljs-comment">// 将XML文件读入输入流</span>            InputStream inputStream = Resources.getResourceAsStream(resource);            <span class="hljs-comment">// 从XML文件中构建 SqlSessionFactory 的实例</span>            sqlSessionFactory = <span class="hljs-keyword">new</span> SqlSessionFactoryBuilder().build(inputStream);        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;    <span class="hljs-comment">// 第二步：获取SqlSession对象</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> SqlSession <span class="hljs-title">getSqlSession</span><span class="hljs-params">()</span></span>&#123;        <span class="hljs-keyword">return</span> sqlSessionFactory.openSession();    &#125;&#125;</code></pre><h2 id="6-由SqlSessionFactory获取SqlSession"><a href="#6-由SqlSessionFactory获取SqlSession" class="headerlink" title="6. 由SqlSessionFactory获取SqlSession"></a>6. 由SqlSessionFactory获取SqlSession</h2><p>在MybatisUtils类中定义了一个方法，通过调用openSession()获取SqlSession对象</p><pre><code class="hljs java">SqlSession session = MybatisUtils.getSqlSession();</code></pre><h2 id="7-编写测试类"><a href="#7-编写测试类" class="headerlink" title="7. 编写测试类"></a>7. 编写测试类</h2><p>获取SqlSession对象后，通过<code>getMapper()</code>方法获取Mapper对象，通过Mapper对象调用接口方法执行SQL语句</p><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.youzikeji.dao;<span class="hljs-keyword">import</span> com.youzikeji.pojo.User;<span class="hljs-keyword">import</span> com.youzikeji.utils.MybatisUtils;<span class="hljs-keyword">import</span> org.apache.ibatis.session.SqlSession;<span class="hljs-keyword">import</span> org.apache.log4j.Logger;<span class="hljs-keyword">import</span> org.junit.Test;<span class="hljs-keyword">import</span> java.util.List;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UserMapperTest</span> </span>&#123;    <span class="hljs-comment">//通过反射获取本类的日志对象</span>    <span class="hljs-keyword">static</span> Logger logger  = Logger.getLogger(UserMapperTest.class);    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test</span><span class="hljs-params">()</span></span>&#123;        <span class="hljs-comment">// 1.获取SqlSession对象</span>        SqlSession session = MybatisUtils.getSqlSession();        <span class="hljs-comment">// 2.执行SQL(getmapper())</span>        UserMapper mapper = session.getMapper(UserMapper.class);        List&lt;User&gt; list = mapper.getUserList();        <span class="hljs-keyword">for</span> (User user : list) &#123;            System.out.println(user);        &#125;        <span class="hljs-comment">// 3.关闭SqlSession</span>        session.close();    &#125;    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getUserById</span><span class="hljs-params">()</span></span>&#123;        SqlSession session = MybatisUtils.getSqlSession();        UserMapper mapper = session.getMapper(UserMapper.class);        User user = mapper.getUserById(<span class="hljs-number">1</span>);        System.out.println(user);        session.close();    &#125;    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">addUser</span><span class="hljs-params">()</span></span>&#123;        SqlSession session = MybatisUtils.getSqlSession();        UserMapper mapper = session.getMapper(UserMapper.class);        mapper.addUser(<span class="hljs-keyword">new</span> User(<span class="hljs-number">4</span>,<span class="hljs-string">&quot;lalalalal&quot;</span>, <span class="hljs-string">&quot;111111&quot;</span>));        <span class="hljs-comment">// autocommit=true ——&gt; 自动提交事务</span>        session.commit();        session.close();    &#125;    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">updateUser</span><span class="hljs-params">()</span></span>&#123;        SqlSession session = MybatisUtils.getSqlSession();        UserMapper mapper = session.getMapper(UserMapper.class);        mapper.updateUser(<span class="hljs-keyword">new</span> User(<span class="hljs-number">4</span>, <span class="hljs-string">&quot;nba&quot;</span>, <span class="hljs-string">&quot;111112&quot;</span>));        session.commit();        session.close();    &#125;    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">deleteUser</span><span class="hljs-params">()</span></span>&#123;        SqlSession session = MybatisUtils.getSqlSession();        UserMapper mapper = session.getMapper(UserMapper.class);        mapper.deleteUser(<span class="hljs-number">4</span>);        session.commit();        session.close();    &#125;    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getSimilarUser</span><span class="hljs-params">()</span></span>&#123;        SqlSession session = MybatisUtils.getSqlSession();        UserMapper mapper = session.getMapper(UserMapper.class);        List&lt;User&gt; users = mapper.getSimilarUser(<span class="hljs-string">&quot;an&quot;</span>);        <span class="hljs-keyword">for</span> (User user : users) &#123;            System.out.println(user);        &#125;        session.close();    &#125;    <span class="hljs-meta">@Test</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testLog4j</span><span class="hljs-params">()</span></span>&#123;        logger.info(<span class="hljs-string">&quot;info —— 我在测试testLog4j&quot;</span>);        logger.debug(<span class="hljs-string">&quot;debug —— 我在测试testLog4j&quot;</span>);        logger.error(<span class="hljs-string">&quot;error —— 我在测试testLog4j&quot;</span>);    &#125;&#125;</code></pre><h2 id="8-动态SQL"><a href="#8-动态SQL" class="headerlink" title="8. 动态SQL"></a>8. 动态SQL</h2><p>参考<a href="https://mybatis.org/mybatis-3/zh/dynamic-sql.html">官方文档</a></p><h2 id="9-MyBatis缓存"><a href="#9-MyBatis缓存" class="headerlink" title="9. MyBatis缓存"></a>9. MyBatis缓存</h2><h3 id="缓存基础"><a href="#缓存基础" class="headerlink" title="缓存基础"></a>缓存基础</h3><p>MyBatis中默认定义了两级缓存：<code>一级缓存</code>和<code>二级缓存</code></p><ul><li><p>默认只开启一级缓存，SqlSession(会话)级别的缓存，也称为<code>本地缓存</code></p></li><li><p>二级缓存需要手动开启，基于<code>namespace</code>(接口)级别的缓存</p><ul><li><p>所有数据都会先放在一级缓存中，当会话提交或者关闭时，数据才会提交到二级缓存中</p></li><li><p>要启用全局的二级缓存，只需要在 SQL 映射文件中添加一行：<code>&lt;cache/&gt;</code>，该语句的效果如下:</p><ul><li>映射语句文件中的所有 select 语句的结果将会被缓存</li><li>映射语句文件中的所有 insert、update 和 delete 语句会刷新缓存</li><li>缓存默认会使用<code>最近最少使用</code>算法（LRU, Least Recently Used）算法来清除不需要的缓存<ul><li>可用的清除策略有：<ul><li><code>LRU</code> – 最近最少使用：移除最长时间不被使用的对象。</li><li><code>FIFO</code> – 先进先出：按对象进入缓存的顺序来移除它们。</li><li><code>SOFT</code> – 软引用：基于垃圾回收器状态和软引用规则移除对象。</li><li><code>WEAK</code> – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。</li></ul></li></ul></li><li>缓存默认不会定时进行刷新</li><li>缓存会保存列表或对象（无论查询方法返回哪种）的 1024 个引用。</li><li>缓存会被视为读/写缓存，这意味着获取到的对象并不是共享的，可以安全地被调用者修改，而不干扰其他调用者或线程所做的潜在修改。</li></ul></li><li><p>二级缓存的属性可以通过 cache 元素的属性来修改：</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">cache</span></span><span class="hljs-tag">  <span class="hljs-attr">eviction</span>=<span class="hljs-string">&quot;FIFO&quot;</span></span><span class="hljs-tag">  <span class="hljs-attr">flushInterval</span>=<span class="hljs-string">&quot;60000&quot;</span> </span><span class="hljs-tag">  <span class="hljs-attr">size</span>=<span class="hljs-string">&quot;512&quot;</span></span><span class="hljs-tag">  <span class="hljs-attr">readOnly</span>=<span class="hljs-string">&quot;true&quot;</span>/&gt;</span></code></pre><p>上面语句的效果如下：</p><ul><li>创建了一个 FIFO 缓存</li><li>每隔 60 秒刷新</li><li>最多可以存储结果对象或列表的 512 个引用</li><li>返回的对象被认为是只读的，因此对它们进行修改可能会在不同线程中的调用者产生冲突。</li></ul></li></ul></li><li><p>为了提高扩展性，定义了<code>缓存接口Cache</code>，可以通过实现Cache接口来自定义二级缓存</p><p>Cache接口</p><pre><code class="hljs java"><span class="hljs-keyword">package</span> org.apache.ibatis.cache;<span class="hljs-keyword">import</span> java.util.concurrent.locks.ReadWriteLock;<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">Cache</span> </span>&#123;    <span class="hljs-function">String <span class="hljs-title">getId</span><span class="hljs-params">()</span></span>;    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">putObject</span><span class="hljs-params">(Object var1, Object var2)</span></span>;    <span class="hljs-function">Object <span class="hljs-title">getObject</span><span class="hljs-params">(Object var1)</span></span>;    <span class="hljs-function">Object <span class="hljs-title">removeObject</span><span class="hljs-params">(Object var1)</span></span>;    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">clear</span><span class="hljs-params">()</span></span>;    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">getSize</span><span class="hljs-params">()</span></span>;    <span class="hljs-function"><span class="hljs-keyword">default</span> ReadWriteLock <span class="hljs-title">getReadWriteLock</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;    &#125;&#125;</code></pre><p>自定义缓存方式请参考官方文档<a href="https://mybatis.org/mybatis-3/zh/sqlmap-xml.html#cache">MyBatis缓存</a></p></li></ul><h3 id="缓存原理"><a href="#缓存原理" class="headerlink" title="缓存原理"></a>缓存原理</h3><img src="/2020/12/14/MyBatis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%BC%93%E5%AD%98%E5%8E%9F%E7%90%86.png" class="" title="缓存原理.png">]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MyBatis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于多知识库迭代检索的常识问答系统</title>
    <link href="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="多知识库常识知识迭代检索"><a href="#多知识库常识知识迭代检索" class="headerlink" title="多知识库常识知识迭代检索"></a>多知识库常识知识迭代检索</h2><p><a href="https://arxiv.org/pdf/2011.02705v1.pdf">论文地址</a></p><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-1.png" class=""><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>常识问答任务需要引入外部知识来帮助模型更好地理解自然语言问题，现有的解决方案大都采用两阶段框架：</p><ul><li>第一阶段 —— 从广泛的知识来源中找到与给定问题相关的知识事实或者用预训练模型生成相关的知识</li><li>第二阶段 —— 将找到的或者生成的知识与问题融合以预测答案。</li></ul><p>实验结果证明，外部知识融合到问答系统的做法是十分有效的，但这仍然存在一个关键的问题：就从<strong>单一</strong>外部知识库找寻相关知识而言，<strong>抽取到的部分知识可能对解决问题基本毫无作用，甚至还可能损害模型的性能</strong>。例如，以下面一个QA为例，对于问题实体<script type="math/tex">farmland</script>和三个选项实体<script type="math/tex">midwest \space countryside \space illinois</script>，从<strong>ConceptNet</strong>中抽取到的知识显示，<script type="math/tex">farmland</script>和三个选项实体都直接相关<script type="math/tex">(AtLocation)</script>。</p><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-2.jpg" class=""><p>虽然外部知识给到了模型，但模型仍然很难做出正确的选择，因为这三个选项看上去似乎都是正确的。这样的问题在论文中被称为知识的多价值属性，这种问题在问答系统中十分常见，实体关系的多值属性会损害现有模型的性能。</p><h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><p>提出一种新的多知识源问答方法，通过利用多种知识来源，在所需的背景知识和原始问题以及选择之间建立精确的联系，以解决多值属性带来的挑战。</p><p>三个创新：</p><ul><li><strong>提出基于图的迭代检索模块</strong> —— 通过问题中实体之间的隐藏关系来缩小和细化潜在的有用知识事实</li><li><strong>引入词典为实体或者概念提供解释</strong> —— 综合实体或概念解释和迭代检索的知识事实可以帮助模型精确区分欺骗性的答案选择</li><li><strong>提出答案选择感知注意力机制</strong> —— 在将隐层状态向量输入最终预测的线性分类器之前，引入答案选择感知注意机制来计算给定问题、检索的知识和候选选择的各自的隐层向量之间的注意力分数</li></ul><h3 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h3><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-3.png" class=""><p>仍然采用两阶段的框架(默认已经进行了对QA对的实体识别)：</p><ul><li><p>第一阶段 —— 从多个外部知识库中抽取与QA对相关的知识，这部分大多是在检索知识</p><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-4.png" class=""><ul><li><strong>结构化证据</strong> —— 从ConceptNet中找到问题概念和识别的关键实体(包含选项实体)，并把它们作为初始节点。根据问题的类型，使用<strong>基于规则</strong>的方法推断可能的关系，并使用这些关系来缩小知识提取的范围。基于初始节点和潜在关系，迭代地检索与问题相关的知识事实。</li><li><strong>非结构化证据</strong> —— 将维基百科文档拆分成句子，使用ElasticSearch构建索引。根据原问题检索相关句子，使用<strong>标题</strong>和段落缩小文档的范围。然后使用段落级候选词和它们的句子来建立索引，并检索前10个相关的句子</li><li><strong>实体或概念解释</strong> —— 从字典中提取答案选择和问题概念的含义，帮助模型区分分散注意力的实体</li></ul></li><li><p>第二阶段 —— 用预训练模型对构造的输入进行编码，将编码后的三个隐层向量通过一个答案选择感知注意力计算注意力得分，最终输入到分类器中得到QA对的得分。</p><ul><li><strong>输入构造</strong> —— <script type="math/tex">[CLS] \space Question \space [SEP] \space Extracted \space Knowledge \space [SEP] \space Choices</script></li><li><strong>答案选择感知注意力机制</strong> —— 主要是计算QA对各自隐层向量的注意力系数以及证据和选项各自隐层向量的注意力系数，最后串接加权后的问题隐层向量<script type="math/tex">O_{qa}h_{q}</script>和加权后的证据隐层向量<script type="math/tex">O_{ca}h_{c}</script>以及选项隐层向量<script type="math/tex">h_{a}</script></li></ul></li></ul><h3 id="多源知识库"><a href="#多源知识库" class="headerlink" title="多源知识库"></a>多源知识库</h3><p>结构化的ConceptNet、非结构化的Wikipedia以及剑桥词典(Cambridge Dictionary)。</p><ul><li><strong>ConceptNet</strong> —— 最大的结构化知识库之一，知识主要来自其他众包资源、专家创造的资源</li><li><strong>Wikipedia</strong> —— 一个免费的在线百科全书，由世界各地的志愿者创建和编辑，论文中选用最新的Wikipedia 22-May-2020版本</li><li><strong>Cambridge Dictionary</strong> —— 1995年出版，囊括超140k单词、短语及解释。</li></ul><h3 id="文本编码"><a href="#文本编码" class="headerlink" title="文本编码"></a>文本编码</h3><p>在从多个知识源中检索与问题相关的知识事实后，使用<script type="math/tex">[SEP]</script>来分割证据知识、原始问题和候选答案。</p><p>具体做法：</p><ol><li>将原始答案选择与来自剑桥词典的答案解释连接起来作为<script type="math/tex">A= \left\{ a_{1},a_{2},\dots,a_{n} \right\}</script></li><li>将来自维基百科和概念网的证据连接起来作为上下文<script type="math/tex">C=\left\{c_{1}, c_{2}, \ldots, c_{k}\right\}</script>。</li><li>将来自剑桥词典的概念解释与问题词干连接起来作为<script type="math/tex">Q=\left\{q_{1}, q_{2}, \ldots, q_{m}\right\}</script>。</li></ol><p>从形式上来看，预先训练的语言模型的输入是问题Q、相关证据C和答案选择A的连接：</p><script type="math/tex; mode=display">h_{q}=\operatorname{Encoder}(Q), h_{a}=\operatorname{Encoder}(A), h_{c}=\operatorname{Encoder}(C)</script><h3 id="答案选择感知注意力机制"><a href="#答案选择感知注意力机制" class="headerlink" title="答案选择感知注意力机制"></a>答案选择感知注意力机制</h3><p>通常在从RoBERTa模型中获得最后的隐藏状态向量后，对于下游任务中的问题回答，以往的模型方案是通常直接使用线性分类器来预测答案。</p><p>然而，在论文的实验过程中，观察到线性分类器在检索到的证据或背景知识上表现不佳。因此，论文引入了一种答案选择感知的注意机制来计算问题<script type="math/tex">h_{q}</script>和选择之间的注意分数，并且通过标准的注意计算来计算检索到的证据<script type="math/tex">h_{c}</script>和答案选择<script type="math/tex">h_{a}</script>之间的注意分数。</p><script type="math/tex; mode=display">O_{q a}=A T T\left(h_{q}, h_{a}\right), O_{c a}=A T T\left(h_{c}, h_{a}\right)</script><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-5.png" class=""><p>最后，将注意力重新加权的隐藏状态连接起来，通过线性分类器与ReLU进行传递，以计算最终的双向注意力向量进行预测。公式如下:</p><script type="math/tex; mode=display">P(q, a)=\operatorname{Linear}\left(O_{q a} h_{q}, O_{c a} h_{c}, h_{a}\right)</script><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><ul><li>pretrained model —— RoBERTa-large(24-layers)</li><li>max update step —— 6000</li><li>warmup update step —— 150</li><li>max length —— 512</li><li>dropout —— 0.1</li><li>optimizer —— Adam</li><li>loss function —— cross-entropy loss</li><li>batch size —— 4</li><li>learning rate —— 1e-5</li></ul><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-6.png" class=""><h3 id="创新有效性研究"><a href="#创新有效性研究" class="headerlink" title="创新有效性研究"></a>创新有效性研究</h3><p>左图是对使用多元知识库有效性的研究，可以看到证据来源的知识库越多，模型的表现越好。单知识库来源下，模型表现：剑桥字典 &gt; ConceptNet &gt; Wikipedia。</p><p>右图是对图的迭代知识检索以及QA感知注意力机制有效性的研究，实验证明，这两处创新皆能提升模型表现。</p><img src="/2020/11/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E7%9F%A5%E8%AF%86%E5%BA%93%E8%BF%AD%E4%BB%A3%E6%A3%80%E7%B4%A2%E7%9A%84%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/GIR-7.png" class=""><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>处理多项选择题回答任务，需要额外的背景知识或常识。通过有效地整合多种知识资源，提出了一种基于图迭代检索的新的常识问答系统。首先，论文提出一个新的基于图的迭代知识检索模块来迭代检索与给定问题及其选择相关的概念和实体。此外，论文还提出了一种答案选择感知的注意机制，用于融合由预先训练的语言模型编码的所有隐藏层的状态表示。论文作者在CommonsenseQA数据集上进行了实验，实验结果表明，该方法在Commonsenseqa测试集上的准确率上明显优于其他模型。最后，论文进行了对创新的有效性研究，研究结果显示了基于图的迭代知识检索模块和答案选择感知注意模块在从多个知识源检索和合成背景知识方面的有效性。</p>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常识问答大比拼</title>
    <link href="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/"/>
    <url>/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/</url>
    
    <content type="html"><![CDATA[<h2 id="不同的道路"><a href="#不同的道路" class="headerlink" title="不同的道路"></a>不同的道路</h2><img src="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/0.png" class=""><h3 id="不引入相关知识"><a href="#不引入相关知识" class="headerlink" title="不引入相关知识"></a>不引入相关知识</h3><h4 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h4><h5 id="BERT-MLP-Softmax"><a href="#BERT-MLP-Softmax" class="headerlink" title="BERT + MLP + Softmax"></a>BERT + MLP + Softmax</h5><img src="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/1.png" class=""><p>BERT可以换成RoBERTa、XLNet或者ALBERT等。</p><h4 id="Text2Text"><a href="#Text2Text" class="headerlink" title="Text2Text"></a>Text2Text</h4><h5 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h5><p>提出了一种文本到文本的范式，需要指定任务类型。</p><img src="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/4.png" class=""><h5 id="UnifiedQA"><a href="#UnifiedQA" class="headerlink" title="UnifiedQA"></a>UnifiedQA</h5><p>使用单个QA系统，跨越不同QA数据集的格式障碍。虽然基于T5，但不需要指定任务类型。</p><img src="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/5.png" class=""><h3 id="引入相关知识"><a href="#引入相关知识" class="headerlink" title="引入相关知识"></a>引入相关知识</h3><h4 id="ConceptNet-Wikipedia-XLNet-GNN"><a href="#ConceptNet-Wikipedia-XLNet-GNN" class="headerlink" title="ConceptNet + Wikipedia + XLNet + GNN"></a>ConceptNet + Wikipedia + XLNet + GNN</h4><img src="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/2.png" class=""><h4 id="ConceptNet-GPT2-ALBERT-RN"><a href="#ConceptNet-GPT2-ALBERT-RN" class="headerlink" title="ConceptNet + GPT2 + ALBERT + RN"></a>ConceptNet + GPT2 + ALBERT + RN</h4><img src="/2020/11/17/%E5%B8%B8%E8%AF%86%E9%97%AE%E7%AD%94%E5%A4%A7%E6%AF%94%E6%8B%BC/3.png" class=""><h4 id="ConceptNet-ALBERT-KCR"><a href="#ConceptNet-ALBERT-KCR" class="headerlink" title="ConceptNet + ALBERT + KCR"></a>ConceptNet + ALBERT + KCR</h4><ul><li>为每个QA对获取三元组路径<ul><li>找到三元组路径<ul><li>[CLS] stem [SEP] question_concept relation choice_concept [SEP]</li></ul></li><li>没找到三元组路径<ul><li>找到选项实体相关的其他三元组 —— [CLS] stem [SEP] choice_concept relation object [SEP]</li><li>没找到任何三元组 —— [CLS] stem [SEP] question_concept [SEP] choice_concept [SEP]</li></ul></li></ul></li><li>根据以上三种输入模式，经ALBERT文本编码得到文本嵌入hc</li><li>hc经过一个线性分类器得到QA对的置信得分</li></ul><h4 id="Wikipedia-ALBERT"><a href="#Wikipedia-ALBERT" class="headerlink" title="Wikipedia + ALBERT"></a>Wikipedia + ALBERT</h4><ul><li>清洗Wikipedia数据，得到word: definition形式的句子</li><li>输入构造 —— [CLS] ‘Q:’ + question [SEP] ‘A:’ + Choice + 10 recalled word of definition [SEP]</li><li>取ALBERT编码后得到的最后四层隐层向量的平均hc</li><li>hc经一个线性层和Softmax层得到归一化的QA对得分</li></ul>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>预训练模型——开创NLP新纪元</title>
    <link href="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/"/>
    <url>/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/</url>
    
    <content type="html"><![CDATA[<h2 id="预训练模型——开创NLP新纪元"><a href="#预训练模型——开创NLP新纪元" class="headerlink" title="预训练模型——开创NLP新纪元"></a>预训练模型——开创NLP新纪元</h2><p><a href="https://arxiv.org/pdf/2003.08271v3.pdf">论文地址</a></p><p><a href="https://github.com/tomohideshibata/BERT-related-papers">BERT相关论文列表</a></p><p><a href="https://github.com/thunlp/PLMpapers">清华整理-预训练语言模型</a></p><p><a href="https://github.com/cedrickchee/awesome-bert-nlp">awesome-bert-nlp</a></p><p><a href="https://bertlang.unibocconi.it/">BERT Lang Street</a></p><p><a href="https://huggingface.co/models">huggingface models</a></p><h3 id="论文贡献"><a href="#论文贡献" class="headerlink" title="论文贡献"></a>论文贡献</h3><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-1.png" class=""><ul><li><p>对如今自然语言处理研究中常用的预训练模型进行了全面的概述，包括背景知识、模型架构、预训练任务、预训练模型的各种扩展、预训练模型的适应方法、预训练模型相关资源和应用。</p></li><li><p>基于现有的对预训练模型分类方法，从四个不同的角度提出了一个新的分类方法，它从四个不同的角度对现有的原型系统进行分类:</p><ul><li>表示类型</li><li>模型结构</li><li>预训练任务的类型</li><li>特定类型场景的扩展</li></ul></li><li><p>收集了大量的预训练模型的资源，包括预训练模型的开源实现、可视化工具、语料库和论文列表</p></li><li><p>针对预训练模型，提出了几个可能的未来研究方向。</p></li></ul><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="语言表示学习"><a href="#语言表示学习" class="headerlink" title="语言表示学习"></a>语言表示学习</h4><p>一个好的语言嵌入表示应该能够蕴含文本语料中隐含的语言规则和常识信息，例如<strong>词汇的含义、句法结构、语义角色、语用学</strong>等信息。<strong>分布式表示</strong>的核心在于用<strong>低维实值向量</strong>来描述一段文本的含义，该向量的每个维度上的值都没有对应的意义，但是向量<strong>整体代表了一个具体的概念</strong>。</p><h5 id="与上下文无关的嵌入"><a href="#与上下文无关的嵌入" class="headerlink" title="与上下文无关的嵌入"></a>与上下文无关的嵌入</h5><p>将离散的语言符号映射到分布式嵌入空间中，具体来说，对于词汇表 <script type="math/tex">\text{V}</script> 中每个单词 <script type="math/tex">x</script> ，将其映射成一个 <script type="math/tex">d</script> 维的实值向量，由此得到一个由<strong>词汇表中全部单词的嵌入向量作为列向量</strong>的嵌入矩阵 <script type="math/tex">\text{E}^{d × |\text{V}|}</script>，矩阵的列数就是词汇表 <script type="math/tex">\text{V}</script> 中单词的总数 <script type="math/tex">|\text{V}|</script>，矩阵的行数就是嵌入向量的维度 <script type="math/tex">d</script>。因此，<strong>单词 <script type="math/tex">x</script> 的嵌入向量 <script type="math/tex">e_{x}</script> 也可以由其唯一的独热编码 <script type="math/tex">h_{x}</script>乘上嵌入矩阵得到</strong>，即</p><script type="math/tex; mode=display">e_{x} = h_{x}E</script><p><strong>问题</strong></p><ul><li>嵌入是<strong>静态</strong>的，即单词的嵌入与上下文无关。然而当遇到<strong>多义词</strong>时，不跟据上下文语境的话，无法判断其真实代表的含义。</li><li><strong>词汇量不足</strong>。采用字符或者单词的<strong>子词</strong>作为基本表示单位。例如<strong>CharCNN、FastText</strong>和<strong>Byte-Pair Encoding</strong>等表示方法。</li></ul><h5 id="语境嵌入"><a href="#语境嵌入" class="headerlink" title="语境嵌入"></a>语境嵌入</h5><p>为了解决与上下文无关嵌入存在的问题，需要区分单词在不同语境下代表的语义。</p><p><strong>利用不同的神经上下文编码器 <script type="math/tex">f_{\mathrm{enc}} \left(·\right)</script> 对与上下文无关的嵌入 <script type="math/tex">x_{t}</script> 进行编码，得到蕴含上下文信息的语境嵌入 <script type="math/tex">h_{t}</script>。</strong></p><script type="math/tex; mode=display">\left[\mathbf{h}_{1}, \mathbf{h}_{2}, \cdots, \mathbf{h}_{T}\right]=f_{\mathrm{enc}}\left(x_{1}, x_{2}, \cdots, x_{T}\right)</script><p>下图是展示了利用神经编码器对上下文无关嵌入向量进行编码后得到语境嵌入，然后将其用于下游的面向具体任务的模型。</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-2.png" class=""><h4 id="神经上下文编码器"><a href="#神经上下文编码器" class="headerlink" title="神经上下文编码器"></a>神经上下文编码器</h4><p>大多数神经上下文编码器可以归结为两类：</p><ul><li><p><strong>序列模型</strong> —— 按照顺序捕捉单词的局部上下文信息</p><ul><li><strong>卷积模型</strong> —— 将输入句子中单词的嵌入作为输入，通过卷积运算<strong>聚集</strong>某个单词来自其<strong>邻居的局部信息</strong>来获取该单词的含义</li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-3.png" class=""><ul><li><strong>递归模型</strong> —— 递归模型<strong>捕捉短记忆单词的上下文表示</strong>，如<strong>LSTMs 和GRUs</strong>。从一个词的两边收集信息，但递归模型的性能往往受到<strong>长句子语义依赖问题</strong>的影响。</li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-4.png" class=""><ul><li><strong>优点</strong><ul><li>易于训练</li><li>对于各种自然语言处理任务能获得良好的结果</li></ul></li><li><strong>缺点</strong><ul><li>学到的单词的上下文表示具有局部性偏差</li><li>难以捕捉单词之间的长期交互</li></ul></li></ul></li></ul><ul><li><p><strong>非序列模型</strong> —— 非序列模型通过预先定义的单词之间的树或图结构来学习上下文表示，例如句法结构或语义关系。经典的模型包括<strong>Recursive NN、TreeLSTM和图卷积网络GCN。</strong></p><ul><li><p><strong>图模型存在的问题</strong> </p><ul><li>如何建立一个好的图结构也是一个具有挑战性的问题</li><li>图结构严重依赖于专家知识或外部NLP工具。</li></ul></li><li><p><strong>全连接自注意力模型</strong> </p><ul><li>为所有单词嵌入建立全连接图，让模型自行学习关系结构。</li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-5.png" class=""><ul><li>连接权重由自注意力机制动态计算得到</li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-6.png" class=""><ul><li><strong>Transformer</strong></li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-7.png" class=""></li><li><p><strong>优点</strong></p><ul><li>直接对序列中每两个单词之间的依存关系进行建模，更强大，已成为当前预训练模型采用的主流架构</li><li>更适合对语言的长程依存关系进行建模</li></ul></li><li><p><strong>缺点</strong></p><ul><li>由于其复杂而又沉重的架构以及较小的模型偏差，Transformer通常需要一个大的训练语料库进行训练</li><li>训练时，容易在小的或中等大小的数据集上出现过拟合问题</li></ul></li></ul></li></ul><h4 id="预训练模型诞生背景"><a href="#预训练模型诞生背景" class="headerlink" title="预训练模型诞生背景"></a>预训练模型诞生背景</h4><p>随着深度学习的发展，模型参数的数量迅速增加。需要更大的数据集来充分训练模型参数并防止过度拟合。然而，对于大多数自然语言处理任务来说，构建大规模标注数据集是一个巨大的挑战，因为标注成本非常昂贵，尤其是对于语法和语义相关的任务。相比之下，大规模的无标签语料库相对容易构建。</p><p>为了利用大量未标记的文本数据，可以首先从它们那里学习一个好的表示，然后将这些表示用于其他任务。研究表明，借助于从大型未标注语料库的语料库中提取的表征，许多自然语言处理任务的性能有了显著提高。</p><p>预训练的优势有如下几点：</p><ul><li>在大规模文本语料库中能学习到一般的语言表示以用于下游任务</li><li>使得下游任务采用的模型能更好地被初始化，并获得更好的泛化表现，加速下游任务模型的收敛</li><li>预训练可以看作一种正则化的方式，避免模型在小规模数据上过拟合</li></ul><h4 id="预训练模型的发展史"><a href="#预训练模型的发展史" class="headerlink" title="预训练模型的发展史"></a>预训练模型的发展史</h4><p>预训练一直是学习模型参数的一种有效策略，预训练完毕之后，利用标记数据对模型参数进行微调以适应下游任务。</p><h5 id="第一代：预训练词嵌入"><a href="#第一代：预训练词嵌入" class="headerlink" title="第一代：预训练词嵌入"></a>第一代：预训练词嵌入</h5><p><strong>模型发展：</strong></p><ul><li><strong>NNLM</strong></li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-8.png" class=""><p><strong>学习任务</strong></p><p>输入某个句子中某个单词的前 <script type="math/tex">t-1</script> 个单词，要求NNLM网络<strong>最大化</strong>第 <script type="math/tex">t</script> 个位置出现该单词的概率，例如给定文本句子：”The most popular pre-train models is Bert”，根据前6个单词，让模型预测单词”Bert”即最大化以下概率：</p><script type="math/tex; mode=display">P\left(W_{t}="Bert" \mid W_{1},W_{2},W_{3},\cdots，W_{t-1};\theta\right)</script><p>其中 <script type="math/tex">W_{i}</script> 为单词的独热编码，它们作为模型的初始输入，<script type="math/tex">W_{i}</script> 乘上矩阵 <script type="math/tex">Q</script> 之后就得到对应单词的word embedding值 <script type="math/tex">C\left(W_{i}\right)</script>。将每个单词的word embdding拼接起来，上接隐层向量，然后经过一个 <script type="math/tex">softmax</script> 层预测后面紧跟着应该接哪个词。</p><p>事实上，矩阵 <script type="math/tex">Q</script> 的每一行代表着对应单词的word embedding值，只不过矩阵 <script type="math/tex">Q</script> 的内容也是模型参数，需要学习获得，<script type="math/tex">Q</script> 最初用随机值初始化。当模型训练完毕，矩阵 <script type="math/tex">Q</script> 就是NNLM模型在大规模文本语料库上完成语言模型的训练任务后得到的副产品，这个 <script type="math/tex">Q</script> 的每一行都是对应单词的嵌word embedding。</p><ul><li><p><strong>Word2Vec</strong> —— 基于预测的模型(两种不同训练方式)</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-9.png" class=""><ul><li><p><strong>CBOW</strong> —— 从上下文预测中间词(完形填空)</p></li><li><p><strong>Skip-Gram</strong> —— 从中间词预测上下文</p></li></ul></li><li><p><strong>Glove</strong> —— 基于统计的模型</p><p>基于全局语料库构建词的<strong>共现矩阵</strong>，矩阵的每一行是一个word，每一列是context。共现矩阵就是计算每个word在每个context出现的频率。通过对词的共现计数矩阵进行降维，来得到词向量；首先需要根据整个语料建立一个大型的体现词共现情况的矩阵，其<strong>目标是优化减小重建损失</strong>(reconstruction loss)，即降维之后的向量能尽量表达原始向量的完整信息。</p><p>GloVe 相对于 Word2Vec 有一个优点是<strong>更容易并行化执行</strong>，可以更快，更容易地在大规模语料上训练。</p></li></ul><p><strong>第一代预训练词嵌入的优势：</strong></p><ul><li>尽管网络结构简单，但是仍然可以学习到高质量的单词嵌入来捕捉单词之间潜在的句法和语义相似性</li></ul><p><strong>不足之处：</strong></p><ul><li>得到的词嵌入向量与上下文无关，当词嵌入被应用于下游任务时，模型的其他参数需要重新训练。</li></ul><h5 id="第二代：预训练语境编码器"><a href="#第二代：预训练语境编码器" class="headerlink" title="第二代：预训练语境编码器"></a>第二代：预训练语境编码器</h5><p><strong>模型发展</strong>：</p><script type="math/tex; mode=display">\text{ELMO} \rightarrow \text{GPT} \rightarrow \text{BERT}</script><p>由于大多数自然语言处理任务超出了单词层面，自然要在句子层面或更高层面对神经编码器进行预训练。神经编码器的输出向量也被称为上下文单词嵌入，因为它们根据单词的上下文来表示单词的语义。</p><p>研究者发现，序列模型<strong>Seq2Seq</strong>在做文本分类任务时，编码器和解码器的权重用两种语言模型的预训练权重初始化，然后用标记数据微调。模型的表现大大提升。</p><p>现如今，预训练模型通常使用<strong>更大规模</strong>的语料库、更复杂的神经网络模型结构(例如，Transformer)和新的预训练任务来训练。</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-10.png" class=""><ul><li><p><strong>ELMo</strong></p><ul><li><p><strong>预训练阶段</strong></p><ul><li>利用<strong>语言模型</strong>进行预训练，该语言模型的任务是根据单词的上下文序列正确预测该单词。</li><li><strong>ELMO</strong>网络结构<strong>采用了双层双向LSTM</strong>，左右两端分别是正反向的双层的LSTM编码器。</li><li>模型输入的句子中每个单词都能得到对应的三个嵌入向量：最底层的(<strong>黄色部分</strong>)是词嵌入Word Embedding，第一层双向LSTM中对应单词位置的Embedding，蕴含单词的<strong>句法信息</strong>；然后第二层LSTM中对应单词位置的Embedding，蕴含单词的<strong>语义信息</strong>。</li></ul></li><li><p><strong>微调阶段</strong></p><ul><li>将下游任务模型的输入通过ELMO进行编码得到文本嵌入，集成三种Embedding，将整合后的Embedding用于下游任务模型网络结构中对应单词的输入。</li></ul></li><li><p><strong>特点</strong></p><ul><li>采用了典型的<strong>预训练-微调</strong>的两阶段过程</li><li>预训练过程中，不仅学会了单词的word embedding，还学到了一个双层双向的LSTM网络结构，这个双层双向的网络结构可以用来提取文本的句法信息、语义信息。</li></ul></li><li><p><strong>不足</strong></p><ul><li>LSTM的<strong>特征抽取能力</strong>远比不上Transformer</li><li>双向拼接的<strong>融合特征的能力</strong>不够强</li></ul></li></ul></li><li><p><strong>GPT</strong></p><ul><li><p><strong>预训练阶段</strong></p><ul><li>预训练的过程其实和ELMO类似，仍然以语言模型为目标任务，但是<strong>语言模型改成单向</strong>的，即只根据上文正确预测当前位置的单词，而把单词的下文完全抛开。</li><li>特征抽取器换成了<strong>Transformer</strong>,特征抽取的能力大大提升</li></ul></li><li><p><strong>微调阶段</strong></p><ul><li><p>对于不同的下游任务，<strong>网络结构要向GPT的网络结构看齐</strong>。在做下游任务的时候，利用预训练好的参数初始化GPT的网络结构，这样通过预训练学到的语言学知识就被引入到下游任务中。</p></li><li><p>模型参数初始化后，用下游任务去训练这个网络，对网络参数进行Fine-tuning，使得网络更适合解决下游问题。</p></li><li><p>改造下游任务<br>（1）对于<strong>分类</strong>问题，加上一个起始和终结符号即可；<br>（2）对于<strong>句子关系</strong>判断问题，比如Entailment NLI，两个句子中间再加个分隔符即可；<br>（3）对<strong>文本相似性</strong>判断问题，把两个句子顺序颠倒下做出两个输入即可，这是为了告诉模型句子顺序不重要；<br>（4）对于<strong>多项选择</strong>问题，则多路输入，每一路把文章和答案选项拼接作为输入即可</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-12.png" class=""></li></ul></li><li><p><strong>特点</strong></p><ul><li>训练的是单向语言模型</li><li>采用更强大的特征提取器Transformer</li></ul></li><li><p><strong>不足</strong></p><ul><li>单向语言模型改成双向就好了</li></ul></li></ul></li><li><p><strong>BERT</strong></p><ul><li><p><strong>预训练阶段</strong></p><ul><li><p><strong>MLM(掩盖语言模型)</strong></p><p>（1）<strong>MLM</strong>任务，即<strong>随机屏蔽</strong>(MASK)部分输入token，然后只预测那些被屏蔽的token。</p><p>（2）但是这么干之后，预训练阶段和finetuning阶段之间就不匹配了，因为在finetuning期间不会见到[MASK]。为了解决这个问题，BERT的做法是：不总是用实际的[MASK]替换被“masked”的词汇。相反，训练一个数据生成器随机选择15％的token，执行以下过程：</p><p><strong>80％</strong>的时间：用<strong>[MASK]标记替换</strong>单词，例如，my dog is hairy → my dog is [MASK]<br><strong>10％</strong>的时间：用一个<strong>随机的单词替换</strong>该单词，例如，my dog is hairy → my dog is apple<br><strong>10％</strong>的时间：保持单词<strong>不变</strong>，例如，my dog is hairy → my dog is hairy. </p><p>（3）<strong>缺陷</strong>：MLM模型下，一些单词会被随机替换，而Transformer的encoder部分不知道它将被要求预测的那些单词或哪些单词已被随机单词替换，因此它被迫保持每个输入token的分布式上下文表示。同时，由于训练MLM时，每个batch只预测了15％的token，这表明模型可能需要更多的预训练步骤才能收敛。这无疑增加了训练成本。</p></li><li><p>和GPT不同的地方在于，BERT采用和ELMO一样的<strong>双向语言模型任务</strong>作为预训练任务；</p></li><li><p>和ELMO不同的地方在于，BERT采用和GPT一样的特征提取器<strong>Transformer</strong>，集两家之所长。</p></li></ul></li><li><p><strong>微调阶段</strong></p><ul><li><p>和GPT一样，BERT也面临对下游任务进行改造的问题</p></li><li><p>改造下游任务</p><p><strong>（1）句子对分类</strong> —— 在句子开头加上[<strong>CLS</strong>]，后接单句的组成token，句子对之间用[<strong>SEP</strong>]分隔开，最后[<strong>CLS</strong>]对应位置输出的向量 <script type="math/tex">C</script> 由于不具备特别的语义特征，因此能更好地表示整个<strong>句对的语义信息</strong>。最后， 把第一个起始符号对应的<strong>Transformer</strong>最后一层位置上的输出 <script type="math/tex">C</script> 串接一个 <script type="math/tex">\mathbf{softmax}</script> 分类层对句对关系进行分类</p><p><strong>（2）单句分类</strong> —— [<strong>CLS</strong>]作为句子开头，后接单句的组成token，同样[<strong>CLS</strong>]对应位置输出的向量 <script type="math/tex">C</script> 后接上一个 <script type="math/tex">\mathbf{softmax}</script>分类器对句子进行分类</p><p><strong>（3）问答</strong> —— [<strong>CLS</strong>]作为句子开头，问题句的组成token和背景文本句的组成token用[<strong>SEP</strong>]隔开，将每个属于背景句子的token所在对应位置的输出向量与<strong>Start</strong>向量<strong>做点积算得分</strong>，根据得分确定答案在背景文本中的起始位置，结束位置的确定也是一样。最后在背景文本中，<strong>起始位置和结束位置之间对应的这段文本就当作问题的最终回答</strong>。</p><p><strong>（4）序列标注</strong> —— [<strong>CLS</strong>]作为句子开头，后接单句的组成token，将每个token对应位置输出的向量输入到一个多分类器中，输出每个token的标注分类预测。</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-13.png" class=""></li></ul></li><li><p><strong>特点</strong></p><ul><li><p><strong>MLM</strong>双向语言模型</p></li><li><p><strong>Transformer</strong>做特征提取器</p></li><li><p><strong>BERT</strong>输入部分的处理</p><p><strong>输入部分是个线性序列</strong>，两个句子通过分隔符分割，最前面和最后增加两个标识符号。每个单词有三个embedding</p><p>(1)<strong>单词embedding</strong> </p><p>​    预训练后得到的单词Embedding。</p><p>(2)<strong>位置embedding</strong></p><p>​    自注意力机制没有位置概念，每个位置等同看待，为了弄清楚token所在位置，需要引入位置嵌入，告诉模型当前的token处于句子的什么位置。</p><p>(3)<strong>句子embedding</strong></p><p>​    整个句子的Embedding代表了整个句子的语义信息，句子嵌入需要给到那个句子中每个token。</p><p>把单词对应的三个embedding叠加，就形成了Bert的输入。</p></li></ul></li></ul></li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-14.png" class=""><ul><li><p><strong>不足</strong></p><ul><li>同预训练阶段<strong>MLM</strong>模型的缺陷</li></ul></li></ul><h3 id="预训练模型概览"><a href="#预训练模型概览" class="headerlink" title="预训练模型概览"></a>预训练模型概览</h3><h4 id="预训练任务"><a href="#预训练任务" class="headerlink" title="预训练任务"></a>预训练任务</h4><h5 id="语言模型-LM"><a href="#语言模型-LM" class="headerlink" title="语言模型(LM)"></a>语言模型(LM)</h5><p>语言模型通常特指自回归语言模型或者单向语言模型。</p><ul><li><strong>任务</strong> —— 给定上文，根据紧接着的下一词汇在词汇表中的概率分布输出更可能的下文，即最大化句子出现的概率。给定一串文本序列 <script type="math/tex">x_{1:T} = \left[ x_{1},x_{2}, \dots, x_{T} \right]</script>，其联合分布概率可以表示为如下条件概率的乘积：</li></ul><script type="math/tex; mode=display">p\left(\mathbf{x}_{1: T}\right)=\prod_{t=1}^{T} p\left(x_{t} \mid \mathbf{x}_{0: t-1}\right)</script><p>其中，<script type="math/tex">x_{0}</script> 为起始标记 <script type="math/tex">[Start]</script> 对应的token。上述条件概率 <script type="math/tex">p\left(x_{t} \mid \mathbf{x}_{0: t-1}\right)</script> 可以通过计算给定语境下(即上文<script type="math/tex">x_{0:t-1}</script>) 词汇表中所有词的概率分布来建模，其中，语境上文又可以通过神经编码器 <script type="math/tex">f_{enc}(·)</script> 来进行编码，利用一个预测层 <script type="math/tex">g_{LM}(·)</script> 输出词汇表中所有词在当前位置出现的概率分布。</p><script type="math/tex; mode=display">p\left(x_{t} \mid \mathbf{x}_{0: t-1}\right)=g_{LM}( f_{enc}(x_{0:t-1}))</script><p>当给定一个巨大的语料库时，可以用最大似然估计来训练整个网络。</p><ul><li><strong>缺点</strong> —— 每个token的表示只编码了上文的token和它自己。然而，更好的文本语境表示应该编码来自上文和下文两个方向的上下文信息。</li><li><strong>改进</strong> —— 考虑单向LM的缺陷，用两个单向LM组合起来构成双向LM(BiLM)。BiLM由两个单向LM组成：一个向前的从左到右LM和一个向后的从右到左LM。</li><li><strong>代表模型</strong><ul><li>单向 —— GPT、GPT2、GPT3</li><li>双向 —— ELMO</li></ul></li></ul><h5 id="掩盖语言模型-MLM"><a href="#掩盖语言模型-MLM" class="headerlink" title="掩盖语言模型(MLM)"></a>掩盖语言模型(MLM)</h5><ul><li><strong>任务</strong> —— 完形填空(cloze task)，从文本中的其他词预测当前被掩盖位置最可能出现的词。由于是同时考虑文本的上文和下文对掩盖词进行预测，因此MLM很好地克服了标准单向线性模型语境编码不完全的缺点。</li><li><strong>缺点</strong> —— 由于MLM首先会从输入文本中随机掩盖掉一些token，然后用其余的token来预测掩盖掉的token。因此，这种预训练方法会在预训练阶段和微调阶段之间造成不匹配，因为 <script type="math/tex">[MASK]</script> 不会在微调阶段出现。</li><li><strong>改进</strong>  —— 不总是用 <script type="math/tex">[MASK]</script> 进行替换，训练一个数据生成器<ul><li>在80%的时间内使用特殊的[MASK]进行替换</li><li>在10%的时间内使用随机的token执行替换</li><li>在10%的时间内使用原始token来执行替换</li></ul></li><li><strong>代表模型</strong> —— BERT及其庞大的BERT家族</li></ul><h5 id="排列语言模型-PLM"><a href="#排列语言模型-PLM" class="headerlink" title="排列语言模型(PLM)"></a>排列语言模型(PLM)</h5><p>虽然MLM效果惊人，但是不能忽视的是，MLM在预训练中使用的一些特殊标记(如[MASK])在模型应用于下游任务时并不存在，这导致预训练和微调之间存在差距。为了克服这个问题，提出了排列语言模型PLM。</p><ul><li><strong>任务</strong> —— 基于输入序列的随机排列的语言建模。简单来说，就是从所有可能的排列中随机抽样一个排列。然后，将排列序列中的一些token作为目标，然后训练模型来预测这些目标。需要注意的是，这种随机排列不会影响序列的自然位置，仅会定义token预测的顺序。</li><li><strong>代表模型</strong> —— XLNet</li></ul><h5 id="去噪自编码器-DAE"><a href="#去噪自编码器-DAE" class="headerlink" title="去噪自编码器(DAE)"></a>去噪自编码器(DAE)</h5><ul><li><strong>任务</strong> —— 输入部分损坏的文本，重建原始的未失真的文本。</li></ul><p>破坏文本的方式有：</p><ol><li>token掩盖：从输入中随机采样token，并用[MASK]替换它们。</li><li>token删除：从输入中随机删除token。与掩盖token不同，模型需要确定缺失输入的位置。</li><li>文本填充：像SpanBERT一样，许多文本跨度被采样并用单个[MASK]标记替换。每个跨度长度由泊松分布(λ = 3)得出。该模型需要预测一个跨度中缺少多少个token。</li><li>句子排列：根据句号将文档分成句子，并以随机顺序排列这些句子。</li><li>文档翻转：随机均匀地选择一个token，并翻转文档，使其从该token开始。模型需要识别文档的真正开始位置</li></ol><h5 id="比较学习-CL"><a href="#比较学习-CL" class="headerlink" title="比较学习(CL)"></a>比较学习(CL)</h5><ul><li><strong>总体任务</strong> —— 假设一些观察到的文本对在语义上比随机抽样的文本更相似。学习文本对 <script type="math/tex">(x，y)</script> 的得分函数 <script type="math/tex">s(x，y)</script> 以最小化目标函数：</li></ul><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{CTL}}=\mathbb{E}_{x, y^{+}, y^{-}}\left[-\log \frac{\exp \left(s\left(x, y^{+}\right)\right)}{\exp \left(s\left(x, y^{+}\right)\right)+\exp \left(s\left(x, y^{-}\right)\right)}\right]</script><p>其中，<script type="math/tex">\left(x, y^{+}\right)</script> 是更相似的一对，<script type="math/tex">y^{+}</script> 和 <script type="math/tex">y^{-}</script> 分别为正样本和负样本。文本对的得分函数 <script type="math/tex">s(x，y)</script> 通常通过训练神经网络来学习。</p><p>训练的方式有两种：</p><script type="math/tex; mode=display">s(x, y)=f_{\mathrm{enc}(x)}^{\mathrm{T}} f_{\mathrm{enc}(y)}</script><script type="math/tex; mode=display">s(x, y)=f_{\text {enc }}(x \oplus y)</script><ul><li><strong>代表任务</strong> <ul><li>下一句预测(NSP) —— NSP训练模型来区分两个输入句子是否是来自训练语料库的连续片段。具体来说，在为每个预训练例子选择句子对时，50%的时候，第二句是第一句的实际下一句，50%的时候，是从语料库中随机抽取的一句。通过这样做，它能够教模型理解两个输入句子之间的关系，从而有利于对该信息敏感的下游任务，例如问答和自然语言推理。 但是NSP任务的有效性和必要性备受质疑。</li><li>句子顺序预测(SOP) —— 和NSP不同，SOP使用同一文档中的两个连续片段作为正面示例，使用相同的两个连续片段，但它们的顺序交换作为反面示例。</li></ul></li></ul><h4 id="模型分类"><a href="#模型分类" class="headerlink" title="模型分类"></a>模型分类</h4><p>为了阐明自然语言处理中现有预训练模型之间的关系，可以从四个不同的角度对现有预训练模型进行分类：</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-15.png" class=""><ul><li><p>表示类型</p><ul><li>与上下文独立的表示 —— Word2Vec、Glove等</li><li>与上下文相关的表示 —— ELMO、GPT、BERT等</li></ul></li><li><p>架构(基础网络)</p><ul><li>LSTM —— ELMO</li><li>Transformer<ul><li>encoder —— BERT</li><li>decoder —— GPT（使用了三角矩阵实现了掩盖自注意力机制，即不允许模型在预测的时候看到下文）</li><li>full</li></ul></li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-16.png" class=""></li><li><p>预训练任务</p><ul><li>监督学习 —— 学习一个函数，该函数基于由输入输出对组成的训练数据将输入映射到输出。</li><li>无监督 —— 从未标记的数据中发现一些内在的知识，如LM。</li><li>自监督 —— 监督学习和非监督学习的结合，学习范式和监督学习完全一样，只是训练数据的标签是自动生成的。关键思想是从其他部分以某种形式预测输入的任何部分。如MLM。</li></ul></li><li><p>扩展：特定场景下的预训练模型，包括知识丰富的预训练模型、多语言或特定语言的预训练模型、多模型预训练模型、特定领域的预训练模型等</p></li></ul><h4 id="模型分析"><a href="#模型分析" class="headerlink" title="模型分析"></a>模型分析</h4><h5 id="非上下文词嵌入"><a href="#非上下文词嵌入" class="headerlink" title="非上下文词嵌入"></a>非上下文词嵌入</h5><ul><li><strong>思想</strong> —— 通过神经网络语言模型学习的单词表示能够捕捉语言中的语言规律，单词之间的关系可以通过特定关系的向量偏移来表征。例如，<script type="math/tex">vec(“China”) − vec(“Beijing”) ≈ vec(“Japan”) −vec(“Tokyo”)</script> ，另外，经过神经语言模型训练得到的词向量还具有组合性，<script type="math/tex">vec(“Germany”) + vec(“capital”) ≈ vec(“Berlin”)</script>。</li><li><strong>缺点</strong> —— 这种分布式单词表示擅长预测分类属性(例如，狗是一种动物)，但不能真正学习属性(例如，天是蓝的)。而且，考虑到多义词需要结合上下文语境进行词义的判断，而这种与上下文无关的分布式词表示往往无法代表词的正确意思。</li></ul><h5 id="上下文词嵌入"><a href="#上下文词嵌入" class="headerlink" title="上下文词嵌入"></a>上下文词嵌入</h5><ul><li><strong>思想</strong> —— 在做语言模型任务时，把上下文语境文本融合进词表示向量，使得词表示向量能够蕴含除词本义之外的上下文语义知识信息和语言学信息。<ul><li>语言学信息 —— 研究人员从BERT中提取依赖树和支持树，证明了BERT对语法结构进行编码的能力。<ul><li>语言特征似乎表现在单独的语义和句法子空间中</li><li>注意矩阵包含语法表征</li><li>BERT非常精细地区分词义。</li></ul></li><li>语义知识信息 —— 除了语言知识，预训练模型还可以存储训练数据中呈现的世界知识。探索世界知识的一个简单方法是用“填空”完形填空语句来查询BERT，例如，“但丁诞生于[MASK]”。研究人员通过从几个知识来源手动创建单标记完形填空语句(查询)来构建LAMA(语言模型分析)任务。他们的实验表明BERT包含的世界知识比传统的信息抽取方法更有竞争力。</li></ul></li></ul><h3 id="预训练模型拓展"><a href="#预训练模型拓展" class="headerlink" title="预训练模型拓展"></a>预训练模型拓展</h3><h4 id="基于知识增强"><a href="#基于知识增强" class="headerlink" title="基于知识增强"></a>基于知识增强</h4><ul><li><strong>思想</strong> —— 将外部知识纳入预训练模型</li><li><strong>代表模型</strong><ul><li>LIBERT —— 通过额外的语言限制任务整合语言知识</li><li>SentiLR —— 集成每个词的情感极性，将MLM扩展为具有标签感知能力的MLM(LA-MLM)</li><li>SenseBERT —— 经过预先训练，不仅可以预测掩码标记，还可以预测它们在WordNet中的超集。</li><li>ERNIE —— 将预先在知识图上训练的实体嵌入与文本中相应的实体提及相结合，以增强文本表示。</li><li>KnowBERT —— 将BERT与实体链接模型结合起来，以端到端的方式整合实体表示。</li><li>K-BERT —— 允许在对下游任务进行微调的过程中注入事实知识。</li><li>知识-文本融合模型 —— 机器阅读理解中获取相关语言和事实知识。</li></ul></li></ul><h4 id="基于多语言和特定语言"><a href="#基于多语言和特定语言" class="headerlink" title="基于多语言和特定语言"></a>基于多语言和特定语言</h4><ul><li>多语言<ul><li>跨语言理解</li><li>跨语言生成</li></ul></li><li>特定语言</li></ul><h4 id="基于多模态"><a href="#基于多模态" class="headerlink" title="基于多模态"></a>基于多模态</h4><p>这些多模态模型中的绝大多数是为一般的视觉和语言特征编码而设计的。这些模型是在大量跨模态数据的基础上进行预训练的（如带有口语词的视频或带有字幕的图像），并结合扩展的预训练任务来充分利用多模态特征。</p><h5 id="视频-文本-Video-Text"><a href="#视频-文本-Video-Text" class="headerlink" title="视频-文本(Video-Text)"></a>视频-文本(Video-Text)</h5><p>视频分别由基于CNN的编码器和现成的语音识别技术进行预处理。使用一个单独的Transformer编码器在处理过的数据上进行训练，学习视频字幕等下游任务的视觉语言表示。代表模型有，VideoBERT和CBT。</p><h5 id="图像-文本-Image-Text"><a href="#图像-文本-Image-Text" class="headerlink" title="图像-文本(Image-Text)"></a>图像-文本(Image-Text)</h5><p>引入图像-文本对，旨在微调下游任务，如视觉问题回答(<strong>VQA</strong>)和视觉常识推理(<strong>VCR</strong>)。</p><p><strong>分类：</strong></p><ul><li>采用两个独立的编码器来独立地表示图像和文本， 例如ViLBERT和LXMERT。</li><li>使用single-stream unified Transformer,虽然这些模型体系结构不同，但是在这些方法中引入了类似的预训练任务，例如MLM和图像-文本匹配。例如，VisualBERT，B2T2，VLBERT， Unicoder-VL和UNITER。</li></ul><h5 id="音频-文本-Audio-Text"><a href="#音频-文本-Audio-Text" class="headerlink" title="音频-文本(Audio-Text)"></a>音频-文本(Audio-Text)</h5><p>SpeechBERT模型试图用一个Transformer编码器编码音频和文本以建立一个端到端的语音问答(SQA)模型。</p><h4 id="基于特定领域与任务"><a href="#基于特定领域与任务" class="headerlink" title="基于特定领域与任务"></a>基于特定领域与任务</h4><p>大多数预训练模型都是在维基百科等通用领域语料库上进行预训练的，这限制了它们在特定领域或任务上的应用。</p><ul><li><strong>训练特定领域预训练模型</strong><ul><li>生物医学 —— BioBERT</li><li>科学 —— SciBERT </li><li>临床医学 —— ClinicalBERT</li></ul></li><li><strong>利用通用领域预训练模型适应具体任务</strong><ul><li>情感分析 —— 感知情感标签的MLM</li><li>文本摘要 —— 间歇句生成</li><li>不流畅检测 —— 噪声词检测</li></ul></li></ul><h4 id="模型压缩"><a href="#模型压缩" class="headerlink" title="模型压缩"></a>模型压缩</h4><ul><li><strong>动机</strong> —— 预训练模型参数量过于庞大，很难在现实应用和资源受限的设备上进行部署，因此，如何压缩模型也成为了研究的一个热点。</li><li><strong>模型压缩方法</strong> —— 一种减小模型尺寸和提高计算效率的潜在方法<ul><li><strong>模型修剪</strong> —— 去除不重要的参数，具体来说，就是去除部分神经网络(如权值、神经元、层、通道、注意头)，从而达到减小模型规模、加快推理时间的效果。修剪选择和修剪时机的把握有待研究。</li><li>连接权重量化 —— 用较少的比特表示参数，将精度较高的参数压缩到较低的精度。</li><li><strong>参数共享</strong> —— 对于那些相似的模型单元，共享它们的参数。这种方法广泛应用于CNNs、RNNs和Transformer。例如，ALBERT使用跨层参数共享和因子化嵌入参数化来减少模型的参数。虽然参数数量大大减少，但是ALBERT的训练和推理时间甚至比标准的BERT还要长。通常，参数共享不会提高推理阶段的计算效率。</li><li><strong>知识提取</strong> —— 在原模型的基础上，根据原模型的中间结果学习一个更小的模型</li><li>模块替换 —— 用更紧凑的模块替换原模型具有相似功能的模块。例如使用<strong>Theseus-Compress</strong>，压缩模型的同时保持98%的模型性能，速度是原来的1.4倍。</li></ul></li></ul><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-17.png" class=""><h3 id="预训练模型应用于下游任务"><a href="#预训练模型应用于下游任务" class="headerlink" title="预训练模型应用于下游任务"></a>预训练模型应用于下游任务</h3><h4 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h4><p>迁移学习是将知识从源任务(或领域)调整到目标任务(或领域)。</p><img src="/2020/11/16/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E5%BC%80%E5%88%9BNLP%E6%96%B0%E7%BA%AA%E5%85%83/PTM-18.png" class=""><h4 id="如何迁移"><a href="#如何迁移" class="headerlink" title="如何迁移"></a>如何迁移</h4><ul><li><p>选择合适的预训练任务、模型架构和语料库</p><ul><li>不同的预训练任务有各自的偏向，对不同的任务有不同的效果。例如，NSP任务使预训练模型学习了两句话之间的关系。因此，训练后的预训练模型可以受益于问答和自然语言推理(NLI)等下游任务。</li><li>BERT虽然能很好地解决自然语言推理任务，但是很难用于生成式的任务。</li><li>下游任务的数据分布应该接近预训练模型。</li></ul></li><li><p>选择合适的层</p><ul><li><p>给定一个预先训练的深度模型，不同的层应该捕获不同种类的信息，例如词性标注、解析、长期依赖、语义角色、共指。对于基于RNN的模型，研究表明，多层LSTM编码器的不同层学习到的表示有益于不同的任务。</p></li><li><p>有三种方法可以选择表示：</p><ul><li>只选择预先训练的静态嵌入表示，而模型的其余部分仍然需要为新的目标任务从头开始训练。这些部分无法获取更高级别的信息，而这些信息可能更有用。</li><li>顶层表示。最简单有效的方法是将顶层的表示馈入特定任务模型。</li><li>所有层。更灵活的方法是自动选择最佳层：</li></ul><script type="math/tex; mode=display">\mathbf{r}_{t}=\gamma \sum_{l=1}^{L} \alpha_{l} \mathbf{h}_{t}^{(l)}</script><p>​            其中，<script type="math/tex">\alpha</script> 表示 <script type="math/tex">l</script> 层的软最大归一化权重，<script type="math/tex">\gamma</script>是缩放预训练模型输出的向量的标量。混合表示 <script type="math/tex">r_{t}</script> 被输入到特定任务模型中。</p></li></ul></li></ul><h4 id="微调策略"><a href="#微调策略" class="headerlink" title="微调策略"></a>微调策略</h4><ul><li><strong>两阶段微调</strong> —— 在第一阶段，预训练模型被转换成一个由中间任务或语料库微调的模型。在第二阶段，转移的模型被微调到目标任务。</li><li><strong>多任务微调</strong> —— 多任务学习框架下的微调BERT，多任务学习和预训练是互补的技术。</li><li><strong>使用额外的自适应模块进行微调</strong> —— 微调的主要缺点是参数效率低，每个下游任务都有自己的微调参数。因此，更好的解决方案是在原始参数固定的情况下，往预训练模型中注入一些可微调的自适应模块。</li></ul><h3 id="预训练模型资源"><a href="#预训练模型资源" class="headerlink" title="预训练模型资源"></a>预训练模型资源</h3><ul><li><strong>预训练模型的开源实现</strong><ul><li><a href="https://github.com/tmikolov/word2vec">word2vec</a></li><li><a href="https://nlp.stanford.edu/projects/glove">GloVe</a></li><li><a href="https://github.com/facebookresearch/fastText">FastText</a></li><li><a href="https://github.com/huggingface/transformers">Transformer</a></li><li><a href="https://github.com/pytorch/fairseq">Fairseq</a></li><li><a href="https://github.com/flairNLP/flair">Flair</a></li><li><a href="https://github.com/allenai/allennlp">AllenNLP</a></li><li><a href="https://github.com/fastnlp/fastNLP">fastNLP</a></li><li><a href="https://github.com/microsoft/unilm">UniLMs</a></li><li><a href="https://github.com/ymcui/Chinese-BERT-wwm">Chinese-BERT</a></li><li><a href="https://github.com/google-research/bert">BERT</a></li><li><a href="https://github.com/pytorch/fairseq/tree/master/examples/roberta">RoBERTa</a></li><li><a href="https://github.com/zihangdai/xlnet/">XLNet</a></li><li><a href="https://github.com/google-research/ALBERT">ALBERT</a></li><li><a href="https://github.com/google-research/text-to-text-transfer-transformer">T5</a></li><li><a href="https://github.com/PaddlePaddle/ERNIE">ERNIE</a></li><li><a href="https://github.com/salesforce/ctrl">CTRL</a></li><li><a href="https://github.com/jessevig/bertviz">BertViz</a></li><li><a href="https://github.com/bhoov/exbert">exBERT</a></li><li><a href="https://github.com/airaria/TextBrewer">TextBrewer</a></li><li><a href="https://github.com/deepmipt/DeepPavlov">DeepPavlov</a></li></ul></li><li>语料库<ul><li><a href="https://github.com/jcpeterson/openwebtext">OpenWebText</a></li><li><a href="http://commoncrawl.org/">Common Crawl</a></li><li><a href="https://dumps.wikimedia.org/enwiki/">WikiEn</a></li></ul></li></ul><h3 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h3><ul><li>预训练模型还未到达上限 —— 模型可以通过更多的训练步骤和更大的语料库来进一步改进。</li><li>预训练模型架构优化 —— 为预训练模型寻找更有效的模型架构对于获取更大范围的上下文信息非常重要。深度架构的设计具有挑战性，可能会寻求一些自动化方法的帮助，比如神经架构搜索。</li><li>面向任务的预训练和模型压缩</li><li>实现超越微调的知识转移</li><li>提高预训练模型的可解释性和可靠性</li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>[1] Qiu X, Sun T, Xu Y, et al. Pre-trained models for natural language processing: A survey[J]. arXiv preprint arXiv:2003.08271, 2020.</p><p>[2] Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep bidirectional transformers for language understanding[J]. arXiv preprint arXiv:1810.04805, 2018.</p><p>[3] Radford A, Narasimhan K, Salimans T, et al. Improving language understanding by generative pre-training[J]. 2018.</p><p>[4] Yang Z, Dai Z, Yang Y, et al. Xlnet: Generalized autoregressive pretraining for language understanding[C]//Advances in neural information processing systems. 2019: 5753-5763.</p><p>[5] <a href="https://zhuanlan.zhihu.com/p/49271699">从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史 by 张俊林</a></p>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常识Transformer用于自动知识图构建</title>
    <link href="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/"/>
    <url>/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="《COMET：Commonsense-Transformers-for-Automatic-Knowledge-Graph-Construction》"><a href="#《COMET：Commonsense-Transformers-for-Automatic-Knowledge-Graph-Construction》" class="headerlink" title="《COMET：Commonsense Transformers for Automatic Knowledge Graph Construction》"></a>《COMET：Commonsense Transformers for Automatic Knowledge Graph Construction》</h3><p><a href="https://arxiv.org/pdf/1906.05317v2.pdf">论文地址</a></p><p><a href="https://github.com/atcbosselut/comet-commonsense">论文源码</a></p><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><ul><li><strong>目的层面</strong> —— 根据两个当前最常用的常识知识图<strong>ATOMIC</strong>和<strong>ConceptNet</strong>构建一个用于<strong>开发常识知识</strong>的自适应生成模型<strong>COMET</strong>，以协助完成常识知识的<strong>自我补充</strong>。</li></ul><p>​    <strong>COMET</strong>是一个自适应框架，用于通过在知识元组的种子集上训练语言模型来从语言模型构建常识知识库。这些知识元组为<strong>COMET</strong>提供了必须学习的知识库结构和关系，<strong>COMET</strong>学习调整从预处理中学习的语言模型表示，以向种子知识图添加新的节点和边。</p><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/1.png" class=""><ul><li><strong>实验层面</strong> <ul><li>训练知识库 —— 格式为 <script type="math/tex">\{s ,r, o\}</script>的自然语言元组, 其中 <script type="math/tex">s</script> 为元组的短语主语,  <script type="math/tex">r</script> 为元组的关系， <script type="math/tex">o</script> 为元组的短语宾语。例如 <script type="math/tex">\left(s="take \space a \space nap", r=Causes, o="have \space energy" \right)</script>。</li><li>任务 —— 给定 <script type="math/tex">s</script> 和 <script type="math/tex">r</script> 作为输入， 要求生成 <script type="math/tex">o</script>。 </li></ul></li></ul><h4 id="Transformer语言模型"><a href="#Transformer语言模型" class="headerlink" title="Transformer语言模型"></a>Transformer语言模型</h4><p>​    采用<strong>GPT</strong>的语言模型架构构建<strong>COMET</strong>。</p><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/2.png" class=""><h5 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h5><p>​    多头注意力机制 —— 顾名思义， 注意力由多个头部组成，每个头部使用查询 <script type="math/tex">Q</script> 和键 <script type="math/tex">K</script> 来计算一个唯一的点积注意力分布。</p><script type="math/tex; mode=display">\text { ATTENTION }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V</script><p>​    其中，<script type="math/tex">d_{k}</script> 为 <script type="math/tex">Q, \space K, \space V</script> 的输入向量的维度。对于每个注意力头来说，在计算注意力之前， <script type="math/tex">Q, \space K, \space V</script> 被一组矩阵唯一映射。(<strong>对应a图蓝色部分</strong>)</p><script type="math/tex; mode=display">H_{i} = \text { ATTENTION }(QW_{i}^{Q}, KW_{i}^{K}, V_{i}^{V})</script><p>​    <script type="math/tex">H_{i}</script> 为单个注意力头的输出， <script type="math/tex">W_{i}^{Q}, \space W_{i}^{K}, \space W_{i}^{V}</script> 为特定头的关于 <script type="math/tex">Q, \space K, \space V</script> 的映射矩阵。</p><p>​    同时，多个注意力头的输出将被连接在一起。(<strong>对应a图紫色部分</strong>)</p><script type="math/tex; mode=display">\operatorname{MULTIH}(\mathrm{Q}, \mathrm{K}, \mathrm{V})=\left[H_{1} ; \ldots ; H_{b}\right] W^{O}</script><p>​    其中 <script type="math/tex">W^{O}</script> 为输出的映射矩阵。</p><p><strong>多头注意力的输入</strong></p><p>​    如b图所示，当前层多头注意力的输入来源于上一层Transformer Block的输出。其中，输入的 <script type="math/tex">Q</script> 对应于上一层Block的输出 <script type="math/tex">h_{t}^{l-1}</script>，而 <script type="math/tex">K</script> 和 <script type="math/tex">V</script> 对应于所有先前时间步长的前一层块的输出 <script type="math/tex">\mathbf{h}_{t}^{l-1} = \left\{h^{l-1}\right\}_{<t}</script> 。</p><script type="math/tex; mode=display">\operatorname{MULTIATTN}\left(h_{t}^{l-1}\right)=\operatorname{MULTIH}\left(h_{t}^{l-1}, \mathbf{h}_{t}^{l-1}, \mathbf{h}_{t}^{l-1}\right)</script><h5 id="Transformer块"><a href="#Transformer块" class="headerlink" title="Transformer块"></a>Transformer块</h5><p>​    如b图所示，每个Transformer层包含一个架构上相同的Transformer Block块(尽管具有唯一的可训练参数)，该Transformer Block对该块的输入应用以下变换:</p><script type="math/tex; mode=display">\begin{aligned}\tilde{g}^{l} &=\mathrm{MULTIATTN}\left(h^{l-1}\right) \\g^{l} &=\mathrm{LAYERNORM}\left(\tilde{g}^{l}+h^{l-1}\right) \\\tilde{h}^{l} &=\mathrm{FFN}\left(g^{l}\right) \\h^{l} &=\text { LAYERNORM }\left(\tilde{h}^{l}+g^{l}\right)\end{aligned}</script><p>​    其中，<script type="math/tex">\tilde{g}^{l}</script> 为多头注意力的输出，<script type="math/tex">FFN</script> 是一个两层的前馈神经网络(Feedforward Network), 而 <script type="math/tex">LAYERNORM</script>层是对多头注意力层输出以及前馈层输出的正则化操作，操作的输入包含一个残差连接，该连接将前一个操作的输出和输入相加。</p><h5 id="输入编码器"><a href="#输入编码器" class="headerlink" title="输入编码器"></a>输入编码器</h5><p>​    <strong>文本嵌入</strong> —— <script type="math/tex">\mathbf{X}= \{ X^{s}, \space X^{r}, \space X^{o} \}</script>,  其中 <script type="math/tex">X^{s}, \space X^{r}, \space X^{o}</script> 分别代表知识元组 <script type="math/tex">\{s ,r, o\}</script> 中每一项的单词序列，<script type="math/tex">\mathbf{X}</script> 为三者的串联。对于任意 <script type="math/tex">x_{t} \in \mathbf{X}</script> ，单词 <script type="math/tex">x_{t}</script> 的单词嵌入为 <script type="math/tex">e_{t} = \sum x_{t}^{i}</script> ，这里的 <script type="math/tex">\sum</script> 为向量和。</p><p><strong>为何单词嵌入是一种向量和的形式？</strong></p><p>这是因为GPT采用<strong>字节对编码</strong>(BPE)的方式构建字词，准确来说，GPT以子词表中子词作为词嵌入的基本单位的，这里输入的文本中的完整单词在字词表中可能是好几个字词之和，所以在表示完整单词的文本嵌入时，用的是子词嵌入向量的和。关于<strong>字节对编码</strong>的具体步骤，我之前的一篇<a href="https://caoyusang.github.io/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/">文章</a>中有提到，这里不再赘述。    </p><p>​    <strong>位置嵌入</strong> —— 因为transformer是一种自注意力模型，没有token顺序的概念，所以引入位置编码 <script type="math/tex">p_{t}</script> 来指示模型各个token在文本序列中所处的绝对位置。</p><p>​    <strong>最终输入</strong> —— <script type="math/tex">h_{t}^{l} = e_{t} + p_{t}</script>， 其中 <script type="math/tex">l</script> 表示transformer层数， <script type="math/tex">t</script> 代表第 <script type="math/tex">t</script> 个时间步。如c图所示，第一层的输入为： <script type="math/tex">h^{0} = e_{0} + p_{0}</script>，</p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><ul><li><strong>训练任务</strong> —— 给定知识元组 <script type="math/tex">\{ s, \space r, \space o \}</script>，要求以 <script type="math/tex">s</script> 和 <script type="math/tex">r</script> 对应token的串接 <script type="math/tex">\left[ X^{s}, X^{r} \right]</script> 作为输入，模型需要学会生成 <script type="math/tex">o</script> 对应的那些tokens，即 <script type="math/tex">X^{o}</script> 。</li><li><strong>损失函数</strong> —— 标准的语言模型的损失函数，即对数似然函数。</li></ul><script type="math/tex; mode=display">\mathcal{L}=-\sum_{t=|s|+|r|}^{|s|+|r|+|o|} \log P\left(x_{t} \mid x_{<t}\right)</script><p>​    已知前 <script type="math/tex">t-1</script> 个生成的token <script type="math/tex">x_{<t}</script> ，当前第 <script type="math/tex">t</script> 个位置生成token <script type="math/tex">x_{t}</script>的概率为：</p><script type="math/tex; mode=display">P\left(x_{t} \mid x_{<t}\right)=\operatorname{softmax}\left(\mathbf{W}_{\text {vocab}} \cdot \mathbf{h}_{\mathrm{t}}\right)</script><p>​    其中，<script type="math/tex">|s|, \space |r|, \space |o|</script> 分别为短句主语、关系、宾语对应的token数目。 这里 <script type="math/tex">h_{t}</script> 表示在解码时GPT对<script type="math/tex">x_{t}</script> 的最终表示，<script type="math/tex">\mathbf{W}_{\text {vocab}}</script>是GPT使用的词汇表的嵌入矩阵。</p><ul><li><p><strong>实验数据集</strong> —— ATOMIC 和 ConceptNet</p></li><li><p><strong>输入构造</strong></p><ul><li>ATOMIC —— 关系token只有一个</li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/3.png" class=""><ul><li>ConceptNet —— 关系token可能有多个，引入第二组mask来分隔关系token和宾语token。</li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/4.png" class=""></li><li><p><strong>模型参数初始化</strong> —— 使用GPT的预训练模型权重初始化模型，为了微调，往词汇表中加入了一些特殊的token。例如，关系嵌入(如oReact for ATOMIC和IsA for ConceptNet)是通过从标准正态分布中采样来初始化的。</p></li><li><p><strong>超参设置 </strong></p><ul><li><strong>12</strong> layers</li><li><strong>768</strong>-dimensional hidden states </li><li><strong>12</strong> attention heads</li><li>dropout    <strong>0.1</strong></li><li>activation fuction    <strong>GeLU</strong></li><li>batch size    <strong>64</strong></li><li>lr    <strong>6.25e-5</strong> (with a warmup period of 100 minibatches)</li><li>decay method    <strong>linear</strong></li></ul></li></ul><h4 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h4><h5 id="ATOMIC"><a href="#ATOMIC" class="headerlink" title="ATOMIC"></a>ATOMIC</h5><h6 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h6><ul><li>877K 知识元组，涵盖围绕特定事件的社会常识知识</li><li>九个关系维度提炼事件中的常识知识</li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/5.png" class=""><p>​    对应到实验中，ATOMIC事件(例如，“<strong>X goes to the store</strong>”)是短语主体 <script type="math/tex">s</script> ，<strong>xIntent</strong>是短语关系 <script type="math/tex">r</script> ，<strong>causes/effects</strong>(例如，“<strong>to get food</strong>”)是短语客体 <script type="math/tex">o</script>。训练集/开发集/测试集的数目分别为：<strong>710k/80k/87k</strong></p><h6 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h6><ul><li><strong>自动评估</strong></li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/6.png" class=""><p>​    上图为采用自动评估标准的评估结果(评估的是生成 <script type="math/tex">o</script> 的质量和新颖性，第一列对比的模型为<strong>ATOMIC</strong>提出文章中的<strong>baseline</strong>，后面两个是论文提出的COMET模型。从第二列开始都是评估的指标，第二列是困惑度<strong>PPL</strong>，第三列是<strong>BLEU-2</strong>，第三列是模型生成元组所占的比例，第四列是模型生成的未出现在训练集元组中 <script type="math/tex">o</script> 所占的比例(<strong>元组新颖性</strong>)，为了证明模型生成的元组新客体不是唯一的，把产生的新客体的数目作为测试集事件产生的唯一客体集合的函数，就是第五列。</p><ul><li><strong>人工评估</strong></li></ul><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/7.png" class=""><p>​    <strong>BLEU-2</strong>的评估结果表明，<strong>COMET</strong>模型超越了所有baseline的表现，比表现最好的baseline实现了51%的相对表现提升。对于人工评估的结果，<strong>COMET</strong>报告了统计上显著的<strong>相对Avg性能</strong>，比最高基线提高了18%。</p><p>​    为了评估在大型语料库上的预训练如何帮助模型学习产生知识，训练了一个没有用预训练权重初始化的COMET版本(COMET(- pretrain))。通过在不同比例的训练数据上训练模型来评估方法的数据效率。</p><p>​    最后，因为最终目标是能够执行高质量、多样化的知识库构建，所以探索了各种解码方案如何影响候选知识元组的质量，采用了不同生成策略进行了实验，这些策略包括：argmax贪婪解码、波束大小的波束搜索、b=2、5、10和k = 5、10的top-k采样。对于每种解码方法，对每种方法产生的最终候选数进行人工评估，结果如下：</p><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/8.png" class=""><p>​    上述结果表明，使用贪婪解码来产生知识元组，与人工评估ATOMIC测试集相比，仅存在10%的相对性能差距，表明由模型产生的知识接近人工性能。</p><h5 id="ConceptNet"><a href="#ConceptNet" class="headerlink" title="ConceptNet"></a>ConceptNet</h5><h6 id="数据集-1"><a href="#数据集-1" class="headerlink" title="数据集"></a>数据集</h6><ul><li>标准的SRO三元组格式，涵盖大量关系三元组，例如(take a nap,  Causes,  have energy)</li></ul><p>​    对应到实验中，各选取了1200个三元组作为测试集和开发集，包含34个关系类型的100k版本的训练集用于训练模型。</p><h6 id="模型评估-1"><a href="#模型评估-1" class="headerlink" title="模型评估"></a>模型评估</h6><img src="/2020/11/05/%E5%B8%B8%E8%AF%86Transformer%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E7%9F%A5%E8%AF%86%E5%9B%BE%E6%9E%84%E5%BB%BA/9.png" class=""><p><strong>生成质量评估</strong></p><p>​    为了评估生成知识的质量，给出在测试集中生成的正面示例的数量，这些正面示例被评为正确。对于给定的 <script type="math/tex">s \space r \space o \space</script>元组，考虑该模型产生元组是否正确的概率，以50%的概率对分数进行阈值化，以识别正确的预测。</p><p>​    结果表明，该模型可以生成高质量的知识：上表中的<strong>低困惑度</strong>(<strong>PPL</strong>)分数表明其预测的高模型置信度，而高分类器得分Score<strong>(95.25%)</strong>表明知识库补全模型在大多数情况下将生成的元组评分为正确。在人工评估(遵循与ATOMIC相同的设计)中，贪婪解码得到的元组的91.7%被评为正确。</p><p><strong>生成新颖度评估</strong></p><p>​    其中<script type="math/tex">N/T \space sro</script> 达到了<strong>59.25%</strong>，说明有接近<strong>6成</strong>的生成元组未出现在训练集中，显示该模型能够在节点之间生成新的边，甚至创建新的节点(<script type="math/tex">N/T \space o = 3.75</script> ，即<strong>3.75%的节点是新的</strong>)来扩展知识图的大小。但是需要注意的是，有一些新产生的元组仅仅是训练集中元组的简化形式。为此论文进行了研究，这些简化形式的新元组到底有多少。结论是<strong>大多数产生的新元组与训练集中它们最接近的元组具有明显不同的单词序列。</strong></p><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>​    本文引入常识转换器<strong>(COMET)</strong>来自动构建常识知识库。<strong>COMET</strong>是一个框架，用于调整语言模型的权重，以学习生成新颖和多样的常识知识元组。在两个常识知识库<strong>ATOMIC</strong>和<strong>ConceptNet上</strong>的实验结果表明，<strong>COMET</strong>经常产生人类评估者认为是正确的新常识知识。这些积极的结果表明未来可以寻求将该方法扩展到各种其他类型的知识库上，以及研究<strong>COMET</strong>是否可以学习为任意知识种子产生OpenIE风格的知识元组。</p>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>自然语言处理任务梳理</title>
    <link href="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/"/>
    <url>/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="NLP任务"><a href="#NLP任务" class="headerlink" title="NLP任务"></a>NLP任务</h1><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/1.png" class="" title="1.png"><h2 id="前处理任务"><a href="#前处理任务" class="headerlink" title="前处理任务"></a>前处理任务</h2><p>前处理任务的结果可作为下游任务输入的额外特征。</p><h3 id="POSTa-词性标注"><a href="#POSTa-词性标注" class="headerlink" title="POSTa(词性标注)"></a>POSTa(词性标注)</h3><p>往模型中输入句子，对每一个token进行词性的识别。</p><p>识别出的词性可以用于下游任务。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/2.png" class="" title="2.png"><h3 id="Word-Segmentation-分词"><a href="#Word-Segmentation-分词" class="headerlink" title="Word Segmentation(分词)"></a>Word Segmentation(分词)</h3><p>对于英文，显然句子有天然的分词。所以分词通常是针对中文句子。</p><p>分词之后，模型的输入就可以以词汇作单位，而不再以字作单位。</p><p>以下面例子做说明：</p><p>将一个句子按字输入模型，训练模型来对每个字来进行二分类决定每个字的对应位置输出N或者Y(N/Y是词的边界标识)</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/3.png" class="" title="3.png"><h3 id="Parsing-语义分析"><a href="#Parsing-语义分析" class="headerlink" title="Parsing(语义分析)"></a>Parsing(语义分析)</h3><p>给定句子产生树状结构——句子的语法结构。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/4.png" class="" title="4.png"><h3 id="Coreference-Rosolution-共指消解"><a href="#Coreference-Rosolution-共指消解" class="headerlink" title="Coreference Rosolution(共指消解)"></a>Coreference Rosolution(共指消解)</h3><p>从一段文章或者一段对话中找出指代同一个人或事物的所有词汇。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/5.png" class="" title="5.png"><h2 id="具体NLP任务"><a href="#具体NLP任务" class="headerlink" title="具体NLP任务"></a>具体NLP任务</h2><h3 id="Summarization-文本摘要"><a href="#Summarization-文本摘要" class="headerlink" title="Summarization(文本摘要)"></a>Summarization(文本摘要)</h3><p><strong>抽取式摘要：</strong>基于二分类任务，每个句子分开考虑。</p><p>衡量文章中句子应不应该放到摘要里面，但是这么做远远不够。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/6.png" class="" title="6.png"><p><strong>生成式摘要：</strong>属于seq2seq模型，输入长文本，模型用自己的语言进行短摘要的生成。</p><p><strong>模型的copy能力</strong>：输入文本序列和输出摘要很有可能有很多共用词汇，这些共用词汇经过模型的修改整合形成摘要的文本。因此模型需要增加输入copy能力，怎么实现？Pointer network(指针网络)。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/7.png" class="" title="7.png"><h3 id="Machine-Translation-机器翻译"><a href="#Machine-Translation-机器翻译" class="headerlink" title="Machine Translation(机器翻译)"></a>Machine Translation(机器翻译)</h3><p><strong>seq2seq</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/8.png" class="" title="8.png"><p><strong>audio2seq</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/9.png" class="" title="9.png"><p><strong>audio2audio</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/10.png" class="" title="10.png"><h3 id="Grammer-Error-Correction-语法纠正"><a href="#Grammer-Error-Correction-语法纠正" class="headerlink" title="Grammer Error Correction(语法纠正)"></a>Grammer Error Correction(语法纠正)</h3><p><strong>seq2seq?</strong> </p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/11.png" class="" title="11.png"><p>不，杀鸡焉用牛刀。</p><p><strong>seq2class</strong></p><p>输入句子，做分类，输出要对token要做的动作的标识（C/R/A/D)。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/12.png" class="" title="12.png"><p>C——复制，保持不变</p><p>A——在后面增加词汇</p><p>R——置换，把词换个时态或者换成别的词</p><p>D——删除</p><h3 id="Sentiment-Classfication-情感分类"><a href="#Sentiment-Classfication-情感分类" class="headerlink" title="Sentiment Classfication(情感分类)"></a>Sentiment Classfication(情感分类)</h3><p>输入一段文本或者评论，训练模型，输出文本的情感分类(正面/负面)。</p><p><strong>seq2class</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/13.png" class="" title="13.png"><h3 id="Stance-Detection-立场侦测"><a href="#Stance-Detection-立场侦测" class="headerlink" title="Stance Detection(立场侦测)"></a>Stance Detection(立场侦测)</h3><p><strong>seq2class</strong></p><p>通过一则博文或者文章以及其下的评论回复来进行评论者所处立场的判断。</p><p>立场通常有四类：SDQC(Support、Denying、Querying and Commenting)。</p><p>立场侦测经常被用于事实预测:</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/14.png" class="" title="14.png"><p><strong>事实预测：</strong></p><p><strong>seq2class</strong></p><p>根据新闻消息或者博文的评论立场以及外部的知识判断消息或文章内容的真实性。</p><h3 id="Natural-Language-Inference-自然语言推理"><a href="#Natural-Language-Inference-自然语言推理" class="headerlink" title="Natural Language Inference(自然语言推理)"></a>Natural Language Inference(自然语言推理)</h3><p><strong>seq2class</strong></p><p><strong>推理模型的文本输入</strong>：premise(前提) + hypothesis(假设)</p><p><strong>模型输出：</strong>对假设是否成立的判断结果，矛盾/包含(可推得)/中立(contradiction/entailment/neutral)</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/15.png" class="" title="15.png"><h3 id="Question-Answering-问答"><a href="#Question-Answering-问答" class="headerlink" title="Question Answering(问答)"></a>Question Answering(问答)</h3><h4 id="传统的基于检索的问答系统"><a href="#传统的基于检索的问答系统" class="headerlink" title="传统的基于检索的问答系统"></a>传统的基于检索的问答系统</h4><p><strong>简单的(模组少)：</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/16.png" class="" title="16.png"><ul><li><p>问题处理——对问题进行格式化，检测其答案的类别</p></li><li><p>检索资料库——进行文档、文章的检索选择</p></li><li><p>答案的生成和评估——从候选文章中抽取答案，抽取的答案根据第一步检测到的答案类别评估其正确性</p></li></ul><p><strong>复杂的(模组多)：</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/17.png" class="" title="17.png"><p><strong>和简单架构的区别：</strong></p><ul><li><p>问题处理——模组更多</p></li><li><p>候选答案生成——综合检索文章得到的候选答案和从自带的有结构资料库中调取的答案</p></li><li>答案评分</li><li>融合对等答案，返回答案及其可信度</li></ul><h4 id="基于深度学习的QA"><a href="#基于深度学习的QA" class="headerlink" title="基于深度学习的QA"></a>基于深度学习的QA</h4><p><strong>seq2seq</strong></p><p>输入问题文本和外部结构化/无结构化的知识(大多来自搜索引擎)，训练模型得到问题的答案。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/18.png" class="" title="18.png"><p>但是要实现直接向模型输入问题和外部知识就生成问题答案还有非常长的一段路要走。目前我们常做的只是从文本中抽取答案。</p><p><strong>抽取式QA：</strong></p><p><strong>seq2seq</strong></p><p>答案就在背景文章里面，向模型输入背景文章和问题，其实就是做通常意义上的阅读理解，模型产生抽取的答案文本在文章中的 start position 和 end position。</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/19.png" class="" title="19.png"><h3 id="Dialogue-对话"><a href="#Dialogue-对话" class="headerlink" title="Dialogue(对话)"></a>Dialogue(对话)</h3><p>对话涉及到自然语言生成(NLG)和自然语言理解(NLU)</p><h4 id="Chatting-闲聊"><a href="#Chatting-闲聊" class="headerlink" title="Chatting(闲聊)"></a>Chatting(闲聊)</h4><p><strong>seq2seq</strong></p><p>聊天都是有背景的，所以模型的输入应该是增量式的，模型的输出是根据之前的对话内容产生的。</p><p>根据对话的需求可以进行定制：</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/20.png" class="" title="20.png"><h4 id="Task-oriented-任务导向的对话"><a href="#Task-oriented-任务导向的对话" class="headerlink" title="Task-oriented(任务导向的对话)"></a>Task-oriented(任务导向的对话)</h4><p><strong>seq2seq</strong></p><p>需要实现一定的功能，比如提供订票、订餐厅、订酒店等服务</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/21.png" class="" title="21.png"><p><strong>系统架构</strong></p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/22.png" class="" title="22.png"><p>State Tracker记录当前对话的状态</p><h2 id="知识图"><a href="#知识图" class="headerlink" title="知识图"></a>知识图</h2><h3 id="NER-命名实体识别"><a href="#NER-命名实体识别" class="headerlink" title="NER(命名实体识别)"></a>NER(命名实体识别)</h3><p><strong>seq2class</strong></p><p>识别出句子中的人名、地名、组织等实体</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/23.png" class="" title="23.png"><h3 id="RE-关系抽取"><a href="#RE-关系抽取" class="headerlink" title="RE(关系抽取)"></a>RE(关系抽取)</h3><p><strong>seq2class</strong></p><p>输入文本和文本中两个实体，训练模型得到两个实体之间的关系</p><p>关系的种类基本是固定的，因此关系抽取的模型往往是去做一个复杂的分类任务</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/24.png" class="" title="24.png"><h2 id="综合任务"><a href="#综合任务" class="headerlink" title="综合任务"></a>综合任务</h2><p>综合任务的意义：看模型是否是真的“理解”了人类语言，能“举一反三”</p><h3 id="GLUE"><a href="#GLUE" class="headerlink" title="GLUE"></a>GLUE</h3><p>分为三大类</p><ul><li>文本分类(语法错误检查、文本情感分析)</li><li>文本相似度计算</li><li>自然语言推理</li></ul><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/25.png" class="" title="25.png"><h3 id="Super-GLUE"><a href="#Super-GLUE" class="headerlink" title="Super GLUE"></a>Super GLUE</h3><p>包含8个NLP任务，大多和QA有关</p><h3 id="DecaNLP"><a href="#DecaNLP" class="headerlink" title="DecaNLP"></a>DecaNLP</h3><p>同一个模型解决10个NLP任务</p><p>怎么实现？往QA的方向改造这些任务</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/26.png" class="" title="26.png"><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>根据这些NLP任务的输入输出，把这些任务和任务相关的一些技术手段进行梳理</p><img src="/2020/11/04/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A2%B3%E7%90%86/27.png" class="" title="27.png"><h3 id="one-on-one"><a href="#one-on-one" class="headerlink" title="one on one"></a>one on one</h3><p><strong>seq2class</strong></p><ul><li>情感分析</li><li>立场检测</li><li>文本内容辨真伪</li><li>文本意图识别</li><li>对话决策</li></ul><p><strong>seq2tokenclass</strong></p><ul><li>词性标注</li><li>分词</li><li>抽取式摘要</li><li>命名实体识别</li></ul><p><strong>seq2seq</strong></p><ul><li>抽象式摘要</li><li>机器翻译</li><li>文本语法矫正</li><li>自然语言生成</li></ul><h3 id="n-on-one"><a href="#n-on-one" class="headerlink" title="n on one"></a>n on one</h3><p><strong>seq2class</strong></p><ul><li>自然语言推理</li><li>搜索引擎</li><li>关系抽取</li></ul><p><strong>copy from input</strong></p><ul><li>抽取式QA</li></ul><p><strong>seq2seq</strong></p><ul><li>常规QA</li><li>任务导向对话</li><li>聊天机器人</li><li>State Tracker</li></ul><h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><ul><li>语义分析</li><li>共指消解</li></ul>]]></content>
    
    
    <categories>
      
      <category>综述</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>溯因推理</title>
    <link href="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/"/>
    <url>/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="Abductive-Commonsense-Reasoning-溯因推理"><a href="#Abductive-Commonsense-Reasoning-溯因推理" class="headerlink" title="Abductive Commonsense Reasoning(溯因推理)"></a>Abductive Commonsense Reasoning(溯因推理)</h2><p><a href="https://arxiv.org/pdf/1908.05739v2.pdf">论文地址</a><br><a href="https://github.com/allenai/abductive-commonsense-reasoning">论文代码</a></p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><strong>溯因推理</strong>是对不完全观察情境的<strong>最合理解释</strong>或假设的推论。</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/1.png" class=""><p><strong>上图给出的是一个简明扼要的例子：</strong></p><p>给定不同时间节点上的情境观测值 <script type="math/tex">O_{1}</script> 和 <script type="math/tex">O_{2}</script> ，溯因推理的任务是从给出的一众解释性假设 <script type="math/tex">H_{1}, \space H_{2}, \space \cdots ,H_{n}</script> 中选出<strong>最合理</strong>的。例如，上图在 <script type="math/tex">t_{0}</script> 时刻观测到的情境 <script type="math/tex">O_{1}</script> 是：<strong>Jenny打扫好了房间并给窗户留了条缝隙之后去工作了</strong>。而在 <script type="math/tex">t_{n}</script> 时刻，情境变成了：<strong>当Jenny回到家，发现房间里一片狼藉。</strong>针对这两个观测到的不同时间节点上情境，有若干个解释性假设 <script type="math/tex">H_{1}, \space H_{2}, \space H_{3}</script>。</p><ul><li>对于假设 <script type="math/tex">H_{1}</script> ，小偷的入室盗窃(<strong>broke into</strong>)很好的承接了 <script type="math/tex">O_{1}</script> 中”<strong>未关紧窗户(a crack open)</strong>“带来的安全隐患，并很好地解释了情境 <script type="math/tex">O_{2}</script> 中房间为什么一团乱(<strong>小偷翻东西</strong>)，因此看上去假设 <script type="math/tex">H_{1}</script> 非常合理的解释了情境 <script type="math/tex">O_{1}</script> 到情境 <script type="math/tex">O_{2}</script> 的转换。</li><li>对于假设 <script type="math/tex">H_{2}</script> ，假设中提到的大只的鸟(<strong>large bird</strong>)似乎不太可能从窗户缝隙飞进房间，但是如果不考虑情境 <script type="math/tex">O_{1}</script>，该假设可以很好地解释房间乱的现象(<strong>鸟儿被困房间，为了逃离，弄得房间很乱</strong>)</li><li>对于假设 <script type="math/tex">H_{3}</script>，前半部分<strong>(At work)</strong>可以很好地承接情境 <script type="math/tex">O_{1}</script>(<strong>Jenny去工作了，因此Jenny在工作中</strong>)，但是该假设后半部分(<strong>blew her papers everywhere</strong>)完全没法解释情境 <script type="math/tex">O_{2}</script>， 因为该假设完全指的是发生在<strong>办公处</strong>的事情，而情境 <script type="math/tex">O_{2}</script> 则是Jenny<strong>家中</strong>的场景。</li></ul><p>综合以上对三个假设的考量，我们很容易得出，第一个假设是最符合情境 <script type="math/tex">O_{1}</script> 和 <script type="math/tex">O_{2}</script> 的。然而这看似简单的推理过程，对于现有的模型来说，却不是那么容易的。</p><p>虽然长期以来<strong>”溯因“</strong>这种行为被认为是人们解读、理解自然语言的核心，但受限于数据集的缺乏和模型的性能，支撑溯因自然语言推理和生成的研究却相对较少。</p><h3 id="ART数据集"><a href="#ART数据集" class="headerlink" title="ART数据集"></a>ART数据集</h3><p>ART(<strong>叙事文本中的溯因推理</strong>——ABDUCTIVE REASONING IN NARRATIVE TEXT)是第一个用于研究叙事文本中溯因推理的大规模基准数据集。其组成如下：</p><ul><li><strong>20K左右的叙述背景</strong> ——成对的观察结果&lt;<script type="math/tex">O_{1}\space，O_{2}</script>&gt;<ul><li>这些观察情境是根据<strong>ROCStories</strong>数据集进行编写的。<strong>ROCStories</strong>是一个由五句话组成的手动精选短篇故事的大集合。它被设计为每个故事都有一个清晰的开始和结束，这自然对应到ART数据集中的 <script type="math/tex">O_{1},O_{2}</script> 。</li></ul></li><li><strong>超过200K的解释性假设</strong><ul><li>按可能的解释性假设 <script type="math/tex">h^{+}</script> 和不太可能的解释性假设 <script type="math/tex">h^{-}</script> 进行众包。对于 <script type="math/tex">h^{-}</script> 的众包 ,要求众包工人在 <script type="math/tex">h^{+}</script> 的基础上，进行最小限度的编辑(最多改动5个单词)，为每个 <script type="math/tex">h^{+}</script> 创造不可信的假设变量 <script type="math/tex">h^{-}</script>。</li></ul></li><li><strong>数据集分析</strong><ul><li>下面分别分析了训练集、开发集、测试集上对应每个观测的平均对应的正反解释性假设的个数和假设及观测文本句的平均词长。</li></ul></li></ul><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/2.png" class=""><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>论文中提出的两个溯因推理任务分别是αNLI(溯因自然语言推理——Abductive Natural Language Inference)和αNLG(溯因自然语言生成 —— Abductive Natural Language Generation)。</p><p>ART数据集中每个例子按如下格式定义：</p><ul><li><script type="math/tex">O_{1}</script> —— <script type="math/tex">t_{1}</script>时刻的观察</li><li><script type="math/tex">O_{2}</script> —— <script type="math/tex">t_{2}</script>时刻的观察</li><li><script type="math/tex">h^{+}</script> —— 对观察 <script type="math/tex">O_{1}</script> 和观察 <script type="math/tex">O_{2}</script> 的更合理的解释</li><li><script type="math/tex">h^{-}</script> —— 对观察 <script type="math/tex">O_{1}</script> 和观察 <script type="math/tex">O_{2}</script> 来说不太合理的解释</li></ul><h4 id="αNLI"><a href="#αNLI" class="headerlink" title="αNLI"></a>αNLI</h4><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/4.png" class=""><p>给定一对观测和一对解释性假设，αNLI的任务是选出两个假设中更有可能的那个。</p><p>在概率框架下模型的目标函数为：</p><script type="math/tex; mode=display">h^{*}=\arg \max _{h^{i}} P\left(H=h^{i} \mid O_{1}, O_{2}\right)</script><p>根据贝叶斯法则，以观测 <script type="math/tex">O_{1}</script> 为先验条件，可以重写上述公式：</p><script type="math/tex; mode=display">\begin{equation}\begin{aligned}P\left(h^{i} \mid O_{1}, O_{2}\right) = \frac{P\left(O_{2}, O_{1}, h^{i}\right)}{P\left(O_{1} , O_{2}\right)} \\=\frac{P\left(O_{2}\mid h^{i}, O_{1}\right)P\left(h^{i},O_{1}\right)}{P\left(O_{2}, O_{1}\right)} \\=\frac{P\left(O_{2}\mid h^{i}, O_{1}\right)P\left(h^{i} \mid O_{1}\right)}{P\left(O_{2}\mid O_{1}\right)}\end{aligned}\end{equation}</script><p>因为 <script type="math/tex">P\left(O_{2}\mid O_{1}\right)</script> 是定值，所求又是优化问题，所以可以仅考虑左侧的目标函数与右侧乘式的相关关系即可：</p><script type="math/tex; mode=display">P\left(h^{i} \mid O_{1}, O_{2}\right) \propto P\left(O_{2} \mid h^{i}, O_{1}\right) P\left(h^{i} \mid O_{1}\right)</script><p>根据上式，建立如下若干独立性假设，为αNLI任务构建一套概率模型：</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/3.png" class=""><ul><li><script type="math/tex">H_{i}</script> 与 <script type="math/tex">O_{1},O_{2}</script>都无关时(模型没用到观测值)</li></ul><script type="math/tex; mode=display">P\left(h^{i} \mid O_{1}, O_{2}\right)=P\left(h_{i}\right)</script><ul><li><p><script type="math/tex">H_{i}</script> 仅与 <script type="math/tex">O_{1},O_{2}</script>其中一个有关（模型用到了一个观测值）</p></li><li><p><strong>线性链</strong>模型 —— <script type="math/tex">H_{i}</script> 与 <script type="math/tex">O_{1},O_{2}</script>都直接相关，但 <script type="math/tex">O_{1} \perp O_{2}</script> (模型使用两个观测值，但独立地考虑了每个观测值对假设的影响)，</p></li></ul><script type="math/tex; mode=display">h^{*}=\arg \max _{h^{i}} P\left(O_{2} \mid h^{i}\right) P\left(h^{i} \mid O_{1}\right) \text { where }\left(O_{1} \perp O_{2} \mid H\right)</script><ul><li><strong>全连接</strong>(模型使用两个观测值，结合两个观测值的信息选择合理的假设)，目标函数为：</li></ul><script type="math/tex; mode=display">h^{*}=\arg \max _{h^{i}} P\left(O_{2} \mid h^{i},O_{1}\right) P\left(h^{i} \mid O_{1}\right)</script><p>在论文的实验中，将不同的独立性假设文本输入BERT进行编码。对于前两个概率模型，可以通过简单地将模型的输入限制为相关变量来加强独立性。另一方面，相关线性链模型将所有三个变量 <script type="math/tex">O_{1},O_{2},H</script> 都作为输入，通过限制模型的形式以加强条件独立性。具体来说，学习一个具有二分类功能的分类器:</p><script type="math/tex; mode=display">P_{\text {Linear }} \text { Chain }\left(h \mid O_{1}, O_{2}\right) \propto e^{\phi\left(O_{1}, h\right)+\phi^{\prime}\left(h, O_{2}\right)}</script><p>其中，<script type="math/tex">\phi</script> 和 <script type="math/tex">\phi^{\prime}</script> 为产生标量值的神经网络模型。</p><h4 id="αNLG"><a href="#αNLG" class="headerlink" title="αNLG"></a>αNLG</h4><p>给定 <script type="math/tex">O_{1},O_{2},h^{+}</script> 为一组的的训练数据，<strong>αNLG</strong>的任务就是最大化 <script type="math/tex">O_{1},O_{2},h^{+}</script> 对应的文本句在生成模型中的生成概率。同时，还可以在给定两个观测的基础上再添加背景知识 <script type="math/tex">\text{K}</script> 作为条件，模型的损失函数构造如下：</p><script type="math/tex; mode=display">\mathcal{L}=-\sum_{i=1}^{N} \log P\left(w_{i}^{h} \mid w_{<i}^{h}, w_{1}^{o 1} \ldots w_{m}^{o 1}, w_{1}^{o 2} \ldots w_{n}^{o 2}, \mathcal{K}\right)</script><p>其中，<script type="math/tex">O_{1}=\left\{w_{1}^{o 1} \ldots w_{m}^{o 1}\right\}</script> ，<script type="math/tex">O_{2}=\left\{w_{1}^{o 2} \ldots w_{n}^{o 2}\right\}</script>，<script type="math/tex">h^{+}=\left\{w_{1}^{h} \ldots w_{l}^{h}\right\}</script>，它们都由其自然语言文本对应的token组成。 <script type="math/tex">w_{<i}^{h}</script> 代表当前位置的前 <script type="math/tex">i</script> 个token，<script type="math/tex">w_{i}^{h}</script> 为当前位置 <script type="math/tex">i</script> 处的token。模型的训练目标就是最大化句子的生成概率 <script type="math/tex">P</script>，也即最小化上述公式的损失 <script type="math/tex">L</script>。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="αNLI-1"><a href="#αNLI-1" class="headerlink" title="αNLI"></a>αNLI</h4><p>αNLI任务被构造成了一个二分类问题。</p><h5 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h5><ul><li><strong>SVM</strong> —— 利用Glove词嵌入，考虑词长度、词的重叠和情感特征等对两个假设选项进行选择。(<strong>50.6%</strong>)</li><li><strong>BOW</strong> —— 将两个观察和一个解释性假设文本串接在一起，利用<strong>Glove</strong>为串接起来的文本构建句子嵌入，再通过一个全连接网络为包含每个不同的解释性假设选项的句子的嵌入打分。(<strong>50.5%</strong>)</li><li><strong>Bi-LSTM + max-pooling</strong> —— 用Bi-LSTM编码句子，使用经过最大池化后的句子嵌入进行打分。(<strong>50.8%</strong>)</li></ul><p>可以看到，传统分类器 + 上下文无关的单词嵌入的方式对解决这个二分类问题看上去几乎毫无作用(因为随机二选一都有一半的概率选对)。</p><h5 id="实验模型"><a href="#实验模型" class="headerlink" title="实验模型"></a>实验模型</h5><p>采用预训练模型GPT和BERT编码观测和解释性假设。</p><ul><li>对于GPT，将观测 <script type="math/tex">O_{1}</script> 和解释性假设 <script type="math/tex">H</script> 串接在一起，然后使用 [SEP] 将其与观测 <script type="math/tex">O_{2}</script> 分隔开，以[START] 和 [SEP] 结尾。</li><li>对于BERT，根据不同独立性假设。有如下五种输入的构造方式：</li></ul><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/6.png" class=""><h5 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h5><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/5.png" class=""><p>最后一列代表模型在论文提出的 <script type="math/tex">\text{ART}</script> 数据集上的表现，和前四个baseline相比，基于GPT和BERT构造的分类模型在数据集上的表现明显提高了很多，最好的<strong>BERT-ft[Linear Chain]</strong>比最佳baseline提升了10.1个百分点，达到了68.9。但是和人类的表现相比，这样的结果还是非常差的。因此，在溯因推理方面的研究还有很多工作要做。</p><h4 id="αNLG-1"><a href="#αNLG-1" class="headerlink" title="αNLG"></a>αNLG</h4><h5 id="实验模型-1"><a href="#实验模型-1" class="headerlink" title="实验模型"></a>实验模型</h5><ul><li><p><script type="math/tex">O_{1}-O_{2}-\text{Only}</script> —— 以组成两个观测值 <script type="math/tex">O_{1}</script> 和 <script type="math/tex">O_{2}</script> 的token为起始训练GPT2。</p></li><li><p>使用<strong>COMET</strong>生成<strong>ATOMIC</strong>格式(<strong>如果-那么</strong>)的知识 —— 包含常识知识的图，是一个以推理“如果-那么”的知识为主的知识库，它以事件作为节点，下列九大关系作为边：</p></li></ul><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/10.png" class=""><p><strong>ATOMIC</strong>是对<script type="math/tex">\text{ART}</script> 数据集中的叙事上下文进行推理所需的背景常识的来源。<strong>COMET</strong>是基于<strong>ATOMIC</strong>训练的专门实现常识知识图自动构建的Transformer，这里借助<strong>COMET</strong>生成基于事件的常识推理知识，然后再GPT2中集成了COMET生成的信息用于αNLG任务。集成方式分两种：</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/9.png" class=""><ul><li><strong>COMeT-Txt+GPT-2</strong>（作为文本短语的方式集成）</li></ul><p>在单词嵌入层嵌入输入标记之后，我们在通过Transformer架构的层之前，向串接的观察序列添加18个(对应于每个观察的九个关系)<strong>自然语言文本</strong>，由GPT2进行编码。</p><ul><li><strong>COMeT-Emb+GPT2</strong>（作为嵌入的方式集成）</li></ul><p>和上面那种方式一样，不过在观察序列前添加的是18个<strong>COMeT Embedding</strong>，这允许模型在处理COMeT嵌入时学习每个token的表示——有效地将背景常识知识集成到语言模型中。</p><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/7.png" class=""><h5 id="评估-1"><a href="#评估-1" class="headerlink" title="评估"></a>评估</h5><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/8.png" class=""><ul><li><strong>自动评估</strong> —— BLEU、METEOR、ROUGE、CIDEr、BERT-Score</li><li><strong>人工评估</strong> —— 向众包人员展示成对的观察结果和一个生成的假设，要求他们标注该假设是否解释了给定的观察结果。最后一栏为对应的评估分数。人工编写的假设在96%的情况下是正确的，而我们最好的生成模型，即使有背景常识知识的增强，也只能达到45%——这表明αNLG生成任务对当前最优越的文本生成器来说尤其具有挑战性。</li></ul><h5 id="生成实例"><a href="#生成实例" class="headerlink" title="生成实例"></a>生成实例</h5><img src="/2020/11/04/%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86/11.png" class=""><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>文章提出了第一项研究，调查基于语言的溯因推理的可行性。概念化并引入溯因自然语言推理(αNLI)——一个关注叙事语境中溯因推理的新任务。该任务被表述为一个选择题回答问题。文章还介绍了溯因自然语言生成(αNLG)——一种新的任务，需要机器为给定的观察结果生成可信的假设。为了支持这些任务，创建并引入了一个新的挑战数据集ART，它由20k个常识性叙述和200k多个解释性假设组成。在实验中，基于最先进的NLI和语言模型建立了这一新任务的Baseline，其准确率为68.9%，与人类性能(91.4%)有相当大的差距。αNLG任务要困难得多——虽然人类可以写出96%的有效解释，但是当前表现最好模型只能达到45%。文章的分析让我们对深度预训练语言模型无法执行的推理类型有了新的见解——尽管预训练模型在NLI蕴涵的密切相关但不同的任务中表现出色，但是在应对基于 <script type="math/tex">\text{ART}</script> 数据集提出的溯因推理和溯因生成任务时，表现却差强人意，这为未来的研究指出了有趣的途径。作者希望ART将成为未来基于语言的溯因推理研究的一个具有挑战性的基准，并且αNLI和αNLG任务将鼓励在人工智能系统中实现复杂推理能力的表征学习。</p>]]></content>
    
    
    <categories>
      
      <category>溯因推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>构建动态知识路径生成器用于常识推理</title>
    <link href="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/"/>
    <url>/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="构建常识问答知识路径生成器"><a href="#构建常识问答知识路径生成器" class="headerlink" title="构建常识问答知识路径生成器"></a>构建常识问答知识路径生成器</h2><h3 id="论文贡献"><a href="#论文贡献" class="headerlink" title="论文贡献"></a>论文贡献</h3><p>  提出学习一个多跳知识路径产生器来根据问题动态产生结构化证据。生成器以预先训练的语言模型为主干，利用语言模型中存储的大量非结构化知识来补充知识库的不完整性。路径生成器生成的这些相关路径被进一步聚合为知识嵌入，并与文本编码器给出的上下文嵌入进行融合。</p><h3 id="论文架构"><a href="#论文架构" class="headerlink" title="论文架构"></a>论文架构</h3><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/1.png" class=""><ul><li><p>从问题和答案选择中提取实体</p></li><li><p>使用构造的路径生成器生成一个多跳知识路径来连接每对问答实体</p><p>生成器学习将问题实体（红色）和选择实体（绿色）与生成的路径连接起来，这些路径充当QA的动态KG。</p></li></ul><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/2.png" class=""><ul><li>将生成的路径聚合为一个知识嵌入，并将其与文本编码器中的上下文嵌入相融合以进行分类。</li></ul><h4 id="识别实体"><a href="#识别实体" class="headerlink" title="识别实体"></a>识别实体</h4><p>从问题选项对中识别出问题中出现的实体和选项中出现的实体</p><ul><li>字符串匹配(论文中实际使用的方法)</li><li>NER(命名实体识别)</li></ul><h4 id="知识路径采样"><a href="#知识路径采样" class="headerlink" title="知识路径采样"></a>知识路径采样</h4><p>使用随机游走从一个常识KG中抽取符号路径，为GPT-2知识路径生成器采样具有代表性的关系路径作为训练的原始数据。</p><p><strong>提高路径质量</strong></p><p>假设使用Random Walk采样的这些样本路径包含和常识问答任务相关的知识，为了保证这些采样路径的质量，制定了两种启发式策略：</p><ul><li><p>保证相关性——定义了一个可能对回答常识问题有帮助的关系类型的子集。例如 {atlocation，isa}。在进行采样之前，丢弃一些被认为是帮助不大甚至无用处的关系类型，这些关系对于回答问题没什么帮助，这些关系包括：relatedto（相关)、synonym（同义）、antonym（反义）、derived-from（派生自）、formof（一种..形式）、etymologicallyderivedfrom（词源派生自） 和 etymologicallyrelatedto（词源相关）。</p></li><li><p>保证信息性——要求采样的路径不包含具有重复关系类型的边，即路径上每条边的关系都是唯一的。</p></li></ul><h5 id="局部采样（帮助生成器生成适用于任务的路径）"><a href="#局部采样（帮助生成器生成适用于任务的路径）" class="headerlink" title="局部采样（帮助生成器生成适用于任务的路径）"></a>局部采样（帮助生成器生成适用于任务的路径）</h5><ul><li>其中<script type="math/tex">E</script> 为实体集，<script type="math/tex">R</script>为关系集，<script type="math/tex">E</script> 由问题实体和选项实体组成，<script type="math/tex">R</script> 为定义的关系集合关系。以此给出静态的知识图(KG)，<script type="math/tex">G=(E,R)</script>。</li><li>随机游走是从任务训练集中的问题和答案选择中出现的实体开始的。随机游走算法进行图 <script type="math/tex">G</script> 上的路径采样，采样的路径形式为<script type="math/tex">({e_{0},r_{0},e_{1},r_{1},\cdots ,r_{T-1},e_{T}})</script>，其中<script type="math/tex">e_{T} \epsilon E</script>，<script type="math/tex">r_{T} \epsilon R</script>，<script type="math/tex">T</script> 为路径跳数</li></ul><h5 id="全局采样（防止生成器偏向生成KG的局部结构的路径）"><a href="#全局采样（防止生成器偏向生成KG的局部结构的路径）" class="headerlink" title="全局采样（防止生成器偏向生成KG的局部结构的路径）"></a>全局采样（防止生成器偏向生成KG的局部结构的路径）</h5><p>从静态KG中随机采样一些实体，并从它们开始进行随机游走，得到一些局部KG以外的路径用于生成器的泛化。</p><p>此外，还为每个关系添加了一个反向关系，这样采样的路径中不光有正向的路径和有反向的路径，这将使得路径生成器更加灵活地连接两个实体。</p><p>除此之外，还对具有混合跳数的路径进行采样，以训练生成器在需要事用可变长的路径来连接实体。对跳数从1到3的路径进行采样，以构造具有混合跳数的路径集。从特定任务数据集的全局采样和局部采样中获得的路径数如下表所示。将这两种抽样策略的路径合并，并进一步将其分成训练/开发/测试集，其比率为 9:0.5:0.5。</p><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/3.png" class=""><h4 id="基于GPT-2的路径生成器构建"><a href="#基于GPT-2的路径生成器构建" class="headerlink" title="基于GPT-2的路径生成器构建"></a>基于GPT-2的路径生成器构建</h4><p>  在随机游走采样的那些路径上对GPT-2进行微调。</p><p>  GPT-2是一种预训练的大容量语言模型，它从庞大的语料库中编码出丰富的非结构化知识。用它来作为路径生成器带来的好处是双重的：</p><ul><li>微调时使用到的结构化知识路径帮助丰富GPT-2，使得它学到按照设计生成具有“常识”风格路径的能力。</li><li>GPT-2从庞大的语料库中编码出的非结构化知识可以缓解KG的稀疏性问题。</li></ul><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/4.png" class=""><h5 id="采样的路径转化为文本化输入"><a href="#采样的路径转化为文本化输入" class="headerlink" title="采样的路径转化为文本化输入"></a><strong>采样的路径转化为文本化输入</strong></h5><p>  GPT-2 使用字节对编码（Byte Pair Encoding）方式来创建词汇表中的词（token），也就是说词（token）其实通常只是单词的一部分。使用GPT2的字节对编码(Byte-Pair Encoding)方法将上一步直接对知识图进行随机游走采样得到的符号路径转换成GPT-2输入的文本形式：</p><script type="math/tex; mode=display">{x}=\left\{X_{0}, Y_{0}, X_{1}, Y_{1}, \ldots, Y_{T-1}, X_{T}\right\}</script><p>  其中，<script type="math/tex">X_{t}=\left\{x_{t}^{0}, x_{t}^{1}, \ldots, x_{t}^{\left|e_{t}\right|}\right\}</script> 是实体 <script type="math/tex">e_{t}</script> 的短语token，而<script type="math/tex">Y_{t}=\left\{y_{t}^{0}, y_{t}^{1}, \ldots, y_{t}^{\left|r_{t}\right|}\right\}</script>是关系 <script type="math/tex">r_{t}</script> 的短语token。<br>  这样生成的文本形式的路径，方可在GPT-2中作为输入。</p><h6 id="字节对编码方法"><a href="#字节对编码方法" class="headerlink" title="字节对编码方法"></a><strong>字节对编码方法</strong></h6><p>  BPE最早是一种数据压缩算法，于2015年被引入到机器翻译领域并很快得到推广。该算法简单有效，因而目前它是最流行的子词表构建方法。GPT-2和RoBERTa使用的Subword算法都是BPE。</p><p>  BPE获得Subword的步骤如下：</p><ul><li>准备足够大的训练语料，并确定期望的Subword词表大小；</li><li>将单词拆分为成最小单元。比如英文中26个字母加上各种符号，这些作为初始词表；</li><li>在语料上统计单词内相邻单元对的频数，选取频数最高的单元对合并成新的Subword单元；</li><li>重复第3步直到达到第1步设定的Subword词表大小或下一个最高频数为1。</li></ul><p>假设有语料集经过统计后表示为{‘l o w &lt;/w&gt;’: 5, ‘l o w e r &lt;/w&gt;’: 2, ‘n e w e s t &lt;/w&gt;’: 6, ‘w i d e s t &lt;/w&gt;’: 3}，其中数字代表的是对应单词在语料中的频数。其中&lt;/w&gt;为终止符，用于区分单词的边界。</p><p>step 1, 最高频连续字节对”e”和”s”出现了6+3=9次，合并成”es”。输出：</p><pre><code class="hljs json">&#123;&#x27;l o w &lt;/w&gt;&#x27;: 5, &#x27;l o w e r &lt;/w&gt;&#x27;: 2, &#x27;n e w es t &lt;/w&gt;&#x27;: 6, &#x27;w i d es t &lt;/w&gt;&#x27;: 3&#125;</code></pre><p>step 2, 最高频连续字节对”es”和”t”出现了6+3=9次, 合并成”est”。输出：</p><pre><code class="hljs json">&#123;&#x27;l o w &lt;/w&gt;&#x27;: 5, &#x27;l o w e r &lt;/w&gt;&#x27;: 2, &#x27;n e w est &lt;/w&gt;&#x27;: 6, &#x27;w i d est &lt;/w&gt;&#x27;: 3&#125;</code></pre><p>step 3, 以此类推，最高频连续字节对为”est”和”&lt;/w&gt;” 输出：</p><pre><code class="hljs json">&#123;&#x27;l o w &lt;/w&gt;&#x27;: 5, &#x27;l o w e r &lt;/w&gt;&#x27;: 2, &#x27;n e w est&lt;/w&gt;&#x27;: 6, &#x27;w i d est&lt;/w&gt;&#x27;: 3&#125;</code></pre><p>……</p><p>step n, 继续迭代直到达到预设的subword词表大小或下一个最高频的字节对出现频率为1。</p><h6 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h6><ul><li><p>编码</p><p>在之前的算法中，已经得到了subword的词表，对该词表按照子词长度由大到小排序。编码时，对于每个单词，遍历排好序的子词词表寻找是否有token是当前单词的子字符串，如果有，则该token是表示单词的tokens之一。</p><p>从最长的token迭代到最短的token，尝试将每个单词中的子字符串替换为token。 最终，我们将迭代所有tokens，并将所有子字符串替换为tokens。 如果仍然有子字符串没被替换但所有token都已迭代完毕，则将剩余的子词替换为特殊token，如<unk>。</p></li></ul><p>例子</p><pre><code class="hljs text">// 给定单词序列[“the&lt;/w&gt;”, “highest&lt;/w&gt;”, “mountain&lt;/w&gt;”]// 假设已有排好序的subword词表[“errrr&lt;/w&gt;”, “tain&lt;/w&gt;”, “moun”, “est&lt;/w&gt;”, “high”, “the&lt;/w&gt;”, “a&lt;/w&gt;”]// 迭代结果&quot;the&lt;/w&gt;&quot; -&gt; [&quot;the&lt;/w&gt;&quot;]&quot;highest&lt;/w&gt;&quot; -&gt; [&quot;high&quot;, &quot;est&lt;/w&gt;&quot;]&quot;mountain&lt;/w&gt;&quot; -&gt; [&quot;moun&quot;, &quot;tain&lt;/w&gt;&quot;]</code></pre><ul><li>解码</li></ul><p>将所有的tokens拼在一起，以<script type="math/tex"></w></script>为界定符。</p><p>例子：</p><pre><code class="hljs python">// 编码序列[“the&lt;/w&gt;”, “high”, “est&lt;/w&gt;”, “moun”, “tain&lt;/w&gt;”]// 解码序列“the&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;”</code></pre><p>通过BPE编码和解码，为采样的路径构造出适合GPT-2的输入的文本格式。</p><h5 id="GPT-2生成器输入构造"><a href="#GPT-2生成器输入构造" class="headerlink" title="GPT-2生成器输入构造"></a>GPT-2生成器输入构造</h5><p>  为了进一步模拟生成器提供一个问题实体和一个选择实体的场景，在每个路径的开始处添加最后一个实体短语标记 <script type="math/tex">x_{T}</script> 和一个单独的标记[SEP]。这样，生成器将知道在生成路径时它应该输出的最后一个实体。</p><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/5.png" class=""><p> 将目标实体 + [SEP]标记 + 起始实体，即灰色部分交给GPT-2生成器来生成连接这两个实体的路径。</p><p>  已知前 <script type="math/tex">t-1</script> 个生成的token <script type="math/tex">s_{<t}</script>，当前第t个位置生成token <script type="math/tex">s_{t}</script> 的概率为：</p><script type="math/tex; mode=display">P\left(s_{t} \mid s_{<t}\right)=\operatorname{softmax}\left(\mathbf{W}_{\text {vocab}} \cdot \mathbf{h}_{\mathrm{t}}\right)</script><p>  这里 <script type="math/tex">h_{t}</script> 表示在解码时GPT-2对 <script type="math/tex">s_{t}</script> 的最终表示， <script type="math/tex">W_{vocab}</script> 是GPT-2使用的词汇表的嵌入矩阵。</p><p>  为了在给定实体对的情况下最大化生成句子 <script type="math/tex">s</script> 的概率，将损失函数定义为：</p><script type="math/tex; mode=display">\mathcal{L}=-\sum_{\mathbf{s}} \log P\left(\mathbf{s} \mid X_{T},[S E P], X_{0}\right)</script><p>  其中，<script type="math/tex">P\left(\mathbf{s} \mid X_{T},[S E P], X_{0}\right)</script> 为条件概率的乘积，另外，由于输入的 <script type="math/tex">X_{0}</script> 和 <script type="math/tex">X_{1}</script> 以及 <script type="math/tex">[SEP]</script>是固定的输入，所以 <script type="math/tex">t</script> 的下标从 <script type="math/tex">|X_{0}|+|X_{1}| + 1</script> 开始。</p><script type="math/tex; mode=display">P\left(\mathbf{s} \mid X_{T},[S E P], X_{0}\right)=\prod_{t=\left|X_{0}\right|+\left|X_{T}\right|+1}^{|\mathbf{s}|} P\left(s_{t} \mid s_{<t}\right)</script><h4 id="文本编码器的选择和构建"><a href="#文本编码器的选择和构建" class="headerlink" title="文本编码器的选择和构建"></a>文本编码器的选择和构建</h4><p>  本文常识问答的框架由两个主要部分组成。第一部分是前面提到的路径生成器。第二部分是一个上下文编码器，它对问题和选择进行编码，以输出一个上下文嵌入 <script type="math/tex">c</script> 作为非结构化证据。</p><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/6.png" class=""><p>  该论文实验采用的文本编码器为BERT和Robert，两种常用的文本输入上下文编码器。问题和选择通过添加一些特殊的标记串接起来，然后输入上下文编码器得到 <script type="math/tex">c</script> 。上下文嵌入 <script type="math/tex">c</script> 和路径生成器生成的路径进行Attention之后，输出一个知识嵌入 <script type="math/tex">p</script> 作为结构化证据。最后，这两类证据被输入分类器，为每个选择输出一个似然性得分。</p><h5 id="KE-知识嵌入-模块"><a href="#KE-知识嵌入-模块" class="headerlink" title="KE(知识嵌入)模块"></a>KE(知识嵌入)模块</h5><p>路径生成器GPT-2为每对问题选项生成一条最终的推理路径，对于生成的这些长度不一的离散路径，将GPT-2中最后一层隐藏状态的平均值 <script type="math/tex">p_{k}</script> 作为路径嵌入，从而最大限度地利用路径生成器。</p><script type="math/tex; mode=display">\mathbf{p}_{\mathbf{k}}=\operatorname{MEAN}\left(\left\{\mathbf{h}_{\mathbf{0}}, \mathbf{h}_{\mathbf{1}}, \ldots, \mathbf{h}_{\mathbf{T}}\right\}\right)</script><p>  由于GPT-2已经在一个大型语料库上进行了预训练，这样的表示应该足以保存路径的信息。</p><p>  由于并非所有的路径都会对决定哪个选择是正确答案做出同等贡献，所以我们利用非结构化证据，即上面提到的上下文嵌入c作为编码这种结构化证据的指导。</p><script type="math/tex; mode=display">\mathbf{p}=W_{p r o j} \cdot \sum_{k} \alpha_{k} \mathbf{p}_{k}</script><p>  其中 <script type="math/tex">W_{proj}</script> 是个可学习的映射矩阵，<script type="math/tex">\alpha_{k}</script> 为每条路径嵌入的注意力权重，其计算公式如下：</p><script type="math/tex; mode=display">\alpha_{k}=\frac{\exp \left(s_{k}\right)}{\sum_{k^{\prime}} \exp \left(s_{k^{\prime}}\right)}</script><p>  其中，<script type="math/tex">s_{k}</script> 的计算公式如下，注意力网络由 <script type="math/tex">W_{att}</script> 和 <script type="math/tex">b_{att}</script> 参数化</p><script type="math/tex; mode=display">s_{k}=\mathbf{c}^{\top} \tanh \left(\mathbf{W}_{a t t} \cdot \mathbf{p}_{k}+\mathbf{b}_{a t t}\right)</script><h5 id="融合异质信息进行分类"><a href="#融合异质信息进行分类" class="headerlink" title="融合异质信息进行分类"></a>融合异质信息进行分类</h5><p>  分类器利用路径生成器产生的路径嵌入 <script type="math/tex">p</script> 和文本编码器产生的非结构化的问题选项的上下文嵌入 <script type="math/tex">c</script> 来计算问题选择对的似然性。</p><p>  <strong>如何计算似然性</strong>？</p><p>  将 <script type="math/tex">c</script> 和 <script type="math/tex">p</script> 连接起来，并将它们提供给最终的线性分类层为每个问题选项对获取一个最终得分，这里涉及一个线性变换：</p><script type="math/tex; mode=display">f(q, a)=\mathbf{W}_{c l s} \cdot[\mathbf{c} ; \mathbf{p}]+\mathbf{b}_{c l s}</script><p>  最后通过一个softmax层对得分进行标准化，得到所有选择的最终概率。</p><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><h4 id="Pre-trained-LM"><a href="#Pre-trained-LM" class="headerlink" title="Pre-trained LM"></a><strong>Pre-trained LM</strong></h4><ul><li><p>BERT</p></li><li><p>RoBERTa</p><p>在该论文的框架中，使用了RoBERTa最后一层隐藏状态的平均池作为上下文嵌入，并将其输入到线性分类器以获得分数。</p></li></ul><h4 id="KG"><a href="#KG" class="headerlink" title="KG"></a><strong>KG</strong></h4><ul><li>静态KG，例如KagNet和RGCN</li><li>动态KG，该论文使用到的GPT-2路径动态生成</li></ul><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><img src="/2020/11/04/%E6%9E%84%E5%BB%BA%E5%8A%A8%E6%80%81%E7%9F%A5%E8%AF%86%E8%B7%AF%E5%BE%84%E7%94%9F%E6%88%90%E5%99%A8%E7%94%A8%E4%BA%8E%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/7.png" class=""><p>当使用RoBERTa作为上下文编码器以及上面提及的路径生成器之后，模型在CSQA的表现同baseline相比是最好的，但是当使用BERT作为上下文编码器时，表现并没有优于所有使用静态KG的模型。这是方法的局限性，在某种程度上仍然依赖上下文编码器来聚合具有注意机制的路径。如何设计一个与文本模块耦合较少的路径生成器是今后的工作。</p><p>​    </p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>  该论文提出了一种生成多跳知识路径的生成器，作为回答常识问题的结构化证据。为了学习这样一个路径生成器，微调了GPT-2，从一个常识KG中随机抽取样本。然后生成器将每对问答实体用一条知识路径连接起来。这些路径被进一步聚合为知识嵌入，并与文本编码器给出的上下文嵌入进行融合。在两个基准数据集上的实验结果表明，该论文的框架在性能上优于强预训练语言模型和静态KG增强方法。除此之外，还证明了所生成的路径在信息性和帮助性方面是可以解释的。未来的工作包括如何将生成器与文本编码器解耦，以及如何更好地融合知识。</p><h3 id="感谢"><a href="#感谢" class="headerlink" title="感谢"></a>感谢</h3><ul><li>BPE字节对编码方法的内容摘自文章：<a href="https://zhuanlan.zhihu.com/p/86965595">https://zhuanlan.zhihu.com/p/86965595</a></li><li>论文地址：<a href="https://arxiv.org/pdf/2005.00691.pdf">《Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering》</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>融合异构知识在图上进行常识推理</title>
    <link href="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/"/>
    <url>/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="融合异构知识进行常识问答"><a href="#融合异构知识进行常识问答" class="headerlink" title="融合异构知识进行常识问答"></a>融合异构知识进行常识问答</h2><p>论文标题 —— 《Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering》<br><a href="https://arxiv.org/pdf/1909.05311v2.pdf">论文来源</a><br><a href="https://github.com/DecstionBack/AAAI_2020_CommonsenseQA">论文代码</a></p><h3 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h3><h4 id="任务概述"><a href="#任务概述" class="headerlink" title="任务概述"></a>任务概述</h4><p>以CSQA（常识问答）为例，针对未提及背景知识的问题，要求考虑背景知识并作出回答</p><h4 id="任务形式"><a href="#任务形式" class="headerlink" title="任务形式"></a>任务形式</h4><p><strong>输入：</strong>问题Q=q_1 q_2⋯q_m和包含n个答案的候选答案集合A={a_1,a_2,⋯,a_n}<br><strong>目标：</strong>从候选集合中选出正确答案<br><strong>评价指标：</strong>准确率</p><h3 id="面临的问题"><a href="#面临的问题" class="headerlink" title="面临的问题"></a>面临的问题</h3><ul><li><p>在与问题相关的背景知识中如何获取evidence信息（抽取三元组，为知识源构建图）</p></li><li><p>如何基于获取到的evidence信息做出预测（图表示学习+图推理来解决）</p></li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/1.png" class=""><h4 id="从外部知识库抽取evidence"><a href="#从外部知识库抽取evidence" class="headerlink" title="从外部知识库抽取evidence"></a>从外部知识库抽取evidence</h4><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><ol><li><p>人工标注——耗时耗力耗财</p></li><li><p>仅从同构（结构化/非结构化）知识源中抽取evidence——没有同时利用不同来源的知识，得到的evidence可能不够全面</p></li><li><p>融合结构化与非结构化知识库中的知识，例如融合结构化的ConceptNet库和纯文本的Wikipedia库，并从中抽取evidence</p></li></ol><h5 id="具体实施"><a href="#具体实施" class="headerlink" title="具体实施"></a>具体实施</h5><p>从ConceptNet中抽取</p><ol><li><p>在ConceptNet中确定不同的问题和选项中出现的实体；</p></li><li><p>从ConceptNet中抽取从问题中的实体到候选中的实体的路径（小于 3 hops）</p></li></ol><p>从Wikipedia中抽取</p><ol><li><p>使用 Spacy 从中抽取出 107M 个句子，并用 Elastic Search 工具构建句子索引；</p></li><li><p>对于每个训练样例，去除问句和候选中的停用词，然后将所有词串联，作为检索查询 ；</p></li><li><p>使用 Elastic 搜索引擎 在检索查询和所有句子之间进行排序，选择出 top-K 个句子作为 Wikipedia 提供的证据信息（在实验中 K=10）；</p></li></ol><h4 id="为每个知识源构建图"><a href="#为每个知识源构建图" class="headerlink" title="为每个知识源构建图"></a>为每个知识源构建图</h4><h5 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h5><ol><li><p>对于ConceptNet库，用其自身的三元组即可</p></li><li><p>对于Wikipedia库，通过语义角色标注SRL(semantic role labeling)来抽取句子中的三元组</p></li></ol><h5 id="具体实施-1"><a href="#具体实施-1" class="headerlink" title="具体实施"></a>具体实施</h5><p><strong>构建ConceptNet图</strong></p><ol><li><p>把从ConceptNet中抽取出的路径拆分成三元组的形式，将每个三元组看做一个节点，融合到图中；对于含有相同实体的三元组，给图中对应到的节点加上一条边；</p></li><li><p>为了获取ConceptNet中节点的上下文词表示，将三元组根据关系模板转化为自然语言语句；</p></li></ol><p><strong>构建Wikipedia图</strong></p><ol><li><p>使用SRL抽出句子中的每个谓词的论元，谓词和论元作为节点，它们之间的关系作为边</p></li><li><p>同样地，为了增强构建图的连通性，基于两条给定的规则进行节点a,b之间的加边：</p><ul><li>b 中包含 a 且 a 的词数大于3</li><li>a 与 b 仅有一个不同的词，并且 a 和 b 包含的词数都大于3</li></ul></li></ol><h4 id="编码图信息、聚集evidence信息"><a href="#编码图信息、聚集evidence信息" class="headerlink" title="编码图信息、聚集evidence信息"></a>编码图信息、聚集evidence信息</h4><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/2.png" class=""><h5 id="具体实施-2"><a href="#具体实施-2" class="headerlink" title="具体实施"></a>具体实施</h5><ol><li><p>利用Topology Sort算法，根据知识抽取部分得到的图结构,对evidence句的顺序进行重排；<br>利用得到的图的结构，通过重定义evidence词之间的相对位置，来让语义相关的词的相对位置更加接近；<br>利用evidence内部的关系结构获取更好的上下文表示；</p></li><li><p>排好顺序的从ConceptNet库、Wikipedia库中抽出的evidence句、问题、所有选项<br>以上4个部分的串接，在使用了[sep]进行分隔后，作为XLNet的输入进行编码</p></li></ol><h4 id="进行最终的预测"><a href="#进行最终的预测" class="headerlink" title="进行最终的预测"></a>进行最终的预测</h4><h5 id="具体实施-3"><a href="#具体实施-3" class="headerlink" title="具体实施"></a>具体实施</h5><ul><li><p>把两个evidence图看作一个无向图，利用GCN对知识图和XLNet编码提供的问答+evidence的词级向量表示，来进行编码来获得节点层次的表示</p></li><li><p>evidence传播：</p><ul><li>从邻居节点聚集信息；</li><li>组合、更新节点表示</li></ul></li><li><p>利用图注意力网络对经过GCN得到的节点表示以及XLNet的input表示进行处理，聚集图级别的表示，进而进行最终的预测打分</p></li></ul><h3 id="重点模块及方法阐述"><a href="#重点模块及方法阐述" class="headerlink" title="重点模块及方法阐述"></a>重点模块及方法阐述</h3><h4 id="SRL"><a href="#SRL" class="headerlink" title="SRL"></a>SRL</h4><p>语义角色标注（Semantic Role Labeling，SRL）以句子的谓词为中心，不对句子所包含的语义信息进行深入分析，只分析句子中各成分与谓词之间的关系，即句子的谓词（Predicate）- 论元（Argument）结构。并用语义角色来描述这些结构关系，是许多自然语言理解任务（如信息抽取，篇章分析，深度问答等）的一个重要中间步骤。在研究中一般都假定谓词是给定的，所要做的就是找出给定谓词的各个论元和它们的语义角色。</p><h4 id="ConceptNet"><a href="#ConceptNet" class="headerlink" title="ConceptNet"></a>ConceptNet</h4><p>ConceptNet：常识知识库，它以三元组形式的关系型知识构成。</p><h4 id="ElaticSearch"><a href="#ElaticSearch" class="headerlink" title="ElaticSearch"></a>ElaticSearch</h4><p>ElasticSearch：一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，是当前流行的企业级搜索引擎。</p><h4 id="Topology-Sort"><a href="#Topology-Sort" class="headerlink" title="Topology Sort"></a>Topology Sort</h4><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/3.png" class=""><ul><li><p><strong>处理ConceptNet</strong></p><p>将三元组转化为自然语句，例如，(mammals, HasA, hair) -&gt; mammals has hair</p></li><li><p><strong>处理Wikipedia</strong></p><p>以evidence句作为句子图中的节点来构建句子图，如果在构建wikipedia图的过程中，节点p和q分别在句子s和t中，则为句子图中的代表两个相应句子的节点添加一条边。<br>利用拓扑排序算法对这些构建的句子图中的节点进行排序。</p></li></ul><h4 id="XLNET"><a href="#XLNET" class="headerlink" title="XLNET"></a>XLNET</h4><p><strong>使用XLNet而不采用BERT的原因，总结起来有以下几点：</strong></p><ul><li><p>BERT训练数据和测试数据之间的不一致性，这也叫作Discrephancy。当我们训练BERT的时候，<br> 会随机的Mask掉一些单词的，但实际上在使用的过程当中，我们却没有MASK这类的标签，<br> 所以这个问题就导致训练的过程和使用（测试）的过程其实不太一样，这是一个主要的问题。</p></li><li><p>BERT并不能用来生成数据。由于BERT本身是依赖于DAE的结构来训练的，所以不像那些基于语言模型训练出来的模型具备很好地生成能力。<br> 之前的方法比如NNLM，ELMo是基于语言模型生成的，所以用训练好的模型可以生成出一些句子、文本等。<br> 但基于这类生成模型的方法论本身也存在一些问题，因为理解一个单词在上下文里的意思的时候，语言模型只考虑了它的上文，而没有考虑下文！</p></li></ul><p>基于这些BERT的缺点，学者们提出了XLNet, 而且也借鉴了语言模型，还有BERT的优缺点。具体做法如下：</p><ul><li><p>首先，生成模型是单向的，即便我们使用Bidirectional LSTM类模型，其实本质是使用了两套单向的模型。<br> 通过使用permutation language model, 也就是把所有可能的permutation全部考虑进来。</p></li><li><p>另外，为了迎合这种改变，他们在原来的Transformer Encoder架构上做了改进，引入双流注意力机制,<br> 而且为了更好地处理较长的文本，进而使用的是Transformer-XL。 </p></li></ul><h4 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h4><p>图卷积神经网络，实际上跟CNN的作用一样，就是一个特征提取器，只不过它的对象是图数据（结构十分不规则，数据不具有平移不变性，<br>这让适用于处理图片、语言这类欧氏空间数据的传统的CNN、RNN瞬间失效）。</p><p>GCN精妙地设计了一种从图数据中提取特征的方法，从而让我们可以使用这些特征去对图数据进行节点分类<br>（node classification）、图分类（graph classification）、边预测（link prediction），还可以顺便得到图的嵌入表示（graph embedding）。</p><p>在Step 4对evidence图进行编码的过程，实际上就相当于对图数据进行了特征的提取。</p><p>GCN也是一个神经网络层，层与层之间的传播方式如下（利用了拉普拉斯矩阵）：</p><script type="math/tex; mode=display">H^{l+1}=\sigma\left(\widetilde{D}^{-\frac{1}{2}} \tilde{A} \widetilde{D}^{-\frac{1}{2}} H^{l} W^{l}\right)</script><p>需要说明的是，<script type="math/tex">\tilde{A}=A+I</script>为图的邻接矩阵，I为单位阵。<script type="math/tex">\tilde{D}</script> 为 <script type="math/tex">\tilde{A}</script> 的度矩阵。<script type="math/tex">H</script> 为每一层的特征。对于输入层 <script type="math/tex">H=X</script>。</p><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/4.png" class=""><p>若构造一个两层的GCN来进行分类任务，激活函数分别采用ReLU和softmax，则整体的正向传播公式为：</p><script type="math/tex; mode=display">\mathrm{Z}=\mathrm{f}(\mathrm{X}, \mathrm{A})=\operatorname{softmax}\left(\tilde{A} \operatorname{Re} L U\left(\tilde{A} X W^{(0)}\right) W^{(1)}\right)</script><p>上图中的GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，node之间的连接关系，即A，都是共享的。</p><p>GCN的特别之处：即使不训练，完全使用随机初始化的参数W，GCN提取出来的特征就已经非常优秀了！</p><h4 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h4><p>和所有的attention mechanism一样，GAT的计算也分为两步走：</p><ul><li>计算注意力系数；对于顶点i，注意计算它与它的邻接节点的相似系数</li></ul><script type="math/tex; mode=display">  e_{i j}=a\left(W \overrightarrow{h_{i}}, W \overrightarrow{h_{j}}\right)</script><p>其中共享参数W的线性映射给顶点的特征进行了增强，a(·)把拼接后的高维特征映射到一个实数上，这个过程一般通过一个单层的前馈神经网络来实现.对相关系数用softmax进行归一化便得到了注意力系数。 要理解计算过程可见下图。</p><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/5.png" class=""><ul><li>加权求和。把计算好的注意力系数进行加权求和，加上多头机制进行增强</li></ul><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/6.png" class=""><h4 id="GCN与GAT的异同"><a href="#GCN与GAT的异同" class="headerlink" title="GCN与GAT的异同"></a>GCN与GAT的异同</h4><ul><li><strong>同</strong>：GCN与GAT都是将邻居顶点的特征聚合到中心顶点上（一种aggregate运算），利用graph上的局部平稳性学习新的顶点特征表达。</li><li><strong>异</strong>：GCN利用了拉普拉斯矩阵，GAT利用attention系数。</li></ul><h5 id="为什么要融合异构知识源？"><a href="#为什么要融合异构知识源？" class="headerlink" title="为什么要融合异构知识源？"></a>为什么要融合异构知识源？</h5><ul><li><strong>结构化知识</strong> (Structured Knowledge Source)：包含大量的三元组信息（概念及其之间的关系），利于推理，但是存在覆盖度低的问题；</li><li><strong>非结构化知识</strong> (Unstructured Knowledge Source)：即 Plain-Text，包含大量冗余的、覆盖范围广的信息，可以辅助/补充结构化知识；</li></ul><img src="/2020/11/04/%E8%9E%8D%E5%90%88%E5%BC%82%E6%9E%84%E7%9F%A5%E8%AF%86%E5%9C%A8%E5%9B%BE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E5%B8%B8%E8%AF%86%E6%8E%A8%E7%90%86/7.png" class=""><p>在结构化知识和非结构化知识的协同作用下，模型选出了最佳答案。</p>]]></content>
    
    
    <categories>
      
      <category>常识推理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>B站弹幕爬取</title>
    <link href="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/"/>
    <url>/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h3 id="B站弹幕爬取"><a href="#B站弹幕爬取" class="headerlink" title="B站弹幕爬取"></a>B站弹幕爬取</h3><h4 id="单个视频弹幕的爬取"><a href="#单个视频弹幕的爬取" class="headerlink" title="单个视频弹幕的爬取"></a>单个视频弹幕的爬取</h4><pre><code>B站弹幕都是以xml文件的形式存在的，而xml文件的请求地址是如下形式：</code></pre><pre><code class="hljs html">http://comment.bilibili.com/233182992.xml</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/1.png" class=""><pre><code>其中，**233182992**是**cid**，这个需要从原视频的网页中获取。获取了**cid**之后，就可以按照上述的形式拼接请求地址，发送**get**请求，获取对应的xml文件。</code></pre><h5 id="cid获取"><a href="#cid获取" class="headerlink" title="cid获取"></a>cid获取</h5><pre><code>以华农兄弟的某个视频为例，进入视频主页。</code></pre><ul><li>右键启用<strong>检查模式</strong></li><li>选择<strong>网络</strong>(Network)，刷新网页</li><li>点开第一个文件，选择<strong>响应</strong>(response)</li><li>使用<strong>CTRL + F</strong>进行字段查找，输入<strong>“cid:”</strong>，发现匹配到的第一个cid就是视频的cid</li></ul><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/2.png" class=""><pre><code>接下来，就是如何从视频主页返回的网页信息中**提取cid**。</code></pre><ul><li>确定视频的<strong>bv号</strong> </li><li>根据bv号确定请求地址 </li><li>使用<strong>正则表达式</strong>从网页返回的文本中匹配cid</li><li>根据拿到的cid请求<strong>获取xml</strong>文件</li></ul><h5 id="xml文件解析"><a href="#xml文件解析" class="headerlink" title="xml文件解析"></a>xml文件解析</h5><pre><code>获取到xml文件之后，需要从xml文件中提取出弹幕文本。调用lxml库中的etree类，etree.HTML()可以用来解析字符串格式的HTML文档对象，将传进去的字符串转变成Element对象。作为Element对象，可以方便的使用getparent()、remove()、xpath()等方法。这里使用xpath来提取需要的那部分弹幕文本。</code></pre><h5 id="爬虫封装"><a href="#爬虫封装" class="headerlink" title="爬虫封装"></a>爬虫封装</h5><p>完整代码如下：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> re<span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BiliBiliDanMu</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, bv, filename</span>):</span>        <span class="hljs-comment"># 根据bv号构造要爬取的视频url地址</span>        self.video_url = <span class="hljs-string">&quot;https://bilibili.com/video/BV&quot;</span> + bv        self.filename = filename        self.headers = &#123;            <span class="hljs-string">&quot;User-Agent&quot;</span>: <span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)\</span><span class="hljs-string">             AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44&quot;</span>        &#125;    <span class="hljs-comment"># 获取视频的cid</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_video_cid</span>(<span class="hljs-params">self</span>):</span>        response = requests.get(self.video_url, headers=self.headers)        html = response.content.decode()        cid = re.findall(<span class="hljs-string">r&#x27;(&quot;cid&quot;:)([0-9]+)&#x27;</span>, html)        <span class="hljs-comment"># 有的视频没有这个字段，我们跳过它</span>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(cid) == <span class="hljs-number">0</span>:            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>        <span class="hljs-keyword">else</span>:            <span class="hljs-keyword">return</span> cid[<span class="hljs-number">0</span>][<span class="hljs-number">-1</span>]    <span class="hljs-comment"># 获取请求弹幕xml文件返回的内容</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_content</span>(<span class="hljs-params">self, xml_url</span>):</span>        response = requests.get(xml_url, headers=self.headers)        <span class="hljs-keyword">return</span> response.content    <span class="hljs-comment"># 解析获取到的内容，得到包含视频所有弹幕的列表</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_danmu</span>(<span class="hljs-params">self, content_str</span>):</span>        html = etree.HTML(content_str)        danmu_list = html.xpath(<span class="hljs-string">&quot;//d/text()&quot;</span>)        <span class="hljs-keyword">return</span> danmu_list    <span class="hljs-comment"># 将弹幕逐行写入并保存为txt文件</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save</span>(<span class="hljs-params">self, save_items</span>):</span>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(self.filename, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:            lines = []            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> save_items:                lines.append(item + <span class="hljs-string">&#x27;\n&#x27;</span>)            f.writelines(lines)    <span class="hljs-comment"># 爬虫的过程封装</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl</span>(<span class="hljs-params">self</span>):</span>        cid = self.get_video_cid()        <span class="hljs-comment"># 跳过没有cid字段的视频</span>        <span class="hljs-keyword">if</span> cid <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:            xml_url = <span class="hljs-string">&quot;http://comment.bilibili.com/&quot;</span> + <span class="hljs-built_in">str</span>(cid) + <span class="hljs-string">&quot;.xml&quot;</span>            content_str = self.get_content(xml_url)            danmu_lst = self.extract_danmu(content_str)            self.save(danmu_lst)        <span class="hljs-keyword">else</span>:            <span class="hljs-keyword">pass</span><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    bv = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;请输入视频的bv号: &quot;</span>)    dm = BiliBiliDanMu(bv, <span class="hljs-string">&#x27;./output/&#123;&#125;.txt&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">str</span>(bv)))    dm.crawl()</code></pre><h4 id="up主所有视频的弹幕爬取"><a href="#up主所有视频的弹幕爬取" class="headerlink" title="up主所有视频的弹幕爬取"></a>up主所有视频的弹幕爬取</h4><pre><code>仍然以华农兄弟的视频为例，进入华农兄弟的个人空间的视频页，地址如下：</code></pre><pre><code class="hljs html">https://space.bilibili.com/250858633/video</code></pre><h5 id="视频页数和up名字获取"><a href="#视频页数和up名字获取" class="headerlink" title="视频页数和up名字获取"></a>视频页数和up名字获取</h5><pre><code>仍然启用网页检查，来看我们需要的信息究竟该如何请求。首先，选中网络中的**XHR选项**，刷新页面，点击出现的**search**文件，点击响应，**左键连击3次**，选中响应返回的全部数据，其实，这里返回的就是一个**json文件**。</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/3.png" class=""><pre><code>我们使用一个在线工具来看看这个json文件的结构：[json工具](http://json.cn/)</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/4.png" class=""><pre><code>从这个结构里可以看到，**tlist字段**下包含了三类视频的类型id及数目(**count字段**)。而视频页的**最大固定展示数目为30**，因此，我们通过一个简单的计算就可以得到up主视频的总页数。由页数，也就能确定**循环请求的次数**。请求的**url地址**如下：</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/5.png" class=""><pre><code class="hljs html">https://api.bilibili.com/x/space/arc/search？mid=250858633&amp;ps=30&amp;tid=0&amp;pn=1&amp;keyword=&amp;order=pubdate&amp;jsonp=jsonp</code></pre><pre><code>其中，**mid**为up主的id号，**pn**为视频页号。</code></pre><h5 id="视频bv号批量获取"><a href="#视频bv号批量获取" class="headerlink" title="视频bv号批量获取"></a>视频bv号批量获取</h5><pre><code>从上述方式获取到的json文件中，我们可以不仅可以推断视频页的**总页数**，还能获取到当前页**所有视频的BV号以及作者信息**，根据BV号就能使用前面获取单个视频弹幕的代码来逐一获取当前页号下所有视频的弹幕了。</code></pre><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/6.png" class=""><h5 id="爬虫封装-1"><a href="#爬虫封装-1" class="headerlink" title="爬虫封装"></a>爬虫封装</h5><p>完整代码如下：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> json<span class="hljs-keyword">import</span> re<span class="hljs-keyword">import</span> os<span class="hljs-keyword">from</span> bilibili_danmu <span class="hljs-keyword">import</span> BiliBiliDanMuuper_name = <span class="hljs-literal">None</span><span class="hljs-comment"># 获取某个up主的全部视频的弹幕</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AllBv</span>:</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, up_id</span>):</span>        self.up_id = up_id        self.headers = &#123;            <span class="hljs-string">&quot;User-Agent&quot;</span>: <span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)\</span><span class="hljs-string">                     AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44&quot;</span>        &#125;    <span class="hljs-comment"># 获取视频总页数</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_num</span>(<span class="hljs-params">self</span>):</span>        url = <span class="hljs-string">&#x27;https://api.bilibili.com/x/space/arc/search?mid=&#123;&#125;\</span><span class="hljs-string">        &amp;ps=30&amp;tid=0&amp;pn=1&amp;keyword=&amp;order=pubdate&amp;jsonp=jsonp&#x27;</span>.<span class="hljs-built_in">format</span>(self.up_id)        response = requests.get(url=url, headers=self.headers)        json_dict = json.loads(response.content.decode())        video_dict = json_dict[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-string">&#x27;tlist&#x27;</span>]        total_videos = <span class="hljs-number">0</span>        <span class="hljs-keyword">global</span> uper_name        <span class="hljs-keyword">for</span> _, v <span class="hljs-keyword">in</span> video_dict.items():            total_videos += v[<span class="hljs-string">&#x27;count&#x27;</span>]        <span class="hljs-keyword">for</span> comment <span class="hljs-keyword">in</span> json_dict[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-string">&#x27;vlist&#x27;</span>]:            <span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(comment[<span class="hljs-string">&#x27;mid&#x27;</span>]) == self.up_id:                uper_name = comment[<span class="hljs-string">&#x27;author&#x27;</span>]            <span class="hljs-keyword">else</span>:                <span class="hljs-keyword">continue</span>        <span class="hljs-comment"># 每页最多30个视频</span>        <span class="hljs-keyword">return</span> uper_name, <span class="hljs-built_in">int</span>(total_videos / <span class="hljs-number">30</span> + <span class="hljs-number">1</span>)    <span class="hljs-comment"># 获取返回的json</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_json</span>(<span class="hljs-params">self, total_pages</span>):</span>        json_dict_lst = []        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, total_pages + <span class="hljs-number">1</span>):            url = <span class="hljs-string">&#x27;https://api.bilibili.com/x/space/arc/search?mid=&#123;&#125;&amp;ps=30&amp;tid=0&amp;pn=&#123;&#125; \</span><span class="hljs-string">            &amp;keyword=&amp;order=pubdate&amp;jsonp=jsonp&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">str</span>(self.up_id), <span class="hljs-built_in">str</span>(i))            response = requests.get(url=url, headers=self.headers)            json_dict_lst.append(json.loads(response.content.decode()))        <span class="hljs-keyword">return</span> json_dict_lst    <span class="hljs-comment"># 从json文件中获取bv号列表</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_bv_from_json</span>(<span class="hljs-params">self, json_dict</span>):</span>        v_lst = json_dict[<span class="hljs-string">&#x27;data&#x27;</span>][<span class="hljs-string">&#x27;list&#x27;</span>][<span class="hljs-string">&#x27;vlist&#x27;</span>]        bv_lst = []        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> v_lst:            bv_lst.append(item[<span class="hljs-string">&#x27;bvid&#x27;</span>][<span class="hljs-number">2</span>:])        <span class="hljs-keyword">return</span> bv_lst    <span class="hljs-comment"># 将得到的bv号列表存到一个txt文件中，文件夹名字以up主名字命名</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_bv_lst</span>(<span class="hljs-params">self, bv_lst, au_name</span>):</span>        folder = au_name        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(folder):            os.mkdir(folder)        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(au_name + <span class="hljs-string">&#x27;/bv_lst.txt&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:            lines = []            <span class="hljs-keyword">for</span> bv_id <span class="hljs-keyword">in</span> bv_lst:                lines.append(bv_id + <span class="hljs-string">&#x27;\n&#x27;</span>)            f.writelines(lines)    <span class="hljs-comment"># 封装爬取过程，返回up主的名字和所有视频的bv号列表</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl</span>(<span class="hljs-params">self</span>):</span>        up_name, pages_total = self.get_pages_num()        bv_video_lst = []        json_dict_lst = self.get_pages_json(pages_total)        <span class="hljs-keyword">for</span> json_file <span class="hljs-keyword">in</span> json_dict_lst:            bv_lst = self.get_bv_from_json(json_file)            bv_video_lst = bv_video_lst + bv_lst            self.save_bv_lst(bv_lst, <span class="hljs-string">&#x27;./&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(up_name))        <span class="hljs-keyword">return</span> up_name, bv_video_lst<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    up_id = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;please input up_id: &quot;</span>)    <span class="hljs-comment"># 实例化</span>    abm = AllBv(up_id)    author_name, bv_video_list = abm.crawl()    <span class="hljs-comment"># 借助单独一个bv视频弹幕爬取的类BiliBiliDanMu进行弹幕的爬取</span>    <span class="hljs-keyword">for</span> bv <span class="hljs-keyword">in</span> bv_video_list:        bm = BiliBiliDanMu(bv, <span class="hljs-string">&#x27;./&#123;&#125;/&#123;&#125;.txt&#x27;</span>.<span class="hljs-built_in">format</span>(author_name, <span class="hljs-built_in">str</span>(bv)))        bm.crawl()</code></pre><h4 id="制作词云"><a href="#制作词云" class="headerlink" title="制作词云"></a>制作词云</h4><pre><code class="hljs python"><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud<span class="hljs-keyword">import</span> jieba<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-comment"># 1:打开词云文本</span>txt = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./a.txt&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).read()<span class="hljs-comment"># 2:用jieba进行分词</span>txt_cut = <span class="hljs-string">&quot;&quot;</span>.join(jieba.cut(txt, cut_all=<span class="hljs-literal">False</span>) )<span class="hljs-comment"># 3:设置词云的属性</span>font = <span class="hljs-string">&quot;C:\\Windows\\Fonts\\simkai.TTF&quot;</span>     <span class="hljs-comment"># 词云的中文字体所在路径，不设置字体的话，很可能出现乱码</span>wc = WordCloud(font_path=font,               background_color=<span class="hljs-string">&quot;white&quot;</span>,               height=<span class="hljs-number">800</span>,               width=<span class="hljs-number">1000</span>               )<span class="hljs-comment"># 4:生成词云</span>wc.generate(txt_cut)<span class="hljs-comment"># 5:存储词云</span>wc.to_file(<span class="hljs-string">&quot;./demo.png&quot;</span>)</code></pre><p>效果图如下：</p><img src="/2020/11/04/B%E7%AB%99%E5%BC%B9%E5%B9%95%E7%88%AC%E5%8F%96/7.png" class="">]]></content>
    
    
    <categories>
      
      <category>爬虫</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker安装部署neo4j</title>
    <link href="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/"/>
    <url>/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/</url>
    
    <content type="html"><![CDATA[<h3 id="docker部署neo4j"><a href="#docker部署neo4j" class="headerlink" title="docker部署neo4j"></a>docker部署neo4j</h3><p>环境：ubuntu16.04LTS</p><h4 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h4><p>详见：<a href="https://www.runoob.com/docker/ubuntu-docker-install.html">菜鸟教程(docker安装)</a></p><h4 id="docker国内镜像源配置"><a href="#docker国内镜像源配置" class="headerlink" title="docker国内镜像源配置"></a>docker国内镜像源配置</h4><p>第一步，进入<a href="https://cr.console.aliyun.com/">阿里云</a>，登陆后点击左侧的镜像加速，生成自己的镜像加速地址。</p><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/%E9%98%BF%E9%87%8C%E4%BA%91%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E5%9C%B0%E5%9D%80%E7%94%9F%E6%88%90.png" class="" title="阿里云镜像加速"><p>第二步，选择ubuntu，执行阿里云推荐的终端命令，即可更新docker的镜像源为阿里云镜像。</p><h4 id="docker部署neo4j-1"><a href="#docker部署neo4j-1" class="headerlink" title="docker部署neo4j"></a>docker部署neo4j</h4><h5 id="拉取neo4j镜像"><a href="#拉取neo4j镜像" class="headerlink" title="拉取neo4j镜像"></a>拉取neo4j镜像</h5><p>第一步，从镜像源中找合适的镜像</p><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> search neo<span class="hljs-number">4</span>j</code></pre><p>第二步，拉取镜像源</p><pre><code class="hljs gcode">docker pull <span class="hljs-symbol">neo4</span>j<span class="hljs-comment">(:版本号)</span> <span class="hljs-comment">//缺省 “:版本号” 时默认安装latest版本的</span></code></pre><p>第三步，查看本地镜像，检验是否拉取成功</p><pre><code class="hljs ebnf"><span class="hljs-attribute">docker images</span></code></pre><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/%E6%9C%AC%E5%9C%B0%E9%95%9C%E5%83%8F.png" class="" title="本地镜像"><h5 id="构建neo4j容器"><a href="#构建neo4j容器" class="headerlink" title="构建neo4j容器"></a>构建neo4j容器</h5><p>第一步，在你根目录的任意一个子目录（我这里是/home)下建立四个基本的文件夹</p><ul><li>data——数据存放的文件夹</li><li>logs——运行的日志文件夹</li><li>conf——数据库配置文件夹（在配置文件<strong>neo4j.conf</strong>中配置包括开放远程连接、设置默认激活的数据库）</li><li>import——为了大批量导入csv来构建数据库，需要导入的节点文件<strong>nodes.csv</strong>和关系文件<strong>rel.csv</strong>需要放到这个文件夹下）</li></ul><pre><code class="hljs haml">docker run -d --name container_name \  //-d表示容器后台运行 --name指定容器名字-<span class="ruby">p <span class="hljs-number">7474</span><span class="hljs-symbol">:</span><span class="hljs-number">7474</span> -p <span class="hljs-number">7687</span><span class="hljs-symbol">:</span><span class="hljs-number">7687</span> \  /<span class="hljs-regexp">/映射容器的端口号到宿主机的端口号</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">data:</span>/data \  /<span class="hljs-regexp">/把容器内的数据目录挂载到宿主机的对应目录下</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">logs:</span>/logs \  /<span class="hljs-regexp">/挂载日志目录</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">conf:</span>/var/lib/neo4j/conf   /<span class="hljs-regexp">/挂载配置目录</span></span><span class="ruby">-v /home/neo4j/<span class="hljs-symbol">import:</span>/var/lib/neo4j/import \  /<span class="hljs-regexp">/挂载数据导入目录</span></span><span class="ruby">--env NEO4J_AUTH=neo4j/password \  /<span class="hljs-regexp">/设定数据库的名字的访问密码</span></span><span class="ruby">neo4j /<span class="hljs-regexp">/指定使用的镜像</span></span></code></pre><p>一个可以直接复制粘贴到终端执行的代码模板</p><pre><code class="hljs awk">docker run -d --name container_name -p <span class="hljs-number">7474</span>:<span class="hljs-number">7474</span> -p <span class="hljs-number">7687</span>:<span class="hljs-number">7687</span> -v <span class="hljs-regexp">/home/</span>neo4j<span class="hljs-regexp">/data:/</span>data -v <span class="hljs-regexp">/home/</span>neo4j<span class="hljs-regexp">/logs:/</span>logs -v <span class="hljs-regexp">/home/</span>neo4j<span class="hljs-regexp">/conf:/</span>var<span class="hljs-regexp">/lib/</span>neo4j<span class="hljs-regexp">/conf -v /</span>home<span class="hljs-regexp">/neo4j/im</span>port:<span class="hljs-regexp">/var/</span>lib<span class="hljs-regexp">/neo4j/im</span>port --env NEO4J_AUTH=neo4j/password neo4j</code></pre><p>其中<strong>container_name</strong>可以自己指定，挂载在根目录下的子目录可以根据你自己的实际情况进行替换，我这里是<strong>/home</strong>。另外<strong>NEO4J_AUTH</strong>也是你自己来进行设置。</p><p>执行完上述命令后就在后台把neo4j容器启动起来了，这个时候你就能在宿主机的浏览器中输入</p><pre><code class="hljs angelscript">localhost:<span class="hljs-number">7474</span></code></pre><p>输入用户名和密码就能登录到数据库了。</p><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/neo4j%E7%95%8C%E9%9D%A2.png" class="" title="neo4j界面"><h5 id="neo4j配置"><a href="#neo4j配置" class="headerlink" title="neo4j配置"></a>neo4j配置</h5><p>上述方式启动的neo4j是按照默认的配置进行启动的，而默认的数据库配置是不允许远程登陆的，这样对于在服务器上使用docker搭载neo4j的同学来说，就很不方便了。所以我们对默认配置进行一些改变，改变如下：</p><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 进入容器配置目录挂载在宿主机的对应目录，我这里是<span class="hljs-regexp">/home/</span>neo4j/confcd <span class="hljs-regexp">/home/</span>neo4j/conf<span class="hljs-regexp">//</span> vim编辑器打开neo4j.confvim neo4j.conf<span class="hljs-regexp">//</span> 进行以下更改<span class="hljs-regexp">//</span>在文件配置末尾添加这一行dbms.connectors.default_listen_address=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>  <span class="hljs-regexp">//</span>指定连接器的默认监听ip为<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>，即允许任何ip连接到数据库<span class="hljs-regexp">//</span>修改dbms.connector.bolt.listen_address=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7687</span>  <span class="hljs-regexp">//</span>取消注释并把对bolt请求的监听“地址:端口”改为“<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7687</span>”dbms.connector.http.listen_address=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7474</span>  <span class="hljs-regexp">//</span>取消注释并把对http请求的监听“地址:端口”改为“<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">7474</span>”</code></pre><p>保存后退出，重启neo4j容器，可以使用容器的省略id或者生成容器时指定的容器名进行重启。</p><pre><code class="hljs applescript">docker restart 容器<span class="hljs-built_in">id</span>（或者容器名）</code></pre><p><strong>防火墙设置</strong></p><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 查看当前防火墙状态，若为“inactive”，则防火墙已关闭，不必进行接续操作。sudo ufw status<span class="hljs-regexp">//</span> 若防火墙状态为“active”，则使用下列命令开放端口sudo ufw allow <span class="hljs-number">7474</span>sudo ufw allow <span class="hljs-number">7687</span><span class="hljs-regexp">//</span> 重启防火墙sudo ufw reload</code></pre><h4 id="neo4j数据导入"><a href="#neo4j数据导入" class="headerlink" title="neo4j数据导入"></a>neo4j数据导入</h4><p>neo4j数据的批量导入方法</p><img src="/2020/11/04/docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2neo4j/%E5%AF%BC%E5%85%A5%E6%96%B9%E6%B3%95.png" class="" title="导入方法"><p>为了加快速度，使用官方的<strong>Neo4j-import</strong>进行导入</p><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 数据准备清空data<span class="hljs-regexp">/databases/g</span>raph.db文件夹(如果有),将清洗好的结点文件nodes.csv和关系文件rel.csv拷贝到宿主机<span class="hljs-regexp">/home/</span>neo4j/import中<span class="hljs-regexp">//</span> docker以exec方式进入容器的交互式终端docker exec -it container_name(or container_id) <span class="hljs-regexp">/bin/</span>bash<span class="hljs-regexp">//</span> 停掉neo4jbin/neo4j stop<span class="hljs-regexp">//</span>使用如下命令导入bin/neo4j-admin import \--database=graph.db \        <span class="hljs-regexp">//</span>指定导入的数据库，没有系统则会在data/databases下自动创建一个--nodes .<span class="hljs-regexp">/import/</span>nodes.csv <span class="hljs-regexp">//</span>指定导入的节点文件位置--relationships .<span class="hljs-regexp">/import/</span>rel.csv <span class="hljs-regexp">//</span>指定导入的关系文件位置--skip-duplicate-nodes=true <span class="hljs-regexp">//</span>设置重复节点自动过滤--skip-bad-relationships=true <span class="hljs-regexp">//</span>设置bad关系自动过滤<span class="hljs-regexp">//</span>可执行一行式终端命令bin<span class="hljs-regexp">/neo4j-admin import --database=graph.db --nodes ./im</span>port<span class="hljs-regexp">/nodes.csv --relationships ./im</span>port/rel.csv --skip-duplicate-nodes=true --skip-bad-relationships=true<span class="hljs-regexp">//</span> 容器内启动neo4jbin/neo4j start<span class="hljs-regexp">//</span> 退出交互式终端但是保证neo4j后台继续运行ctrl + P + Q<span class="hljs-regexp">//</span>保险起见，重启neo4j容器docker restart container_name(or container_id)</code></pre><p>重启后使用另一台主机向服务器发送http请求进行远程登陆，在浏览器中输入</p><pre><code class="hljs angelscript">服务器ip:<span class="hljs-number">7474</span></code></pre><p><strong>切换连接模式</strong>为 <strong>bolt:/</strong> ，输入用户名和密码进行登陆，登陆成功发现在数据库一栏没找到新导入的数据库<strong>graph.db</strong></p><p>这是因为配置不够全，继续进到容器挂载到宿主机的<strong>/home/neo4j/conf</strong>中对<strong>neo4j.conf</strong>进行配置</p><pre><code class="hljs reasonml"><span class="hljs-comment">//在文件末尾添加默认的数据库</span>dbms.active_database=graph.db<span class="hljs-comment">// 保存后重启容器</span>docker restart container<span class="hljs-constructor">_name(<span class="hljs-params">or</span> <span class="hljs-params">container_id</span>)</span></code></pre><p>重新进行远程连接，此时数据库的默认选择应该就切换到了新导入的graph.db。</p><h4 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h4><p>数据如何清洗成两个符合neo4j-import导入格式的csv文件？</p><ul><li><a href="https://blog.csdn.net/muruibin88/article/details/106475757">ownthink_kg 1.4亿数据快速导入Neo4j</a></li><li><a href="https://github.com/jievince/rdf-converter">GO语言编写的开源数据清洗工具</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
